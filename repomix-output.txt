This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-16T21:24:32.923Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

================================================================
Directory Structure
================================================================
commands/
  fetch_gpu_data.py
gpuhunt/
  src/
    gpuhunt/
      _internal/
        catalog.py
        constraints.py
        default.py
        models.py
        storage.py
        utils.py
      providers/
        __init__.py
        aws.py
        azure.py
        crusoe.py
        cudo.py
        datacrunch.py
        gcp.py
        genesiscloud.py
        lambdalabs.py
        latitude.py
        leadergpu.py
        linode.py
        nebius.py
        oci.py
        runpod.py
        scaleway.py
        scraper.py
        seeweb.py
        tensordock.py
        vastai.py
        vultr.py
      __init__.py
      __main__.py
      version.py
    integrity_tests/
      conftest.py
      test_all.py
      test_aws.py
      test_azure.py
      test_datacrunch.py
      test_gcp.py
      test_nebius.py
      test_oci.py
      test_runpod.py
    tests/
      _internal/
        test_catalog.py
        test_constraints.py
        test_models.py
        test_utils.py
      providers/
        test_cudo.py
        test_datacrunch.py
        test_oci.py
        test_providers.py
        test_scaleway.py
        test_tensordock.py
        test_vultr.py
  tests/
    providers/
      test_leadergpu.py
  README.md
middleware/
  auth.py
migrations/
  versions/
    1c11b26cc472_update_gpu_schema_for_gpuhunt_.py
  env.py
models/
  gpu_listing.py
  project.py
  user_preferences.py
  user.py
routes/
  gpu_listings.py
  project.py
  user_preferences.py
  user.py
scripts/
  web-scrapping/
    normalize_data.py
    scrape_latitude.py
    scrape_leadergpu.py
    scrape_scaleway.py
    scrape_vast.py
    scrape-tensordock.py
  check_db.py
  populate_db.py
  reset_db.py
  setup_postgres.py
utils/
  database.py
  gpu_data_fetcher.py
app.py
config.py
Ideas.md
README.md

================================================================
Files
================================================================

================
File: commands/fetch_gpu_data.py
================
from flask.cli import with_appcontext
import click
from utils.gpu_data_fetcher import fetch_gpu_data

@click.command('fetch-gpu-data')
@with_appcontext
def fetch_gpu_data_command():
    """Fetch GPU data from providers"""
    try:
        fetch_gpu_data()
        click.echo('Successfully fetched GPU data')
    except Exception as e:
        click.echo(f'Error fetching GPU data: {str(e)}', err=True)
        raise

================
File: gpuhunt/src/gpuhunt/_internal/catalog.py
================
import csv
import dataclasses
import heapq
import io
import logging
import os
import time
import urllib.request
import zipfile
from concurrent.futures import ThreadPoolExecutor, wait
from pathlib import Path
from typing import Optional, Union

import gpuhunt._internal.constraints as constraints
from gpuhunt._internal.models import AcceleratorVendor, CatalogItem, QueryFilter
from gpuhunt._internal.utils import parse_compute_capability
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
version_url = "https://dstack-gpu-pricing.s3.eu-west-1.amazonaws.com/v1/version"
catalog_url = "https://dstack-gpu-pricing.s3.eu-west-1.amazonaws.com/v1/{version}/catalog.zip"
OFFLINE_PROVIDERS = ["aws", "azure", "datacrunch", "gcp", "lambdalabs", "oci", "runpod"]
ONLINE_PROVIDERS = ["cudo", "tensordock", "vastai", "vultr", "latitude"]
RELOAD_INTERVAL = 15 * 60  # 15 minutes

class Catalog:
    def __init__(self, balance_resources: bool = True, auto_reload: bool = True):
        """
        Args:
            balance_resources: increase min resources to better match the chosen GPU
            auto_reload: if `True`, the catalog will be automatically loaded from the S3 bucket every 4 hours
        """
        self.catalog = None
        self.loaded_at = None
        self.providers: list[AbstractProvider] = []
        self.balance_resources = balance_resources
        self.auto_reload = auto_reload

    def query(
        self,
        *,
        provider: Optional[Union[str, list[str]]] = None,
        min_cpu: Optional[int] = None,
        max_cpu: Optional[int] = None,
        min_memory: Optional[float] = None,
        max_memory: Optional[float] = None,
        min_gpu_count: Optional[int] = None,
        max_gpu_count: Optional[int] = None,
        gpu_vendor: Optional[Union[AcceleratorVendor, str]] = None,
        gpu_name: Optional[Union[str, list[str]]] = None,
        min_gpu_memory: Optional[float] = None,
        max_gpu_memory: Optional[float] = None,
        min_total_gpu_memory: Optional[float] = None,
        max_total_gpu_memory: Optional[float] = None,
        min_disk_size: Optional[int] = None,
        max_disk_size: Optional[int] = None,
        min_price: Optional[float] = None,
        max_price: Optional[float] = None,
        min_compute_capability: Optional[Union[str, tuple[int, int]]] = None,
        max_compute_capability: Optional[Union[str, tuple[int, int]]] = None,
        spot: Optional[bool] = None,
    ) -> list[CatalogItem]:
        """
        Query the catalog for matching offers

        Args:
            provider: name of the provider to filter by. If not specified, all providers will be used
            min_cpu: minimum number of CPUs
            max_cpu: maximum number of CPUs
            min_memory: minimum amount of RAM in GB
            max_memory: maximum amount of RAM in GB
            min_gpu_count: minimum number of GPUs
            max_gpu_count: maximum number of GPUs
            gpu_name: name of the GPU to filter by. If not specified, all GPUs will be used
            min_gpu_memory: minimum amount of GPU VRAM in GB for each GPU
            max_gpu_memory: maximum amount of GPU VRAM in GB for each GPU
            min_total_gpu_memory: minimum amount of GPU VRAM in GB for all GPUs combined
            max_total_gpu_memory: maximum amount of GPU VRAM in GB for all GPUs combined
            min_disk_size: minimum disk size in GB
            max_disk_size: maximum disk size in GB
            min_price: minimum price per hour in USD
            max_price: maximum price per hour in USD
            min_compute_capability: minimum compute capability of the GPU
            max_compute_capability: maximum compute capability of the GPU
            spot: if `False`, only ondemand offers will be returned. If `True`, only spot offers will be returned

        Returns:
            list of matching offers
        """
        if self.auto_reload and (
            self.loaded_at is None or time.monotonic() - self.loaded_at > RELOAD_INTERVAL
        ):
            self.load()

        query_filter = QueryFilter(
            provider=[provider] if isinstance(provider, str) else provider,
            min_cpu=min_cpu,
            max_cpu=max_cpu,
            min_memory=min_memory,
            max_memory=max_memory,
            min_gpu_count=min_gpu_count,
            max_gpu_count=max_gpu_count,
            gpu_vendor=AcceleratorVendor.cast(gpu_vendor) if gpu_vendor else None,
            gpu_name=[gpu_name] if isinstance(gpu_name, str) else gpu_name,
            min_gpu_memory=min_gpu_memory,
            max_gpu_memory=max_gpu_memory,
            min_total_gpu_memory=min_total_gpu_memory,
            max_total_gpu_memory=max_total_gpu_memory,
            min_disk_size=min_disk_size,
            max_disk_size=max_disk_size,
            min_price=min_price,
            max_price=max_price,
            min_compute_capability=parse_compute_capability(min_compute_capability),
            max_compute_capability=parse_compute_capability(max_compute_capability),
            spot=spot,
        )

        if query_filter.provider is not None:
            # validate providers
            for p in query_filter.provider:
                if p.lower() not in OFFLINE_PROVIDERS + ONLINE_PROVIDERS:
                    raise ValueError(f"Unknown provider: {p}")
        else:
            query_filter.provider = OFFLINE_PROVIDERS + list(
                set(p.NAME for p in self.providers if p.NAME in ONLINE_PROVIDERS)
            )

        # fetch providers
        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = []

            for provider_name in ONLINE_PROVIDERS:
                if provider_name in map(str.lower, query_filter.provider):
                    futures.append(
                        executor.submit(
                            self._get_online_provider_items,
                            provider_name,
                            query_filter,
                        )
                    )

            for provider_name in OFFLINE_PROVIDERS:
                if provider_name in map(str.lower, query_filter.provider):
                    futures.append(
                        executor.submit(
                            self._get_offline_provider_items,
                            provider_name,
                            query_filter,
                        )
                    )

            completed, _ = wait(futures)
            # The merge preserves provider-specific order, picking the cheapest offer at each step.
            # The final list is not strictly sorted by the price.
            items = list(heapq.merge(*[f.result() for f in completed], key=lambda i: i.price))
        return items

    def load(self, version: Optional[str] = None):
        """
        Fetch the catalog from the S3 bucket

        Args:
            version: specific version of the catalog to download. If not specified, the latest version will be used
        """
        if version is None:
            version = self.get_latest_version()
        logger.debug("Downloading catalog %s...", version)
        with urllib.request.urlopen(catalog_url.format(version=version)) as f:
            self.loaded_at = time.monotonic()
            self.catalog = io.BytesIO(f.read())

    @staticmethod
    def get_latest_version() -> str:
        """
        Get the latest version of the catalog from the S3 bucket
        """
        with urllib.request.urlopen(version_url) as f:
            return f.read().decode("utf-8").strip()

    def add_provider(self, provider: AbstractProvider):
        """
        Add provider for querying offers

        Args:
            provider: provider to add
        """
        self.providers.append(provider)

    def _get_offline_provider_items(
        self, provider_name: str, query_filter: QueryFilter
    ) -> list[CatalogItem]:
        logger.debug("Loading items for offline provider %s", provider_name)
        items = []
        # Set this env var to use a local catalog instead of the s3 catalog
        catalog_dir = os.getenv("GPUHUNT_CATALOG_DIR")
        if catalog_dir is not None:
            with open(Path(catalog_dir) / f"{provider_name}.csv", "rb") as csv_file:
                reader = csv.DictReader(io.TextIOWrapper(csv_file, "utf-8"))
                for row in reader:
                    item = CatalogItem.from_dict(row, provider=provider_name)
                    if constraints.matches(item, query_filter):
                        items.append(item)
        else:
            if self.catalog is None:
                logger.warning("Catalog not loaded")
                return items
            with zipfile.ZipFile(self.catalog) as zip_file:
                with zip_file.open(f"{provider_name}.csv", "r") as csv_file:
                    reader = csv.DictReader(io.TextIOWrapper(csv_file, "utf-8"))
                    for row in reader:
                        item = CatalogItem.from_dict(row, provider=provider_name)
                        if constraints.matches(item, query_filter):
                            items.append(item)
        return items

    def _get_online_provider_items(
        self, provider_name: str, query_filter: QueryFilter
    ) -> list[CatalogItem]:
        logger.debug("Loading items for online provider %s", provider_name)
        items = []
        found = False
        for provider in self.providers:
            if provider.NAME != provider_name:
                continue
            found = True
            for i in provider.get(
                query_filter=query_filter, balance_resources=self.balance_resources
            ):
                item = CatalogItem(provider=provider_name, **dataclasses.asdict(i))
                if constraints.matches(item, query_filter):
                    items.append(item)
        if not found:
            raise ValueError(f"Provider is not loaded: {provider_name}")
        return items

================
File: gpuhunt/src/gpuhunt/_internal/constraints.py
================
from typing import Optional, TypeVar, Union

from gpuhunt._internal.models import (
    AcceleratorVendor,
    AMDArchitecture,
    AMDGPUInfo,
    CatalogItem,
    NvidiaGPUInfo,
    QueryFilter,
    TPUInfo,
)

# v5litepod = v5e
_TPU_VERSIONS = ["v2", "v3", "v4", "v5p", "v5litepod", "v6e"]


def _is_tpu(name: str) -> bool:
    parts = name.split("-")
    if len(parts) == 2:
        version, cores = parts
        if version in _TPU_VERSIONS and cores.isdigit():
            return True
    return False


Comparable = TypeVar("Comparable", bound=Union[int, float, tuple[int, int]])


def is_between(value: Comparable, left: Optional[Comparable], right: Optional[Comparable]) -> bool:
    if is_below(value, left) or is_above(value, right):
        return False
    return True


def is_below(value: Comparable, limit: Optional[Comparable]) -> bool:
    if limit is not None and value < limit:
        return True
    return False


def is_above(value: Comparable, limit: Optional[Comparable]) -> bool:
    if limit is not None and value > limit:
        return True
    return False


def matches(i: CatalogItem, q: QueryFilter) -> bool:
    """
    Check if the catalog item matches the filters

    Args:
        i: catalog item
        q: filters

    Returns:
        whether the catalog item matches the filters
    """
    if q.provider is not None and i.provider.lower() not in map(str.lower, q.provider):
        return False
    if not is_between(i.price, q.min_price, q.max_price):
        return False
    if q.spot is not None and i.spot != q.spot:
        return False
    if not is_between(i.cpu, q.min_cpu, q.max_cpu):
        return False
    if not is_between(i.memory, q.min_memory, q.max_memory):
        return False
    if q.gpu_vendor and q.gpu_vendor != i.gpu_vendor:
        return False
    if not is_between(i.gpu_count, q.min_gpu_count, q.max_gpu_count):
        return False
    if q.gpu_name is not None:
        if i.gpu_name is None:
            return False
        if i.gpu_name.lower() not in map(str.lower, q.gpu_name):
            return False
    if q.min_compute_capability is not None or q.max_compute_capability is not None:
        if i.gpu_vendor != AcceleratorVendor.NVIDIA:
            return False
        if not i.gpu_name:
            return False
        cc = get_compute_capability(i.gpu_name)
        if not cc or not is_between(cc, q.min_compute_capability, q.max_compute_capability):
            return False
    if not is_between(i.gpu_memory if i.gpu_count > 0 else 0, q.min_gpu_memory, q.max_gpu_memory):
        return False
    if not is_between(
        (i.gpu_count * i.gpu_memory) if i.gpu_count > 0 else 0,
        q.min_total_gpu_memory,
        q.max_total_gpu_memory,
    ):
        return False
    if i.disk_size is not None:
        if not is_between(i.disk_size, q.min_disk_size, q.max_disk_size):
            return False
    return True


def get_compute_capability(gpu_name: str) -> Optional[tuple[int, int]]:
    for gpu in KNOWN_NVIDIA_GPUS:
        if gpu.name.lower() == gpu_name.lower():
            return gpu.compute_capability
    return None


def correct_gpu_memory_gib(gpu_name: str, memory_mib: float) -> int:
    """
    Round to whole number of gibibytes and attempt correcting the reported GPU
    memory size if the actual memory size for that GPU is known and the
    difference between the reported and the known memory is within a heuristic
    threshold.

    This is useful for cases when nvidia-smi or cloud providers report the GPU
    memory imprecisely.
    """

    memory_gib = memory_mib / 1024
    known_memories_gib = {gpu.memory for gpu in KNOWN_ACCELERATORS if gpu.name == gpu_name}
    if known_memories_gib:
        closest_known_memory_gib = min(known_memories_gib, key=lambda x: abs(x - memory_gib))
        difference_gib = abs(closest_known_memory_gib - memory_gib)
        if difference_gib / closest_known_memory_gib < 0.07:
            return closest_known_memory_gib
    return round(memory_gib)


KNOWN_NVIDIA_GPUS: list[NvidiaGPUInfo] = [
    NvidiaGPUInfo(name="A10", memory=24, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A16", memory=16, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A40", memory=48, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A100", memory=40, compute_capability=(8, 0)),
    NvidiaGPUInfo(name="A100", memory=80, compute_capability=(8, 0)),
    NvidiaGPUInfo(name="A10G", memory=24, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A4000", memory=16, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A4500", memory=20, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A5000", memory=24, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="A6000", memory=48, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="H100", memory=80, compute_capability=(9, 0)),
    NvidiaGPUInfo(name="H100NVL", memory=94, compute_capability=(9, 0)),
    NvidiaGPUInfo(name="L4", memory=24, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="L40", memory=48, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="L40S", memory=48, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="P100", memory=16, compute_capability=(6, 0)),
    NvidiaGPUInfo(name="RTX3060", memory=8, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3060", memory=12, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3060Ti", memory=8, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3070Ti", memory=8, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3080", memory=10, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3080Ti", memory=12, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX3090", memory=24, compute_capability=(8, 6)),
    NvidiaGPUInfo(name="RTX4090", memory=24, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="RTX6000", memory=24, compute_capability=(7, 5)),
    NvidiaGPUInfo(name="RTX2000Ada", memory=16, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="RTX4000Ada", memory=20, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="RTX6000Ada", memory=48, compute_capability=(8, 9)),
    NvidiaGPUInfo(name="T4", memory=16, compute_capability=(7, 5)),
    NvidiaGPUInfo(name="V100", memory=16, compute_capability=(7, 0)),
    NvidiaGPUInfo(name="V100", memory=32, compute_capability=(7, 0)),
]

KNOWN_AMD_GPUS: list[AMDGPUInfo] = [
    AMDGPUInfo(name="MI100", memory=32, architecture=AMDArchitecture.CDNA),
    AMDGPUInfo(name="MI210", memory=64, architecture=AMDArchitecture.CDNA2),
    AMDGPUInfo(name="MI250", memory=128, architecture=AMDArchitecture.CDNA2),
    AMDGPUInfo(name="MI250X", memory=128, architecture=AMDArchitecture.CDNA2),
    AMDGPUInfo(name="MI300A", memory=128, architecture=AMDArchitecture.CDNA3),
    AMDGPUInfo(name="MI300X", memory=192, architecture=AMDArchitecture.CDNA3),
    AMDGPUInfo(name="MI308X", memory=128, architecture=AMDArchitecture.CDNA3),
    AMDGPUInfo(name="MI325X", memory=288, architecture=AMDArchitecture.CDNA3),
]

KNOWN_TPUS: list[TPUInfo] = [TPUInfo(name=version, memory=0) for version in _TPU_VERSIONS]

KNOWN_ACCELERATORS: list[Union[NvidiaGPUInfo, AMDGPUInfo, TPUInfo]] = (
    KNOWN_NVIDIA_GPUS + KNOWN_AMD_GPUS + KNOWN_TPUS
)

================
File: gpuhunt/src/gpuhunt/_internal/default.py
================
import functools
import importlib
import logging
from typing import Callable, TypeVar

from typing_extensions import Concatenate, ParamSpec

from gpuhunt._internal.catalog import Catalog

logger = logging.getLogger(__name__)


@functools.lru_cache
def default_catalog() -> Catalog:
    """
    Returns:
        the latest catalog with all available providers loaded
    """
    catalog = Catalog()
    catalog.load()
    for module, provider in [
        ("gpuhunt.providers.tensordock", "TensorDockProvider"),
        ("gpuhunt.providers.vastai", "VastAIProvider"),
        ("gpuhunt.providers.cudo", "CudoProvider"),
        ("gpuhunt.providers.vultr", "VultrProvider"),
    ]:
        try:
            module = importlib.import_module(module)
            provider = getattr(module, provider)()
            catalog.add_provider(provider)
        except ImportError:
            logger.warning("Failed to import provider %s", provider)
    return catalog


P = ParamSpec("P")
R = TypeVar("R")
Method = Callable[P, R]
CatalogMethod = Callable[Concatenate[Catalog, P], R]


def with_signature(method: CatalogMethod) -> Callable[[Method], Method]:
    """
    Returns:
        decorator to add the signature of the Catalog method to the decorated method
    """

    def decorator(func: Method) -> Method:
        @functools.wraps(func)
        def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
            return func(*args, **kwargs)

        return wrapper

    return decorator


@with_signature(Catalog.query)
def query(*args: P.args, **kwargs: P.kwargs) -> R:
    """
    Query the `default_catalog`.
    See `Catalog.query` for more details on parameters

    Returns:
        (List[CatalogItem]): the result of the query
    """
    return default_catalog().query(*args, **kwargs)

================
File: gpuhunt/src/gpuhunt/_internal/models.py
================
import enum
from dataclasses import asdict, dataclass, fields
from typing import (
    ClassVar,
    Optional,
    Union,
)

from gpuhunt._internal.utils import empty_as_none


def bool_loader(x: Union[bool, str]) -> bool:
    if isinstance(x, bool):
        return x
    return x.lower() == "true"


class AMDArchitecture(enum.Enum):
    CDNA = "CDNA"
    CDNA2 = "CDNA2"
    CDNA3 = "CDNA3"

    @classmethod
    def cast(cls, value: Union["AMDArchitecture", str]) -> "AMDArchitecture":
        if isinstance(value, AMDArchitecture):
            return value
        return cls(value.upper())


class AcceleratorVendor(enum.Enum):
    NVIDIA = "nvidia"
    AMD = "amd"
    GOOGLE = "google"

    @classmethod
    def cast(cls, value: Union["AcceleratorVendor", str]) -> "AcceleratorVendor":
        if isinstance(value, AcceleratorVendor):
            return value
        return cls(value.lower())


@dataclass
class RawCatalogItem:
    instance_name: Optional[str]
    location: Optional[str]
    price: Optional[float]
    cpu: Optional[int]
    memory: Optional[float]
    gpu_count: Optional[int]
    gpu_name: Optional[str]
    gpu_memory: Optional[float]
    spot: Optional[bool]
    disk_size: Optional[float]
    gpu_vendor: Optional[str] = None

    def __post_init__(self) -> None:
        # This heuristic will be required indefinitely since we support historical catalogs.
        is_tpu = False
        gpu_name = self.gpu_name
        if gpu_name and gpu_name.startswith("tpu-"):
            is_tpu = True
            self.gpu_name = gpu_name[4:]
        gpu_vendor = self.gpu_vendor
        if gpu_vendor is None:
            if not self.gpu_count:
                # None or 0
                return
            if is_tpu:
                self.gpu_vendor = AcceleratorVendor.GOOGLE.value
            else:
                self.gpu_vendor = AcceleratorVendor.NVIDIA.value
        elif isinstance(gpu_vendor, AcceleratorVendor):
            self.gpu_vendor = gpu_vendor.value

    @staticmethod
    def from_dict(v: dict) -> "RawCatalogItem":
        return RawCatalogItem(
            instance_name=empty_as_none(v.get("instance_name")),
            location=empty_as_none(v.get("location")),
            price=empty_as_none(v.get("price"), loader=float),
            cpu=empty_as_none(v.get("cpu"), loader=int),
            memory=empty_as_none(v.get("memory"), loader=float),
            gpu_vendor=empty_as_none(v.get("gpu_vendor")),
            gpu_count=empty_as_none(v.get("gpu_count"), loader=int),
            gpu_name=empty_as_none(v.get("gpu_name")),
            gpu_memory=empty_as_none(v.get("gpu_memory"), loader=float),
            spot=empty_as_none(v.get("spot"), loader=bool_loader),
            disk_size=empty_as_none(v.get("disk_size"), loader=float),
        )

    def dict(self) -> dict[str, Union[str, int, float, bool, None]]:
        return asdict(self)


@dataclass
class CatalogItem:
    """
    Attributes:
        instance_name: name of the instance
        location: region or zone
        price: $ per hour
        cpu: number of CPUs
        memory: amount of RAM in GB
        gpu_count: number of GPUs
        gpu_name: name of the GPU
        gpu_memory: amount of GPU VRAM in GB for each GPU
        spot: whether the instance is a spot instance
        provider: name of the provider
        disk_size: size of disk in GB
    """

    instance_name: str
    location: str
    price: float
    cpu: int
    memory: float
    gpu_count: int
    gpu_name: Optional[str]
    gpu_memory: Optional[float]
    spot: bool
    disk_size: Optional[float]
    provider: str
    gpu_vendor: Optional[AcceleratorVendor] = None

    def __post_init__(self) -> None:
        gpu_vendor = self.gpu_vendor
        if gpu_vendor is None:
            # This heuristic is only required until we update all providers to always set
            # the vendor.
            if not self.gpu_count:
                # None or 0
                return
            # GCPProvider already sets gpu_vendor, and all other providers only support Nvidia
            self.gpu_vendor = AcceleratorVendor.NVIDIA
        else:
            # This cast to the enum is always required since RawCatalogItem.gpu_vendor
            # is a string field (for (de)serialization purposes).
            self.gpu_vendor = AcceleratorVendor.cast(gpu_vendor)

    @staticmethod
    def from_dict(v: dict, *, provider: Optional[str] = None) -> "CatalogItem":
        return CatalogItem(provider=provider, **asdict(RawCatalogItem.from_dict(v)))


@dataclass
class QueryFilter:
    """
    Attributes:
        provider: name of the provider to filter by. If not specified, all providers will be used
        min_cpu: minimum number of CPUs
        max_cpu: maximum number of CPUs
        min_memory: minimum amount of RAM in GB
        max_memory: maximum amount of RAM in GB
        min_gpu_count: minimum number of GPUs
        max_gpu_count: maximum number of GPUs
        gpu_vendor: accelerator vendor to filter by. If not specified, all vendors will be used
        gpu_name: name of the GPU to filter by. If not specified, all GPUs will be used
        min_gpu_memory: minimum amount of GPU VRAM in GB for each GPU
        max_gpu_memory: maximum amount of GPU VRAM in GB for each GPU
        min_total_gpu_memory: minimum amount of GPU VRAM in GB for all GPUs combined
        max_total_gpu_memory: maximum amount of GPU VRAM in GB for all GPUs combined
        min_disk_size: minimum disk size in GB
        max_disk_size: maximum disk size in GB
        min_price: minimum price per hour in USD
        max_price: maximum price per hour in USD
        min_compute_capability: minimum compute capability of the GPU
        max_compute_capability: maximum compute capability of the GPU
        spot: if `False`, only ondemand offers will be returned. If `True`, only spot offers will be returned
    """

    provider: Optional[list[str]] = None  # strings can have mixed case
    min_cpu: Optional[int] = None
    max_cpu: Optional[int] = None
    min_memory: Optional[float] = None
    max_memory: Optional[float] = None
    min_gpu_count: Optional[int] = None
    max_gpu_count: Optional[int] = None
    gpu_vendor: Optional[AcceleratorVendor] = None
    gpu_name: Optional[list[str]] = None  # strings can have mixed case
    min_gpu_memory: Optional[float] = None
    max_gpu_memory: Optional[float] = None
    min_total_gpu_memory: Optional[float] = None
    max_total_gpu_memory: Optional[float] = None
    min_disk_size: Optional[int] = None
    max_disk_size: Optional[int] = None
    min_price: Optional[float] = None
    max_price: Optional[float] = None
    min_compute_capability: Optional[tuple[int, int]] = None
    max_compute_capability: Optional[tuple[int, int]] = None
    spot: Optional[bool] = None

    def __repr__(self) -> str:
        """
        >>> QueryFilter()
        QueryFilter()
        >>> QueryFilter(min_cpu=4)
        QueryFilter(min_cpu=4)
        >>> QueryFilter(max_price=1.2, min_cpu=4)
        QueryFilter(min_cpu=4, max_price=1.2)
        """
        kv = ", ".join(
            f"{f.name}={value}"
            for f in fields(self)
            if (value := getattr(self, f.name)) is not None
        )
        return f"QueryFilter({kv})"


@dataclass
class AcceleratorInfo:
    vendor: ClassVar[AcceleratorVendor]
    name: str
    memory: int


@dataclass
class NvidiaGPUInfo(AcceleratorInfo):
    vendor = AcceleratorVendor.NVIDIA
    compute_capability: tuple[int, int]


@dataclass
class AMDGPUInfo(AcceleratorInfo):
    vendor = AcceleratorVendor.AMD
    architecture: AMDArchitecture


@dataclass
class TPUInfo(AcceleratorInfo):
    vendor = AcceleratorVendor.GOOGLE

================
File: gpuhunt/src/gpuhunt/_internal/storage.py
================
import csv
import dataclasses
from collections.abc import Iterable
from typing import TypeVar

from gpuhunt._internal.models import RawCatalogItem

T = TypeVar("T", bound=RawCatalogItem)


def dump(items: list[T], path: str, *, cls: type[T] = RawCatalogItem):
    with open(path, "w", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=[field.name for field in dataclasses.fields(cls)])
        writer.writeheader()
        for item in items:
            writer.writerow(item.dict())


def load(path: str, *, cls: type[T] = RawCatalogItem) -> list[T]:
    items = []
    with open(path, newline="") as f:
        reader: Iterable[dict[str, str]] = csv.DictReader(f)
        for row in reader:
            item = cls.from_dict(row)
            items.append(item)
    return items

================
File: gpuhunt/src/gpuhunt/_internal/utils.py
================
from typing import Callable, Optional, Union


def empty_as_none(value: Optional[str], loader: Optional[Callable] = None):
    if value is None or value == "":
        return None
    if loader is not None:
        return loader(value)
    return value


def parse_compute_capability(
    value: Optional[Union[str, tuple[int, int]]],
) -> Optional[tuple[int, int]]:
    if isinstance(value, str):
        major, minor = value.split(".")
        return int(major), int(minor)
    return value


def to_camel_case(snake_case: str) -> str:
    words = snake_case.split("_")
    words = list(filter(None, words))
    words[1:] = [word[:1].upper() + word[1:] for word in words[1:]]
    return "".join(words)

================
File: gpuhunt/src/gpuhunt/providers/__init__.py
================
from abc import ABC, abstractmethod
from typing import Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem


class AbstractProvider(ABC):
    NAME: str = "abstract"

    @abstractmethod
    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        pass

    @classmethod
    def filter(cls, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        return offers

================
File: gpuhunt/src/gpuhunt/providers/aws.py
================
import copy
import csv
import datetime
import logging
import os
import re
import tempfile
from collections import defaultdict
from collections.abc import Iterable
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Optional

import boto3
import requests
from botocore.exceptions import ClientError, EndpointConnectionError

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
ec2_pricing_url = (
    "https://pricing.us-east-1.amazonaws.com/offers/v1.0/aws/AmazonEC2/current/index.csv"
)
disclaimer_rows_skip = 5
# https://aws.amazon.com/ec2/previous-generation/
previous_generation_families = [
    "a1.",
    "c1.",
    "c3.",
    "c4.",
    "g2.",
    "g3.",
    "g3s.",
    "i2.",
    "m1.",
    "m2.",
    "m3.",
    "r3.",
    "r4.",
    "t1.",
    "cr1.",
    "hs1.",
]
pricing_filters = {
    "TermType": ["OnDemand"],
    "Tenancy": ["Shared"],
    "Operating System": ["Linux"],
    "CapacityStatus": ["Used"],
    "Unit": ["Hrs"],
    "Currency": ["USD"],
    "Pre Installed S/W": ["", "NA"],
    "MarketOption": ["OnDemand"],
}
describe_instances_limit = 100


class AWSProvider(AbstractProvider):
    """
    AWSProvider parses Bulk API index file for AmazonEC2 in all regions and fills missing GPU details

    Required IAM permissions:
    * `ec2:DescribeInstanceTypes`
    """

    NAME = "aws"

    def __init__(self, cache_path: Optional[str] = None):
        if cache_path:
            self.cache_path = cache_path
        else:
            self.temp_dir = tempfile.TemporaryDirectory()
            self.cache_path = self.temp_dir.name + "/index.csv"
        # todo aws creds
        self.preview_gpus = {
            "p4de.24xlarge": ("A100", 80.0),
        }

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        if not os.path.exists(self.cache_path):
            logger.info("Downloading EC2 prices to %s", self.cache_path)
            with requests.get(ec2_pricing_url, stream=True, timeout=20) as r:
                r.raise_for_status()
                with open(self.cache_path, "wb") as f:
                    for chunk in r.iter_content(chunk_size=8192):
                        f.write(chunk)

        offers = []
        with open(self.cache_path, newline="") as f:
            for _ in range(disclaimer_rows_skip):
                f.readline()
            reader: Iterable[dict[str, str]] = csv.DictReader(f)
            for row in reader:
                if self.skip(row):
                    continue
                offer = RawCatalogItem(
                    instance_name=row["Instance Type"],
                    location=row["Region Code"],
                    price=float(row["PricePerUnit"]),
                    cpu=int(row["vCPU"]),
                    memory=parse_memory(row["Memory"]),
                    gpu_vendor=None,
                    gpu_count=parse_optional_count(row["GPU"]),
                    spot=False,
                    gpu_name=None,
                    gpu_memory=None,
                    disk_size=None,
                )
                offers.append(offer)
        self.fill_gpu_details(offers)
        offers = self.add_spots(offers)
        return sorted(offers, key=lambda i: i.price)

    def skip(self, row: dict[str, str]) -> bool:
        if any(row["Instance Type"].startswith(family) for family in previous_generation_families):
            return True
        for key, values in pricing_filters.items():
            if row[key] not in values:
                return True
        return False

    def fill_gpu_details(self, offers: list[RawCatalogItem]):
        regions = defaultdict(list)
        for offer in offers:
            if offer.gpu_count > 0 and offer.instance_name not in self.preview_gpus:
                regions[offer.location].append(offer.instance_name)

        gpus = copy.deepcopy(self.preview_gpus)
        while regions:
            region = max(regions, key=lambda r: len(regions[r]))
            instance_types = regions.pop(region)

            client = boto3.client("ec2", region_name=region)
            paginator = client.get_paginator("describe_instance_types")
            for offset in range(0, len(instance_types), describe_instances_limit):
                logger.info("Fetching GPU details for %s (offset=%s)", region, offset)
                pages = paginator.paginate(
                    InstanceTypes=instance_types[offset : offset + describe_instances_limit]
                )
                for page in pages:
                    for i in page["InstanceTypes"]:
                        gpu = i["GpuInfo"]["Gpus"][0]
                        gpus[i["InstanceType"]] = (
                            gpu["Name"],
                            _get_gpu_memory_gib(gpu["Name"], gpu["MemoryInfo"]["SizeInMiB"]),
                        )

            regions = {
                region: left
                for region, names in regions.items()
                if (left := [i for i in names if i not in instance_types])
            }

        for offer in offers:
            if offer.gpu_count > 0:
                offer.gpu_name, offer.gpu_memory = gpus[offer.instance_name]

    def _add_spots_worker(
        self, region: str, instance_types: set[str]
    ) -> dict[tuple[str, str], float]:
        spot_prices = dict()
        logger.info("Fetching spot prices for %s", region)
        try:
            client = boto3.client("ec2", region_name=region)  # todo creds
            pages = client.get_paginator("describe_spot_price_history").paginate(
                Filters=[
                    {
                        "Name": "product-description",
                        "Values": ["Linux/UNIX"],
                    }
                ],
                InstanceTypes=list(instance_types),
                StartTime=datetime.datetime.utcnow(),
            )

            instance_prices = defaultdict(list)
            for page in pages:
                for item in page["SpotPriceHistory"]:
                    instance_prices[item["InstanceType"]].append(float(item["SpotPrice"]))
            for (
                instance_type,
                zone_prices,
            ) in instance_prices.items():  # reduce zone prices to a single value
                spot_prices[(instance_type, region)] = min(zone_prices)
        except (ClientError, EndpointConnectionError):
            return {}
        return spot_prices

    def add_spots(self, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        region_instances = defaultdict(set)
        for offer in offers:
            region_instances[offer.location].add(offer.instance_name)

        spot_prices = dict()
        with ThreadPoolExecutor(max_workers=8) as executor:
            future_to_region = {}
            for region, instance_types in region_instances.items():
                future = executor.submit(self._add_spots_worker, region, instance_types)
                future_to_region[future] = region
            for future in as_completed(future_to_region):
                spot_prices.update(future.result())

        spot_offers = []
        for offer in offers:
            if (price := spot_prices.get((offer.instance_name, offer.location))) is None:
                continue
            spot_offer = copy.deepcopy(offer)
            spot_offer.spot = True
            spot_offer.price = price
            spot_offers.append(spot_offer)
        return offers + spot_offers

    @classmethod
    def filter(cls, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        return [
            i
            for i in offers
            if any(
                i.instance_name.startswith(family)
                for family in [
                    "t2.small",
                    "c5.",
                    "m5.",
                    "p3.",
                    "p5.",
                    "p5e.",
                    "g5.",
                    "g6.",
                    "g6e.",
                    "gr6.",
                    "g4dn.",
                    "p4d.",
                    "p4de.",
                ]
            )
        ]


def _get_gpu_memory_gib(gpu_name: str, reported_memory_mib: int) -> float:
    """
    Fixes L4 memory size misreported by AWS API
    """

    if gpu_name != "L4":
        return reported_memory_mib / 1024

    if reported_memory_mib not in (22888, 91553, 183105):
        logger.warning(
            "The L4 memory size reported by AWS changed. "
            "Please check that it is now correct and remove the hardcoded size if it is."
        )
    return 24


def parse_memory(s: str) -> float:
    r = re.match(r"^([0-9.]+) GiB$", s)
    return float(r.group(1))


def parse_optional_count(s: str) -> int:
    if not s:
        return 0
    return int(s)

================
File: gpuhunt/src/gpuhunt/providers/azure.py
================
import json
import logging
import math
import os
import re
import time
from collections import namedtuple
from collections.abc import Iterable
from queue import Queue
from threading import Thread
from typing import Optional

import requests
import requests.adapters
from azure.core.credentials import TokenCredential
from azure.identity import DefaultAzureCredential
from azure.mgmt.compute import ComputeManagementClient

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
prices_url = "https://prices.azure.com/api/retail/prices"
retail_prices_page_size = 1000
prices_version = "2023-01-01-preview"
prices_filters = [
    "serviceName eq 'Virtual Machines'",
    "priceType eq 'Consumption'",
    "contains(productName, 'Windows') eq false",
    "contains(productName, 'Dedicated') eq false",
    "contains(meterName, 'Low Priority') eq false",  # retires in 2025
]
VMSeries = namedtuple("VMSeries", ["pattern", "gpu_name", "gpu_memory"])
gpu_vm_series = [
    VMSeries(r"NC(\d+)ads_A100_v4", "A100", 80.0),  # NC A100 v4-series [A100 80GB]
    VMSeries(r"NC(\d+)ads_A10_v4", "A10", 24.0),  # NC A10 v4-series [A10]
    VMSeries(r"NC(\d+)as_T4_v3", "T4", 16.0),  # NCasT4_v3-series [T4]
    VMSeries(r"NC(\d+)r?s_v3", "V100", 16.0),  # NCv3-series [V100 16GB]
    VMSeries(r"ND(\d+)amsr_A100_v4", "A100", 80.0),  # NDm A100 v4-series [8xA100 80GB]
    VMSeries(r"ND(\d+)asr_v4", "A100", 40.0),  # ND A100 v4-series [8xA100 40GB]
    VMSeries(r"ND(\d+)rs_v2", "V100", 32.0),  # NDv2-series [8xV100 32GB]
    VMSeries(r"NG(\d+)adm?s_V620_v1", "V620", None),  # NGads V620-series [V620]  # todo
    VMSeries(r"NV(\d+)adm?s_A10_v5", "A10", 24.0),  # NVadsA10 v5-series [A10]
    VMSeries(r"NV(\d+)as_v4", "MI25", None),  # NVv4-series [MI25]  # todo
    VMSeries(r"NV(\d+)s_v3", "M60", None),  # NVv3-series [M60]  # todo
]
# https://learn.microsoft.com/en-us/azure/virtual-machines/sizes-previous-gen
retired_vm_series = [
    r"Basic_A(\d+)",
    r"Standard_A(\d+)",
    r"Standard_D(\d+)",
    r"Standard_DC(\d+)s",
    r"Standard_DS(\d+)",
    r"Standard_F(\d+)",
    r"Standard_F(\d+)s",
    r"Standard_G(\d+)",
    r"Standard_GS(\d+)",
    r"Standard_L(\d+)s",
    r"Standard_NC(\d+)r?",
    r"Standard_NC(\d+)r?s_v2",
    r"Standard_ND(\d+)r?s",
    r"Standard_NV(\d+)",
    r"Standard_NV(\d+)s_v2",
]


class AzureProvider(AbstractProvider):
    NAME = "azure"

    def __init__(
        self,
        subscription_id: str,
        credential: Optional[TokenCredential] = None,
        cache_dir: Optional[str] = None,
    ):
        self.cache_dir = cache_dir
        self.client = ComputeManagementClient(
            credential=credential or DefaultAzureCredential(),
            subscription_id=subscription_id,
        )

    def get_pages(self, threads: int = 8) -> Iterable[list[dict]]:
        q = Queue()
        workers = [
            Thread(target=self._get_pages_worker, args=(q, threads, i), daemon=True)
            for i in range(threads)
        ]
        for worker in workers:
            worker.start()

        exited = 0
        while exited < threads:
            page = q.get()
            if page is None:
                exited += 1
            else:
                yield page
            q.task_done()

    def _get_pages_worker(self, q: Queue, stride: int, worker_id: int):
        page_id = worker_id
        session = requests.Session()
        session.mount("https://", requests.adapters.HTTPAdapter(max_retries=3))
        try:
            while True:
                cached_page = None
                if self.cache_dir is not None:
                    cached_page = os.path.join(self.cache_dir, f"{page_id:04}.json")
                if cached_page is not None and os.path.exists(cached_page):
                    with open(cached_page) as f:
                        data = json.load(f)
                else:
                    logger.info("Worker %s fetches pricing page %s", worker_id, page_id)
                    res = session.get(
                        prices_url,
                        params={
                            "api-version": "2023-01-01-preview",
                            "$filter": " and ".join(prices_filters),
                            "$skip": page_id * retail_prices_page_size,
                        },
                    )
                    if res.status_code == 429:
                        logger.warning("Worker %s got 429: sleep 3 & retry", worker_id)
                        time.sleep(3)
                        continue
                    res.raise_for_status()
                    if cached_page is not None:
                        with open(cached_page, "w") as f:
                            f.write(res.text)
                    data = res.json()
                if not data["Items"]:
                    logger.info("Worker %s exited", worker_id)
                    return
                q.put(data["Items"])
                page_id += stride
        except Exception as e:
            logger.exception("Worker %s failed: %s", worker_id, e)
        finally:
            q.put(None)

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        offers = []
        for page in self.get_pages():
            for item in page:
                if is_retired(item["armSkuName"]):
                    continue
                if not item["armSkuName"]:
                    continue
                price = float(item["retailPrice"])
                if math.isclose(price, 0):
                    continue
                offer = RawCatalogItem(
                    instance_name=item["armSkuName"],
                    location=item["armRegionName"],
                    price=price,
                    spot="Spot" in item["meterName"],
                    cpu=None,
                    memory=None,
                    gpu_vendor=None,
                    gpu_count=None,
                    gpu_name=None,
                    gpu_memory=None,
                    disk_size=None,
                )
                offers.append(offer)
        offers = self.fill_details(offers)
        return sorted(offers, key=lambda i: i.price)

    def fill_details(self, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        logger.info("Fetching instance details")
        instances = {}
        resources = self.client.resource_skus.list()
        for resource in resources:
            if resource.resource_type != "virtualMachines":
                continue
            if is_retired(resource.name):
                continue
            capabilities = {pair.name: pair.value for pair in resource.capabilities}
            gpu_count, gpu_name, gpu_memory = 0, None, None
            if "GPUs" in capabilities:
                gpu_count = int(capabilities["GPUs"])
                gpu_name, gpu_memory = get_gpu_name_memory(resource.name)
                if gpu_name is None and gpu_count:
                    logger.warning("Can't parse VM name: %s", resource.name)
                    continue
            instances[resource.name] = RawCatalogItem(
                instance_name=resource.name,
                cpu=capabilities["vCPUs"],
                memory=float(capabilities["MemoryGB"]),
                gpu_vendor=None,
                gpu_count=gpu_count,
                gpu_name=gpu_name,
                gpu_memory=gpu_memory,
                location=None,
                price=None,
                spot=None,
                disk_size=None,
            )
        with_details = []
        without_details = []
        for offer in offers:
            if (resources := instances.get(offer.instance_name)) is None:
                without_details.append(offer)
                continue
            offer.cpu = resources.cpu
            offer.memory = resources.memory
            offer.gpu_count = resources.gpu_count
            offer.gpu_name = resources.gpu_name
            offer.gpu_memory = resources.gpu_memory
            with_details.append(offer)
        return with_details + without_details

    @classmethod
    def filter(cls, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        vm_series = [
            VMSeries(r"D(\d+)s_v3", None, None),  # Dsv3-series
            VMSeries(r"E(\d+)i?s_v4", None, None),  # Esv4-series
            VMSeries(r"E(\d+)-(\d+)s_v4", None, None),  # Esv4-series (constrained vCPU)
            VMSeries(r"NC(\d+)s_v3", "V100", 16 * 1024),  # NCv3-series [V100 16GB]
            VMSeries(r"NC(\d+)as_T4_v3", "T4", 16 * 1024),  # NCasT4_v3-series [T4]
            VMSeries(r"ND(\d+)rs_v2", "V100", 32 * 1024),  # NDv2-series [8xV100 32GB]
            VMSeries(r"NV(\d+)adm?s_A10_v5", "A10", 24 * 1024),  # NVadsA10 v5-series [A10]
            VMSeries(r"NC(\d+)ads_A100_v4", "A100", 80 * 1024),  # NC A100 v4-series [A100 80GB]
            VMSeries(r"ND(\d+)asr_v4", "A100", 40 * 1024),  # ND A100 v4-series [8xA100 40GB]
            VMSeries(
                r"ND(\d+)amsr_A100_v4", "A100", 80 * 1024
            ),  # NDm A100 v4-series [8xA100 80GB]
        ]
        vm_series_pattern = re.compile(
            f"^Standard_({'|'.join(series.pattern for series in vm_series)})$"
        )
        return [i for i in offers if vm_series_pattern.match(i.instance_name)]


def get_gpu_name_memory(vm_name: str) -> tuple[Optional[str], Optional[float]]:
    for pattern, gpu_name, gpu_memory in gpu_vm_series:
        m = re.match(f"^Standard_{pattern}$", vm_name)
        if m is None:
            continue
        if gpu_name == "A10" and vm_name.endswith("_v4"):
            gpu_memory = gpu_memory * min(1.0, int(m.group(1)) / 16)
        elif gpu_name == "A10" and vm_name.endswith("_v5"):
            gpu_memory = gpu_memory * min(1.0, int(m.group(1)) / 36)

        return gpu_name, gpu_memory
    return None, None


def is_retired(name: str) -> bool:
    if re.match(f"^({'|'.join(retired_vm_series)})$", name):
        return True
    return False

================
File: gpuhunt/src/gpuhunt/providers/crusoe.py
================
import logging
from typing import List, Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers.scraper import ScraperProvider

logger = logging.getLogger(__name__)

class CrusoeProvider(ScraperProvider):
    """Provider for Crusoe Cloud GPU instances using web scraping"""
    
    NAME = "crusoe"

    def __init__(self):
        super().__init__()

    @property
    def urls(self) -> List[str]:
        return ["https://crusoe.ai/cloud/"]

    @property
    def prompt(self) -> str:
        return """
        Extract all GPU instances from the Crusoe Cloud pricing page. For each GPU instance, provide:
        1. GPU model name (e.g. H100, A100) - remove any vendor prefix
        2. GPU memory in GB (as a number)
        3. Number of GPUs per instance (as a number)
        4. Price per hour in USD (as a number)
        5. Location (set to "US" as all instances are in US)
        6. Number of CPU cores (as a number)
        7. System RAM in GB (as a number)
        8. Disk size in GB if available (as a number)

        Important:
        - Return ALL GPU instances you find
        - All numeric values should be numbers, not strings
        - Look for pricing information in USD per hour
        - The vendor is always "NVIDIA"
        - If memory/CPU/RAM information is not provided, set to 0
        
        Return the data in this format:
        {
          "gpus": [
            {
              "name": "H100",
              "memory": 80,
              "count": 8,
              "price": 25.00,
              "location": "US",
              "cpu": 0,
              "ram": 0,
              "disk": 0,
              "spot": false,
              "vendor": "NVIDIA"
            },
            ... additional GPUs ...
          ]
        }
        """

================
File: gpuhunt/src/gpuhunt/providers/cudo.py
================
import logging
import math
from collections import namedtuple
from itertools import chain
from math import ceil
from typing import Optional, TypeVar, Union

import requests

from gpuhunt import QueryFilter, RawCatalogItem
from gpuhunt._internal.constraints import KNOWN_NVIDIA_GPUS, get_compute_capability, is_between
from gpuhunt.providers import AbstractProvider

CpuMemoryGpu = namedtuple("CpuMemoryGpu", ["cpu", "memory", "gpu"])
logger = logging.getLogger(__name__)

API_URL = "https://rest.compute.cudo.org/v1"
MIN_CPU = 2
MIN_MEMORY = 8
RAM_PER_VRAM = 2
RAM_DIV = 2
CPU_DIV = 2
RAM_PER_CORE = 4
MIN_DISK_SIZE = 100


class CudoProvider(AbstractProvider):
    NAME = "cudo"

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        offers = self.fetch_offers(query_filter, balance_resources)
        offers = get_min_price_for_location_and_instance(offers)
        return sorted(offers, key=lambda i: i.price)

    def fetch_offers(
        self, query_filter: Optional[QueryFilter], balance_resources
    ) -> list[RawCatalogItem]:
        machine_types = self.list_vm_machine_types()
        if query_filter is not None:
            return self.optimize_offers(machine_types, query_filter, balance_resources)
        else:
            offers = []
            for machine_type in machine_types:
                gpu_model_name = gpu_name(machine_type["gpuModel"])
                if gpu_model_name is None:
                    continue
                gpu_memory_size = get_memory(gpu_model_name)
                if gpu_memory_size is None:
                    continue
                machine_type["gpu_name"] = gpu_model_name
                machine_type["gpu_memory"] = gpu_memory_size
                optimized_specs = optimize_offers_with_gpu(
                    QueryFilter(), machine_type, balance_resources=False
                )
                raw_catalogs = [get_raw_catalog(machine_type, spec) for spec in optimized_specs]
                offers.append(raw_catalogs)
            return list(chain.from_iterable(offers))

    @staticmethod
    def list_vm_machine_types() -> dict:
        resp = requests.request(
            method="GET",
            url=f"{API_URL}/vms/machine-types-2",
            timeout=10,
        )
        if resp.ok:
            data = resp.json()
            return data["machineTypes"]
        resp.raise_for_status()

    @staticmethod
    def optimize_offers(machine_types, q: QueryFilter, balance_resource) -> list[RawCatalogItem]:
        offers = []

        # Empty query, example: QureyFilter(provider="cudo")
        get_all_offers = all(
            condition is None
            for condition in (
                q.min_gpu_count,
                q.max_gpu_count,
                q.min_total_gpu_memory,
                q.max_total_gpu_memory,
                q.min_gpu_memory,
                q.max_gpu_memory,
                q.gpu_name,
            )
        )

        has_significant_gpu_filter = any(
            condition is not None
            for condition in (
                q.min_gpu_count or None,
                q.max_gpu_count or None,
                q.min_total_gpu_memory or None,
                q.max_total_gpu_memory or None,
                q.min_gpu_memory or None,
                q.max_gpu_memory or None,
                q.gpu_name or None,
            )
        )

        if has_significant_gpu_filter or get_all_offers:
            # filter offers with gpus
            gpu_machine_types = [
                vm for vm in machine_types if vm["maxGpuFree"] != 0 and vm["gpuModelId"]
            ]
            for machine_type in gpu_machine_types:
                gpu_model_name = gpu_name(machine_type["gpuModel"])
                if gpu_model_name is None:
                    continue
                gpu_memory_size = get_memory(gpu_model_name)
                if gpu_memory_size is None:
                    continue
                machine_type["gpu_name"] = gpu_model_name
                machine_type["gpu_memory"] = gpu_memory_size
                if not is_between(
                    machine_type["gpu_memory"], q.min_gpu_memory, q.max_total_gpu_memory
                ):
                    continue
                if q.gpu_name is not None and machine_type["gpu_name"].lower() not in map(
                    str.lower, q.gpu_name
                ):
                    continue
                cc = get_compute_capability(machine_type["gpu_name"])
                if not cc or not is_between(
                    cc, q.min_compute_capability, q.max_compute_capability
                ):
                    continue
                optimized_specs = optimize_offers_with_gpu(q, machine_type, balance_resource)
                raw_catalogs = [get_raw_catalog(machine_type, spec) for spec in optimized_specs]
                offers.append(raw_catalogs)

        include_cpu_offers = any(
            (
                q.min_gpu_count == 0,
                (q.min_total_gpu_memory == 0) if q.min_total_gpu_memory is not None else False,
                q.min_gpu_memory == 0,
            )
        )

        if not has_significant_gpu_filter or get_all_offers or include_cpu_offers:
            cpu_only_machine_types = [
                vm for vm in machine_types if vm["maxVcpuFree"] != 0 and not vm["gpuModelId"]
            ]
            for machine_type in cpu_only_machine_types:
                optimized_specs = optimize_offers_no_gpu(q, machine_type, balance_resource)
                raw_catalogs = [get_raw_catalog(machine_type, spec) for spec in optimized_specs]
                offers.append(raw_catalogs)

        return list(chain.from_iterable(offers))


def get_raw_catalog(machine_type, spec):
    raw = RawCatalogItem(
        instance_name=machine_type["machineType"],
        location=machine_type["dataCenterId"],
        spot=False,
        price=round(
            math.fsum(
                (
                    float(machine_type["vcpuPriceHr"]["value"]) * spec["cpu"],
                    float(machine_type["memoryGibPriceHr"]["value"]) * spec["memory"],
                    float(machine_type["gpuPriceHr"]["value"]) * spec.get("gpu", 0),
                    float(machine_type["minStorageGibPriceHr"]["value"]) * spec["disk_size"],
                    float(machine_type["ipv4PriceHr"]["value"]),
                )
            ),
            5,
        ),
        cpu=spec["cpu"],
        memory=spec["memory"],
        gpu_vendor=None,
        gpu_count=spec.get("gpu", 0),
        gpu_name=machine_type.get("gpu_name", ""),
        gpu_memory=machine_type.get("gpu_memory", 0),
        disk_size=spec["disk_size"],
    )
    return raw


def get_min_price_for_location_and_instance(offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
    """
    Returns offers with the minimum price for each unique combination
    of location and instance name.
    """
    min_price_offers = {}
    for offer in offers:
        key = (offer.location, offer.instance_name)
        if key not in min_price_offers or offer.price < min_price_offers[key].price:
            min_price_offers[key] = offer
    return list(min_price_offers.values())


def optimize_offers_with_gpu(q: QueryFilter, machine_type, balance_resources: bool):
    # Generate ranges for CPU, GPU, and memory based on the specified minimums, maximums, and available resources
    cpu_range = get_cpu_range(q.min_cpu, q.max_cpu, machine_type["maxVcpuFree"])
    gpu_range = get_gpu_range(q.min_gpu_count, q.max_gpu_count, machine_type["maxGpuFree"])
    memory_range = get_memory_range(q.min_memory, q.max_memory, machine_type["maxMemoryGibFree"])
    min_vcpu_per_memory_gib = machine_type.get("minVcpuPerMemoryGib", 0)
    max_vcpu_per_memory_gib = machine_type.get("maxVcpuPerMemoryGib", float("inf"))
    min_vcpu_per_gpu = machine_type.get("minVcpuPerGpu", 0)
    max_vcpu_per_gpu = machine_type.get("maxVcpuPerGpu", float("inf"))
    unbalanced_specs = []
    for cpu in cpu_range:
        for gpu in gpu_range:
            for memory in memory_range:
                # Check CPU/memory constraints
                if not is_between(
                    cpu, memory * min_vcpu_per_memory_gib, memory * max_vcpu_per_memory_gib
                ):
                    continue

                # Check CPU/GPU constraints
                if gpu > 0:
                    if not is_between(cpu, gpu * min_vcpu_per_gpu, gpu * max_vcpu_per_gpu):
                        continue

                # If all constraints are met, append this combination
                unbalanced_specs.append({"cpu": cpu, "memory": memory, "gpu": gpu})

    # If resource balancing is required, filter combinations to meet the balanced memory requirement
    if balance_resources:
        memory_balanced = [
            spec
            for spec in unbalanced_specs
            if spec["memory"]
            == get_balanced_memory(spec["gpu"], machine_type["gpu_memory"], q.max_memory)
        ]
        balanced_specs = memory_balanced
        # Add disk
        balanced_specs = [
            {
                "cpu": spec["cpu"],
                "memory": spec["memory"],
                "gpu": spec["gpu"],
                "disk_size": get_balanced_disk_size(
                    machine_type["maxStorageGibFree"],
                    spec["memory"],
                    spec["gpu"] * machine_type["gpu_memory"],
                    q.max_disk_size,
                    q.min_disk_size,
                ),
            }
            for spec in balanced_specs
        ]
        # Return balanced combinations if any; otherwise, return all combinations
        return balanced_specs

    disk_size = q.min_disk_size if q.min_disk_size is not None else MIN_DISK_SIZE
    # Add disk
    unbalanced_specs = [
        {"cpu": spec["cpu"], "memory": spec["memory"], "gpu": spec["gpu"], "disk_size": disk_size}
        for spec in unbalanced_specs
    ]
    return unbalanced_specs


def optimize_offers_no_gpu(q: QueryFilter, machine_type, balance_resource):
    # Generate ranges for CPU, memory based on the specified minimums, maximums, and available resources
    cpu_range = get_cpu_range(q.min_cpu, q.max_cpu, machine_type["maxVcpuFree"])
    memory_range = get_memory_range(q.min_memory, q.max_memory, machine_type["maxMemoryGibFree"])

    # Cudo Specific Constraints
    min_vcpu_per_memory_gib = machine_type.get("minVcpuPerMemoryGib", 0)
    max_vcpu_per_memory_gib = machine_type.get("maxVcpuPerMemoryGib", float("inf"))

    unbalanced_specs = []
    for cpu in cpu_range:
        for memory in memory_range:
            # Check CPU/memory constraints
            if not is_between(
                cpu, memory * min_vcpu_per_memory_gib, memory * max_vcpu_per_memory_gib
            ):
                continue
            # If all constraints are met, append this combination
            unbalanced_specs.append({"cpu": cpu, "memory": memory})

    # If resource balancing is required, filter combinations to meet the balanced memory requirement
    if balance_resource:
        cpu_balanced = [
            spec
            for spec in unbalanced_specs
            if spec["cpu"] == get_balanced_cpu(spec["memory"], q.max_memory)
        ]

        balanced_specs = cpu_balanced
        # Add disk
        disk_size = q.min_disk_size if q.min_disk_size is not None else MIN_DISK_SIZE
        balanced_specs = [
            {"cpu": spec["cpu"], "memory": spec["memory"], "disk_size": disk_size}
            for spec in balanced_specs
        ]
        # Return balanced combinations if any; otherwise, return all combinations
        return balanced_specs

    disk_size = q.min_disk_size if q.min_disk_size is not None else MIN_DISK_SIZE
    # Add disk
    unbalanced_specs = [
        {
            "cpu": spec["cpu"],
            "memory": spec["memory"],
            "gpu": 0,
            "disk_size": min_none(machine_type["maxStorageGibFree"], disk_size),
        }
        for spec in unbalanced_specs
    ]
    return unbalanced_specs


def get_cpu_range(min_cpu, max_cpu, max_cpu_free):
    cpu_range = range(
        min_cpu if min_cpu is not None else MIN_CPU,
        min(max_cpu if max_cpu is not None else max_cpu_free, max_cpu_free) + 1,
    )
    return cpu_range


def get_gpu_range(min_gpu_count, max_gpu_count, max_gpu_free):
    gpu_range = range(
        min_gpu_count if min_gpu_count is not None else 1,
        min(max_gpu_count if max_gpu_count is not None else max_gpu_free, max_gpu_free) + 1,
    )
    return gpu_range


def get_memory_range(min_memory, max_memory, max_memory_gib_free):
    memory_range = range(
        int(min_memory) if min_memory is not None else MIN_MEMORY,
        min(
            int(max_memory) if max_memory is not None else max_memory_gib_free, max_memory_gib_free
        )
        + 1,
    )
    return memory_range


def get_balanced_memory(gpu_count, gpu_memory, max_memory):
    return min_none(
        round_up(RAM_PER_VRAM * gpu_memory * gpu_count, RAM_DIV), round_down(max_memory, RAM_DIV)
    )


def get_balanced_cpu(memory, max_cpu):
    return min_none(
        round_up(ceil(memory / RAM_PER_CORE), CPU_DIV),
        round_down(max_cpu, CPU_DIV),  # can be None
    )


def get_balanced_disk_size(available_disk, memory, total_gpu_memory, max_disk_size, min_disk_size):
    return max_none(
        min_none(
            available_disk,
            max(memory, total_gpu_memory),
            max_disk_size,
        ),
        min_disk_size,
    )


def gpu_name(name: str) -> Optional[str]:
    if not name:
        return None
    result = GPU_MAP.get(name)
    return result


def get_memory(gpu_name: str) -> Optional[int]:
    if not gpu_name:
        return None
    for gpu in KNOWN_NVIDIA_GPUS:
        if gpu.name.lower() == gpu_name.lower():
            return gpu.memory


def round_up(value: Optional[Union[int, float]], step: int) -> Optional[int]:
    if value is None:
        return None
    return round_down(value + step - 1, step)


def round_down(value: Optional[Union[int, float]], step: int) -> Optional[int]:
    if value is None:
        return None
    return int(value // step * step)


T = TypeVar("T", bound=Union[int, float])


def min_none(*args: Optional[T]) -> T:
    return min(v for v in args if v is not None)


def max_none(*args: Optional[T]) -> T:
    return max(v for v in args if v is not None)


GPU_MAP = {
    "RTX A4000": "A4000",
    "RTX A4500": "A4500",
    "RTX A5000": "A5000",
    "RTX A6000": "A6000",
    "NVIDIA A40": "A40",
    "NVIDIA V100": "V100",
    "RTX 3080": "RTX3080",
}

================
File: gpuhunt/src/gpuhunt/providers/datacrunch.py
================
import copy
import itertools
import logging
from collections.abc import Iterable
from typing import Optional

from datacrunch import DataCrunchClient
from datacrunch.instance_types.instance_types import InstanceType

from gpuhunt import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

AMD_RX7900XTX = "RX7900XTX"
ALL_AMD_GPUS = [
    AMD_RX7900XTX,
]


class DataCrunchProvider(AbstractProvider):
    NAME = "datacrunch"

    def __init__(self, client_id: str, client_secret: str) -> None:
        self.datacrunch_client = DataCrunchClient(client_id, client_secret)

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        instance_types = self._get_instance_types()
        locations = self._get_locations()

        spots = (True, False)
        location_codes = [loc["code"] for loc in locations]
        instances = generate_instances(spots, location_codes, instance_types)

        return sorted(instances, key=lambda x: x.price)

    def _get_instance_types(self) -> list[InstanceType]:
        return self.datacrunch_client.instance_types.get()

    def _get_availabilities(self, spot: bool) -> list[dict]:
        return self.datacrunch_client.instances.get_availabilities(is_spot=spot)

    def _get_locations(self) -> list[dict]:
        return self.datacrunch_client.locations.get()

    @classmethod
    def filter(cls, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        return [o for o in offers if o.gpu_name not in ALL_AMD_GPUS]  # skip AMD GPU


def generate_instances(
    spots: Iterable[bool], location_codes: Iterable[str], instance_types: Iterable[InstanceType]
) -> list[RawCatalogItem]:
    instances = []
    for spot, location, instance in itertools.product(spots, location_codes, instance_types):
        item = transform_instance(copy.copy(instance), spot, location)
        if item is None:
            continue
        instances.append(RawCatalogItem.from_dict(item))
    return instances


def transform_instance(instance: InstanceType, spot: bool, location: str) -> Optional[dict]:
    gpu_memory = 0
    gpu_count = instance.gpu["number_of_gpus"]
    gpu_name = None

    if instance.gpu["number_of_gpus"]:
        gpu_memory = instance.gpu_memory["size_in_gigabytes"] / instance.gpu["number_of_gpus"]
        gpu_name = get_gpu_name(instance.gpu["description"])

    if gpu_count and gpu_name is None:
        logger.warning("Can't get GPU name from description: '%s'", instance.gpu["description"])
        return None

    raw = dict(
        instance_name=instance.instance_type,
        location=location,
        spot=spot,
        price=instance.spot_price_per_hour if spot else instance.price_per_hour,
        cpu=instance.cpu["number_of_cores"],
        memory=instance.memory["size_in_gigabytes"],
        gpu_count=gpu_count,
        gpu_name=gpu_name,
        gpu_memory=gpu_memory,
    )
    return raw


GPU_MAP = {
    "1x H100 SXM5 80GB": "H100",
    "2x H100 SXM5 80GB": "H100",
    "4x H100 SXM5 80GB": "H100",
    "8x H100 SXM5 80GB": "H100",
    "1x A100 SXM4 80GB": "A100",
    "2x A100 SXM4 80GB": "A100",
    "4x A100 SXM4 80GB": "A100",
    "8x A100 SXM4 80GB": "A100",
    "1x A100 SXM4 40GB": "A100",
    "2x A100 SXM4 40GB": "A100",
    "4x A100 SXM4 40GB": "A100",
    "8x A100 SXM4 40GB": "A100",
    "1x NVIDIA RTX6000 Ada 48GB": "RTX6000Ada",
    "2x NVIDIA RTX6000 Ada 48GB": "RTX6000Ada",
    "4x NVIDIA RTX6000 Ada 48GB": "RTX6000Ada",
    "8x NVIDIA RTX6000 Ada 48GB": "RTX6000Ada",
    "1x NVIDIA RTX A6000 48GB": "A6000",
    "2x NVIDIA RTX A6000 48GB": "A6000",
    "4x NVIDIA RTX A6000 48GB": "A6000",
    "8x NVIDIA RTX A6000 48GB": "A6000",
    "1x NVIDIA Tesla V100 16GB": "V100",
    "2x NVIDIA Tesla V100 16GB": "V100",
    "4x NVIDIA Tesla V100 16GB": "V100",
    "8x NVIDIA Tesla V100 16GB": "V100",
    "1x NVIDIA L40S": "L40S",
    "2x NVIDIA L40S": "L40S",
    "4x NVIDIA L40S": "L40S",
    "8x NVIDIA L40S": "L40S",
    "1x AMD 7900XTX": AMD_RX7900XTX,
    "2x AMD 7900XTX": AMD_RX7900XTX,
    "4x AMD 7900XTX": AMD_RX7900XTX,
    "8x AMD 7900XTX": AMD_RX7900XTX,
    "12x AMD 7900XTX": AMD_RX7900XTX,
}


def get_gpu_name(name: str) -> Optional[str]:
    if not name:
        return None
    result = GPU_MAP.get(name)
    return result

================
File: gpuhunt/src/gpuhunt/providers/gcp.py
================
import copy
import importlib.resources
import json
import logging
import re
from collections import defaultdict, namedtuple
from collections.abc import Iterable
from dataclasses import dataclass
from typing import Optional

import google.cloud.billing_v1 as billing_v1
import google.cloud.compute_v1 as compute_v1
from google.cloud import tpu_v2
from google.cloud.billing_v1 import CloudCatalogClient, ListSkusRequest
from google.cloud.billing_v1.types.cloud_catalog import Sku
from google.cloud.location import locations_pb2

from gpuhunt._internal.models import AcceleratorVendor, QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
compute_service = "services/6F81-5844-456A"
AcceleratorDetails = namedtuple("AcceleratorDetails", ["name", "memory"])
# As of 2024-14-08, this mapping contains only Nvidia accelerators; update gpu_vendor
# inferring code in fill_gpu_vendors_and_names() if a non-Nvidia accelerator is added
accelerator_details = {
    "nvidia-a100-80gb": AcceleratorDetails("A100", 80.0),
    "nvidia-h100-80gb": AcceleratorDetails("H100", 80.0),
    "nvidia-h100-mega-80gb": AcceleratorDetails("H100", 80.0),
    "nvidia-l4": AcceleratorDetails("L4", 24.0),
    "nvidia-tesla-a100": AcceleratorDetails("A100", 40.0),
    "nvidia-tesla-k80": AcceleratorDetails("K80", 12.0),
    "nvidia-tesla-p100": AcceleratorDetails("P100", 16.0),
    "nvidia-tesla-p4": AcceleratorDetails("P4", 8.0),
    "nvidia-tesla-t4": AcceleratorDetails("T4", 16.0),
    "nvidia-tesla-v100": AcceleratorDetails("V100", 16.0),
}
CpuMemory = namedtuple("CpuMemory", ["cpu", "memory"])
accelerator_limits = {
    "nvidia-tesla-k80": [
        CpuMemory(8, 52),
        CpuMemory(16, 104),
        CpuMemory(32, 208),
        CpuMemory(64, 208),
    ],
    "nvidia-tesla-p100": [CpuMemory(16, 104), CpuMemory(32, 208), CpuMemory(96, 624)],
    "nvidia-tesla-p4": [CpuMemory(24, 156), CpuMemory(48, 312), CpuMemory(96, 624)],
    "nvidia-tesla-t4": [CpuMemory(48, 312), CpuMemory(48, 312), CpuMemory(96, 624)],
    "nvidia-tesla-v100": [
        CpuMemory(12, 78),
        CpuMemory(24, 156),
        CpuMemory(48, 312),
        CpuMemory(96, 624),
    ],
}
accelerator_counts = [1, 2, 4, 8, 16]
hours_in_month = 730  # according to GCP pricing
multi_token_vm_families = ["a3-megagpu"]

# https://cloud.google.com/compute/docs/disks/local-ssd#lssd_disks_fixed
local_ssd_sizes_gib = {
    "c3-standard-4-lssd": 1 * 375,
    "c3-standard-8-lssd": 2 * 375,
    "c3-standard-22-lssd": 4 * 375,
    "c3-standard-44-lssd": 8 * 375,
    "c3-standard-88-lssd": 16 * 375,
    "c3-standard-176-lssd": 32 * 375,
    "c3d-standard-8-lssd": 1 * 375,
    "c3d-standard-16-lssd": 1 * 375,
    "c3d-standard-30-lssd": 2 * 375,
    "c3d-standard-60-lssd": 4 * 375,
    "c3d-standard-90-lssd": 8 * 375,
    "c3d-standard-180-lssd": 16 * 375,
    "c3d-standard-360-lssd": 32 * 375,
    "c3d-highmem-8-lssd": 1 * 375,
    "c3d-highmem-16-lssd": 1 * 375,
    "c3d-highmem-30-lssd": 2 * 375,
    "c3d-highmem-60-lssd": 4 * 375,
    "c3d-highmem-90-lssd": 8 * 375,
    "c3d-highmem-180-lssd": 16 * 375,
    "c3d-highmem-360-lssd": 32 * 375,
    "a3-megagpu-8g": 16 * 375,
    "a3-highgpu-8g": 16 * 375,
    "a2-ultragpu-1g": 1 * 375,
    "a2-ultragpu-2g": 2 * 375,
    "a2-ultragpu-4g": 4 * 375,
    "a2-ultragpu-8g": 8 * 375,
    "z3-standard-88-lssd": 12 * 3000,
    "z3-standard-176-lssd": 12 * 3000,
}


@dataclass
class TPUHardwareSpec:
    name: str
    cpu: int
    memory_gb: int
    hbm_gb: int


TPU_HARDWARE_SPECS = [
    TPUHardwareSpec(name="v2-8", cpu=96, memory_gb=334, hbm_gb=64),
    TPUHardwareSpec(name="v3-8", cpu=96, memory_gb=334, hbm_gb=128),
    TPUHardwareSpec(name="v5litepod-1", cpu=24, memory_gb=48, hbm_gb=16),
    TPUHardwareSpec(name="v5litepod-2", cpu=112, memory_gb=192, hbm_gb=16),
    TPUHardwareSpec(name="v5litepod-8", cpu=224, memory_gb=384, hbm_gb=128),
    TPUHardwareSpec(name="v5p-8", cpu=208, memory_gb=448, hbm_gb=95),
    TPUHardwareSpec(name="v6e-1", cpu=44, memory_gb=176, hbm_gb=32),
    TPUHardwareSpec(name="v6e-4", cpu=180, memory_gb=720, hbm_gb=128),
    TPUHardwareSpec(name="v6e-8", cpu=180, memory_gb=1440, hbm_gb=256),
]


# For newer TPUs, the specs are described in the docs: https://cloud.google.com/tpu/docs/v6e
# For older TPUs, the specs are collected manually from running instances.
TPU_HARDWARE_SPECS = [
    TPUHardwareSpec(name="v2-8", cpu=96, memory_gb=334, hbm_gb=64),
    TPUHardwareSpec(name="v3-8", cpu=96, memory_gb=334, hbm_gb=128),
    TPUHardwareSpec(name="v5litepod-1", cpu=24, memory_gb=48, hbm_gb=16),
    TPUHardwareSpec(name="v5litepod-4", cpu=112, memory_gb=192, hbm_gb=64),
    TPUHardwareSpec(name="v5litepod-8", cpu=224, memory_gb=384, hbm_gb=128),
    TPUHardwareSpec(name="v5p-8", cpu=208, memory_gb=448, hbm_gb=95),
    TPUHardwareSpec(name="v6e-1", cpu=44, memory_gb=176, hbm_gb=32),
    TPUHardwareSpec(name="v6e-4", cpu=180, memory_gb=720, hbm_gb=128),
    TPUHardwareSpec(name="v6e-8", cpu=180, memory_gb=1440, hbm_gb=256),
]
TPU_NAME_TO_HARDWARE_SPEC = {spec.name: spec for spec in TPU_HARDWARE_SPECS}


def load_tpu_pricing() -> dict:
    return json.loads(
        importlib.resources.files("gpuhunt.resources").joinpath("tpu_pricing.json").read_text()
    )


# A manually filled TPU pricing table from the pricing page.
# On-demand TPUs - https://cloud.google.com/tpu/pricing?hl=en.
# Spot TPUs - https://cloud.google.com/spot-vms/pricing?hl=en.
# It's needed since the TPU pricing API does not return prices for all regions.
# The API may also return 1-year Commitment prices instead of on-demand prices.
TPU_PRICING_TABLE = load_tpu_pricing()


class GCPProvider(AbstractProvider):
    NAME = "gcp"

    def __init__(self, project: str):
        # todo credentials
        self.project = project
        self.machine_types_client = compute_v1.MachineTypesClient()
        self.accelerator_types_client = compute_v1.AcceleratorTypesClient()
        self.regions_client = compute_v1.RegionsClient()
        self.cloud_catalog_client = billing_v1.CloudCatalogClient()

    def list_preconfigured_instances(self) -> list[RawCatalogItem]:
        instances = []
        for region in self.regions_client.list(project=self.project):
            for zone_url in region.zones:
                zone = zone_url.split("/")[-1]
                logger.info("Fetching instances for zone %s", zone)
                for machine_type in self.machine_types_client.list(
                    project=self.project, zone=zone
                ):
                    if (
                        machine_type.deprecated.state
                        == compute_v1.DeprecationStatus.State.DEPRECATED
                    ):
                        continue
                    gpu = None
                    if machine_type.accelerators:
                        accelerator = machine_type.accelerators[0].guest_accelerator_type
                        gpu = accelerator_details.get(accelerator)
                        if gpu is None:
                            logger.warning("Unknown accelerator type: %s", accelerator)
                            continue

                    instance = RawCatalogItem(
                        instance_name=machine_type.name,
                        location=zone,
                        cpu=machine_type.guest_cpus,
                        memory=round(machine_type.memory_mb / 1024, 1),
                        gpu_count=(
                            machine_type.accelerators[0].guest_accelerator_count if gpu else 0
                        ),
                        # gpu_name is canonicalized and gpu_vendor is set later
                        # in fill_gpu_vendors_and_names(), for now we use AcceleratorType.name
                        # as a name (it contains a vendor prefix like "nvidia-")
                        gpu_name=(
                            machine_type.accelerators[0].guest_accelerator_type if gpu else None
                        ),
                        gpu_vendor=None,
                        gpu_memory=gpu.memory if gpu else None,
                        price=None,
                        spot=None,
                        disk_size=None,
                    )
                    instances.append(instance)
        return instances

    def add_gpus(self, instances: list[RawCatalogItem]):
        n1_instances = defaultdict(list)
        for instance in instances:
            if instance.instance_name.startswith("n1-"):
                n1_instances[instance.location].append(instance)

        instances_with_gpus = []
        for zone, zone_n1_instances in n1_instances.items():
            logger.info("Fetching GPUs for zone %s", zone)
            for accelerator in self.accelerator_types_client.list(project=self.project, zone=zone):
                if accelerator.name not in accelerator_limits:
                    continue
                for n, limit in zip(accelerator_counts, accelerator_limits[accelerator.name]):
                    for instance in zone_n1_instances:
                        if instance.cpu > limit.cpu or instance.memory > limit.memory:
                            continue
                        i = copy.deepcopy(instance)
                        i.gpu_count = n
                        i.gpu_name = accelerator.name
                        i.gpu_memory = accelerator_details[accelerator.name].memory
                        instances_with_gpus.append(i)
        instances += instances_with_gpus

    def fill_prices(self, instances: list[RawCatalogItem]) -> list[RawCatalogItem]:
        logger.info("Fetching prices")
        skus = self.cloud_catalog_client.list_skus(parent=compute_service)
        prices = Prices()
        prices.add_skus(skus)

        offers = []
        for instance in instances:
            for spot in (False, True):
                price = prices.get_instance_price(instance, spot)
                if price is None:
                    continue

                offer = copy.deepcopy(instance)
                offer.price = round(price, 6)
                offer.spot = spot
                offers.append(offer)
        return offers

    def fill_gpu_vendors_and_names(self, offers: list[RawCatalogItem]) -> None:
        # Modifies offers in the list in-place
        for offer in offers:
            accelerator_type = offer.gpu_name
            if not accelerator_type:
                continue
            offer.gpu_name = accelerator_details[accelerator_type].name
            if accelerator_type.startswith("nvidia-"):
                offer.gpu_vendor = AcceleratorVendor.NVIDIA.value
            else:
                logger.warning("Unknown accelerator vendor: %s", accelerator_type)

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        instances = self.list_preconfigured_instances()
        self.add_gpus(instances)
        offers = self.fill_prices(instances)
        self.fill_gpu_vendors_and_names(offers)
        offers.extend(get_tpu_offers(self.project))
        return sorted(offers, key=lambda i: i.price)

    @classmethod
    def filter(cls, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        return [
            i
            for i in offers
            if any(
                i.instance_name.startswith(family)
                for family in [
                    "e2-medium",
                    "e2-standard-",
                    "e2-highmem-",
                    "e2-highcpu-",
                    "m1-",
                    "a2-",
                    "g2-",
                ]
            )
            or (i.gpu_name and i.gpu_name not in ["K80", "P4"])
        ]


RegionSpot = tuple[str, bool]
PricePerRegionSpot = dict[RegionSpot, float]


class Prices:
    def __init__(self):
        self.cpu: defaultdict[str, PricePerRegionSpot] = defaultdict(dict)
        self.gpu: defaultdict[str, PricePerRegionSpot] = defaultdict(dict)
        self.ram: defaultdict[str, PricePerRegionSpot] = defaultdict(dict)
        self.local_ssd: PricePerRegionSpot = dict()

    def add_skus(self, skus: Iterable[Sku]) -> None:
        for sku in skus:
            if sku.category.usage_type not in ["OnDemand", "Preemptible"]:
                continue
            if any(
                word in sku.description
                for word in [
                    "Sole Tenancy",
                    "Reserved",
                    "Premium",
                    "Custom",
                    "suspended",
                ]
            ):
                continue
            if sku.category.resource_family == "Compute":
                self.add_compute_sku(sku)
            elif sku.category.resource_family == "Storage":
                self.add_storage_sku(sku)

    def add_compute_sku(self, sku: Sku) -> None:
        r = re.match(
            r"^(?:spot preemptible )?(.+) (gpu|ram|core)",
            sku.description,
            flags=re.IGNORECASE,
        )
        if not r:
            return
        family, resource = r.groups()
        resource = resource.lower()

        if resource == "gpu":
            family = family.replace(" ", "-").lower()
            family = {
                "nvidia-tesla-a100-80gb": "nvidia-a100-80gb",
                "nvidia-h100-80gb-mega": "nvidia-h100-mega-80gb",
            }.get(family, family)
        else:
            r = re.match(r"^([a-z]\d.?) ", family.lower())
            if r:
                family = r.group(1)
            else:
                family = {
                    "Memory-optimized Instance": "m1",
                    "Compute optimized Instance": "c2",
                    "Compute optimized": "c2",
                    "A3Plus Instance": "a3-megagpu",
                }.get(family, family)

        price = sku.pricing_info[0].pricing_expression.tiered_rates[0].unit_price
        price = price.units + price.nanos / 1e9
        resource_prices = {
            "core": self.cpu,
            "gpu": self.gpu,
            "ram": self.ram,
        }[resource]
        self._add_price(sku, resource_prices[family], price)

    def add_storage_sku(self, sku: Sku) -> None:
        if sku.description.lower().startswith("ssd backed local storage"):
            price = sku.pricing_info[0].pricing_expression.tiered_rates[0].unit_price
            price = price.units + price.nanos / 1e9 / hours_in_month
            self._add_price(sku, self.local_ssd, price)

    @staticmethod
    def _add_price(sku: Sku, family_prices: PricePerRegionSpot, price: float) -> None:
        spot = sku.category.usage_type == "Preemptible"
        for region in sku.service_regions:
            family_prices[(region, spot)] = price

    def get_instance_price(self, instance: RawCatalogItem, spot: bool) -> Optional[float]:
        vm_family = self.get_vm_family(instance.instance_name)
        if vm_family in ["g1", "f1", "m2"]:  # shared-core and reservation-only
            return None

        region_spot = (instance.location[:-2], spot)
        if region_spot not in self.cpu[vm_family]:
            return None

        price = 0
        price += instance.cpu * self.cpu[vm_family][region_spot]
        price += instance.memory * self.ram[vm_family][region_spot]
        if instance.gpu_name:
            if region_spot not in self.gpu[instance.gpu_name]:
                return None
            price += instance.gpu_count * self.gpu[instance.gpu_name][region_spot]
        if instance.instance_name in local_ssd_sizes_gib:
            price += local_ssd_sizes_gib[instance.instance_name] * self.local_ssd[region_spot]

        return price

    @staticmethod
    def get_vm_family(instance_name: str) -> str:
        for family in multi_token_vm_families:
            if instance_name.startswith(family):
                return family
        return instance_name.split("-")[0]


def get_tpu_offers(project_id: str) -> list[RawCatalogItem]:
    logger.info("Fetching TPU offers")
    raw_catalog_items: list[RawCatalogItem] = []
    catalog_items: list[dict] = get_catalog_items(project_id)
    # For some TPU offers in some regions, GCP does not list prices at all. Skip such offers.
    filtered_catalog_items = [item for item in catalog_items if item["price"] is not None]
    for item in filtered_catalog_items:
        hardware_spec = get_tpu_hardware_spec(item["instance_name"])
        if hardware_spec is None:
            logger.debug("No TPU hardware spec for %s", item["instance_name"])
            continue
        on_demand_item = RawCatalogItem(
            instance_name=item["instance_name"],
            location=item["location"],
            price=item["price"],
            cpu=hardware_spec.cpu,
            memory=hardware_spec.memory_gb,
            gpu_vendor=AcceleratorVendor.GOOGLE.value,
            gpu_count=1,
            gpu_name=item["instance_name"],
            gpu_memory=hardware_spec.hbm_gb,
            spot=False,
            disk_size=None,
        )
        raw_catalog_items.append(on_demand_item)
        if item["spot"]:
            spot_item = copy.deepcopy(on_demand_item)
            spot_item.price = item["spot"]
            spot_item.spot = True
            raw_catalog_items.append(spot_item)
    return raw_catalog_items


def get_catalog_items(project_id: str) -> list[dict]:
    """
    Returns TPU configurations with pricing info.
    Each configuration contains on-demand price and spot price but any price can be missing.
    This is because the API does not return prices for all regions.
    As a backup, the prices are taken from the pricing table on the GCP website,
    but it also does not contain all the prices.
    Even when creating some TPUs in some regions via the GCP console,
    the price is not shown (e.g. v6e in us-south1).
    """
    tpu_prices: list[dict] = get_tpu_prices()
    configs: list[dict] = get_tpu_configs(project_id)
    for config in configs:
        instance_name = config["instance_name"]
        location = config["location"].rsplit("-", 1)[0]  # Remove the part after the last '-'
        no_of_chips = config["no_of_chips"]
        tpu_version, no_of_cores = instance_name.rsplit("-", 1)
        no_of_cores = int(no_of_cores)
        if tpu_version in ["v5litepod", "v5p", "v6e"]:
            # For TPU-v5 series, the API provides per chip price.
            is_pod = True
            on_demand_base_price = find_base_price_v5(
                tpu_version, location, tpu_prices, spot=False
            )
            if on_demand_base_price is not None:
                on_demand_price = on_demand_base_price * no_of_chips
            else:
                on_demand_price = find_tpu_price_static_src(
                    tpu_version, no_of_cores, location, no_of_chips, False
                )
            spot_base_price = find_base_price_v5(tpu_version, location, tpu_prices, spot=True)
            if spot_base_price is not None:
                spot_price = spot_base_price * no_of_chips
            else:
                spot_price = find_tpu_price_static_src(
                    tpu_version, no_of_cores, location, no_of_chips, True
                )
        elif tpu_version in ["v2", "v3", "v4"]:
            # For TPU-v2 and TPU-v3, the pricing API provides the prices of 8 TPU cores.
            # For TPU-v4, the API provides the price of TPU-v4 pods.
            if no_of_cores > 8 or tpu_version == "v4":
                is_pod = True
                base_instance_name = f"{tpu_version}-8"
                base_no_of_chips = find_no_of_chips(base_instance_name, configs)
                on_demand_base_price = find_base_price(
                    tpu_version, location, tpu_prices, spot=False, is_pod=True
                )
                if on_demand_base_price is not None and base_no_of_chips is not None:
                    on_demand_price = (on_demand_base_price / base_no_of_chips) * no_of_chips
                else:
                    on_demand_price = find_tpu_price_static_src(
                        tpu_version, no_of_cores, location, no_of_chips, False
                    )
                spot_base_price = find_base_price(
                    tpu_version, location, tpu_prices, spot=True, is_pod=True
                )
                if spot_base_price is not None and base_no_of_chips is not None:
                    spot_price = (spot_base_price / base_no_of_chips) * no_of_chips
                else:
                    spot_price = find_tpu_price_static_src(
                        tpu_version, no_of_cores, location, no_of_chips, True
                    )
            elif no_of_cores == 8:
                is_pod = False
                base_no_of_chips = no_of_chips
                on_demand_base_price = find_base_price(
                    tpu_version, location, tpu_prices, spot=False, is_pod=False
                )
                on_demand_price = on_demand_base_price
                spot_base_price = find_base_price(
                    tpu_version, location, tpu_prices, spot=True, is_pod=False
                )
                spot_price = spot_base_price
        else:
            logger.warning("Unknown TPU version %s. Skipping offer.", tpu_version)
            continue
        if on_demand_price is None:
            logger.debug("Failed to find on-demand price for %s in %s", instance_name, location)
        if spot_price is None:
            logger.debug("Failed to find spot price for %s in %s", instance_name, location)
        config["price"] = on_demand_price
        config["spot"] = spot_price
        config["is_pod"] = is_pod
        config["base_price"] = on_demand_base_price
        config["base_no_of_chips"] = base_no_of_chips
        config["spot_base_price"] = spot_base_price
    return configs


def get_tpu_prices() -> list[dict]:
    client = CloudCatalogClient()
    tpu_configs = []
    # E000-3F24-B8AA contains prices for TPU versions v2,v3,v4.
    # 6F81-5844-456A contains prices for newer TPU versions v5p, v5litepod(v5e), v6e.
    service_names = ["services/E000-3F24-B8AA", "services/6F81-5844-456A"]
    for service_name in service_names:
        request = ListSkusRequest(parent=service_name)
        response = client.list_skus(request=request)
        for sku in response.skus:
            if sku.category.resource_group != "TPU":
                continue
            if sku.category.usage_type not in ["OnDemand", "Preemptible"]:
                continue
            tpu_version = extract_tpu_version(sku.description)
            if tpu_version:
                is_pod = True if "Pod" in sku.description else False
                spot = True if "Preemptible" in sku.description else False
                price = sku.pricing_info[0].pricing_expression.tiered_rates[0].unit_price
                price = price.units + price.nanos / 1e9
                tpu_configs.append(
                    {
                        "instance_name": tpu_version,
                        "is_pod": is_pod,
                        "spot": spot,
                        "regions": sku.service_regions,
                        "price": price,
                        "description": sku.description,
                    }
                )
    return tpu_configs


def find_base_price(
    tpu_version: str, location: str, tpu_prices: list[dict], spot: bool, is_pod: bool
) -> Optional[float]:
    for price_info in tpu_prices:
        if (
            price_info["instance_name"] == tpu_version
            and any(loc.startswith(location) for loc in price_info["regions"])
            and price_info["spot"] == spot
            and price_info["is_pod"] == is_pod
        ):
            return price_info["price"]
    return None


def find_no_of_chips(instance_name: str, configs: list[dict]):
    for config in configs:
        if config["instance_name"] == instance_name:
            return config["no_of_chips"]
    return None


def find_tpu_price_static_src(
    tpu_version: str, num_cores: int, tpu_region: str, no_of_chips: int, spot: bool
) -> Optional[float]:
    # The pricing page names v5litepod as v5e
    tpu_version = "v5e" if tpu_version == "v5litepod" else tpu_version
    # The pricing page lists different (device and pod) prices per chip for v2 and v3.
    # The device is the smallest configuration with 8 TPU cores (e.g. v3-8).
    # TPU Pod connects mulitple TPU devices (e.g. v3-32).
    # Not applicable for newer generations.
    tpu_type = f"TPU {tpu_version}"
    if tpu_version in ["v2", "v3", "v4"]:
        is_pod = num_cores > 8 or tpu_version == "v4"
        tpu_type = f"TPU {tpu_version} pod" if is_pod else f"TPU {tpu_version} device"
    price_key = "On Demand (USD)"
    if spot:
        price_key = "Spot (USD)"
    try:
        return TPU_PRICING_TABLE[tpu_type][tpu_region][price_key] * no_of_chips
    except KeyError:
        logger.debug(f"KeyError for {tpu_type} {tpu_region} {price_key}")
        return None


def find_base_price_v5(
    tpu_version: str, location: str, tpu_prices: list[dict], spot: bool
) -> Optional[float]:
    for price_info in tpu_prices:
        if (
            price_info["instance_name"] == tpu_version
            and any(loc.startswith(location) for loc in price_info["regions"])
            and price_info["spot"] == spot
        ):
            return price_info["price"]
    return None


def get_tpu_configs(project_id: str) -> list[dict]:
    instances: list[dict] = []
    client = tpu_v2.TpuClient()
    for location in get_locations(project_id):
        parent = f"projects/{project_id}/locations/{location}"
        request = tpu_v2.ListAcceleratorTypesRequest(
            parent=parent,
        )
        page_result = client.list_accelerator_types(request=request)
        for response in page_result:
            no_of_chips = get_no_of_chips(response.accelerator_configs[0].topology)
            instances.append(
                {
                    "instance_name": response.type_,
                    "location": location,
                    "no_of_chips": no_of_chips,
                    "topology": response.accelerator_configs[0].topology,
                }
            )
    return instances


def get_no_of_chips(expression: str) -> int:
    factors = expression.split("x")
    factors = map(int, factors)
    product = 1
    for factor in factors:
        product *= factor
    return product


def get_locations(project_id: str) -> list[str]:
    client = tpu_v2.TpuClient()
    parent = f"projects/{project_id}"
    list_locations_request = client.list_locations(locations_pb2.ListLocationsRequest(name=parent))
    locations = [loc.location_id for loc in list_locations_request.locations]
    # TPU V4 only available in location us-central2-b only.
    # us-central2-b needs to be enabled in the project.
    return locations


def extract_tpu_version(input_string: str) -> Optional[str]:
    # The regular expression pattern to find a substring starting with 'Tpu'
    pattern = r"\bTpu[-\w]*\b"
    # Search for the first match of the pattern
    match = re.search(pattern, input_string, re.IGNORECASE)
    if match:
        tpu_match = match.group().lower()
        # The regular expression pattern to find the version part
        version_pattern = r"v\d+[a-z]*"
        version_match = re.search(version_pattern, tpu_match)
        if version_match:
            # Name of v5e in gcp console is v5litepod
            version = "v5litepod" if version_match.group() == "v5e" else version_match.group()
            return version
    return None


def get_tpu_hardware_spec(instance_name: str) -> Optional[TPUHardwareSpec]:
    return TPU_NAME_TO_HARDWARE_SPEC.get(instance_name)

================
File: gpuhunt/src/gpuhunt/providers/genesiscloud.py
================
import logging
from typing import List, Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers.scraper import ScraperProvider

logger = logging.getLogger(__name__)

class GenesisCloudProvider(ScraperProvider):
    """Provider for Genesis Cloud GPU instances using web scraping"""
    
    NAME = "genesiscloud"

    def __init__(self):
        super().__init__()

    @property
    def urls(self) -> List[str]:
        return ["https://www.genesiscloud.com/pricing"]

    @property
    def prompt(self) -> str:
        return """
        Extract all GPU instances from the Genesis Cloud pricing page. For each GPU instance, provide:
        1. GPU model name (e.g. RTX 4090, RTX 3090, A100) - remove any vendor prefix
        2. GPU memory in GB (as a number)
        3. Number of GPUs per instance (as a number)
        4. Price per hour in USD (as a number)
        5. Location (use the region specified, default to "EU" if not specified)
        6. Number of CPU cores (as a number)
        7. System RAM in GB (as a number)
        8. Disk size in GB if available (as a number)

        Important:
        - Return ALL GPU instances you find
        - All numeric values should be numbers, not strings
        - Look for both On-Demand and Spot prices (create separate entries with spot=true for spot instances)
        - The vendor is always "NVIDIA"
        - Pay attention to both vCPU and RAM specifications
        - Look for SSD/NVMe storage sizes
        - Make sure to include both RTX and Data Center GPUs
        - Prices should already be in USD per hour
        - For any missing numeric values, use: memory=0, count=1, price=0, cpu=0, ram=0
        - Do not return instances where ALL specifications are missing
        - If only some specifications are available, return those and use defaults for missing ones
        
        Return the data in this format:
        {
          "gpus": [
            {
              "name": "4090",
              "memory": 24,
              "count": 1,
              "price": 0.99,
              "location": "EU",
              "cpu": 8,
              "ram": 32,
              "disk": 100,
              "spot": false,
              "vendor": "NVIDIA"
            },
            ... additional GPUs ...
          ]
        }
        """

================
File: gpuhunt/src/gpuhunt/providers/lambdalabs.py
================
import copy
import logging
import re
from typing import Optional

import requests

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
instance_types_url = "https://cloud.lambdalabs.com/api/v1/instance-types"
all_regions = [
    "us-south-1",
    "us-south-2",
    "us-south-3",
    "us-west-2",
    "us-west-1",
    "us-midwest-1",
    "us-west-3",
    "us-east-1",
    "us-east-2",
    "europe-central-1",
    "asia-south-1",
    "me-west-1",
    "asia-northeast-1",
    "asia-northeast-2",
]


class LambdaLabsProvider(AbstractProvider):
    NAME = "lambdalabs"

    def __init__(self, token: str):
        self.token = token

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        offers = []
        data = requests.get(
            instance_types_url, headers={"Authorization": f"Bearer {self.token}"}, timeout=10
        ).json()["data"]
        for instance in data.values():
            instance = instance["instance_type"]
            logger.info(instance["name"])
            description = instance["description"]
            result = parse_description(description)
            if result is None:
                logger.warning("Can't parse GPU info from description: %s", description)
                continue
            gpu_count, gpu_name, gpu_memory = result
            offer = RawCatalogItem(
                instance_name=instance["name"],
                price=instance["price_cents_per_hour"] / 100,
                cpu=instance["specs"]["vcpus"],
                memory=float(instance["specs"]["memory_gib"]) * 1.074,
                gpu_vendor=None,
                gpu_count=gpu_count,
                gpu_name=gpu_name,
                gpu_memory=gpu_memory,
                spot=False,
                location=None,
                disk_size=float(instance["specs"]["storage_gib"]) * 1.074,
            )
            offers.append(offer)
        offers = self.add_regions(offers)
        return sorted(offers, key=lambda i: i.price)

    def add_regions(self, offers: list[RawCatalogItem]) -> list[RawCatalogItem]:
        # TODO: we don't know which regions are actually available for each instance type
        region_offers = []
        for region in all_regions:
            for offer in offers:
                offer = copy.deepcopy(offer)
                offer.location = region
                region_offers.append(offer)
        return region_offers


def parse_description(v: str) -> Optional[tuple[int, str, float]]:
    """Returns gpus count, gpu name, and GPU memory"""
    r = re.match(r"^(\d)x (?:Tesla )?(.+) \((\d+) GB", v)
    if r is None:
        return None
    count, gpu_name, gpu_memory = r.groups()
    return int(count), gpu_name.replace(" ", ""), float(gpu_memory)

================
File: gpuhunt/src/gpuhunt/providers/latitude.py
================
import logging
import re
from typing import Optional

import requests
from bs4 import BeautifulSoup

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

class LatitudeProvider(AbstractProvider):
    NAME = "latitude"

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        """
        Fetches and processes pricing data from latitude.sh.

        Returns:
            A list of RawCatalogItem objects representing available offers.
        """
        try:
            pricing_data = self.scrape_latitude_pricing()
            offers = self.process_data(pricing_data)
            return offers
        except requests.exceptions.RequestException as e:
            logger.error("Error during request to latitude.sh: %s", e)
            return []

    def scrape_latitude_pricing(self) -> dict:
        """
        Fetches the pricing data from latitude.sh's API endpoint.

        Returns:
            A dictionary containing pricing information.
        Raises:
            requests.exceptions.RequestException: If the HTTP request fails.
        """
        base_url = "https://www.latitude.sh/pricing"
        
        # Fetch the pricing page HTML
        response = requests.get(base_url, timeout=10)
        response.raise_for_status()
        html_content = response.text

        # Extract the dynamic hash
        hash_value = self._extract_hash(html_content)
        if not hash_value:
            raise ValueError("Unable to find the dynamic hash on the page")

        # Build the JSON URL with the dynamic hash
        url = f"https://www.latitude.sh/_next/data/{hash_value}/en/pricing.json"
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        return response.json()

    def _extract_hash(self, html_content: str) -> Optional[str]:
        """
        Extracts the dynamic hash from the HTML content.

        Args:
            html_content: The HTML content of the pricing page.

        Returns:
            The dynamic hash string, or None if not found.
        """
        soup = BeautifulSoup(html_content, "html.parser")
        script_tag = soup.find("script", id="__NEXT_DATA__")
        if script_tag:
            try:
                data = script_tag.string
                if data:
                    match = re.search(r'"buildId":"([^"]+)"', data)
                    if match:
                        return match.group(1)
            except KeyError:
                return None
        return None

    def process_data(self, pricing_data: dict) -> list[RawCatalogItem]:
        """
        Processes the fetched pricing data into RawCatalogItem objects.

        Args:
            pricing_data: A dictionary containing the scraped data.

        Returns:
            A list of RawCatalogItem objects.
        """
        offers = []
        plans_data = pricing_data.get('pageProps', {}).get('plansData', [])
        for plan in plans_data:
            if 'attributes' not in plan:
                continue
            regions = plan['attributes'].get('regions', [])
            for region in regions:
                item = self.create_raw_catalog_item(plan['attributes'], region)
                if item:
                    offers.append(item)
        return offers
    
    def create_raw_catalog_item(self, plan: dict, region: dict) -> Optional[RawCatalogItem]:
        """
        Creates a RawCatalogItem from a plan's data.

        Args:
            plan: A dictionary representing the plan's data.
            region: The region data dictionary

        Returns:
             A RawCatalogItem object or None if data processing fails.
        """
        try:
            specs = plan.get('specs', {})
            if not specs:
                return None

            cpu_info = specs.get('cpu', {})
            cpu_cores = cpu_info.get('cores', 0) * cpu_info.get('count', 1)
            
            memory_info = specs.get('memory', {})
            memory_gb = memory_info.get('total', 0)
            
            gpu_info = specs.get('gpu', {})
            gpu_count = gpu_info.get('count', 0)
            gpu_name = gpu_info.get('type')
            gpu_memory = None
            if gpu_name:
                # Extract GPU memory from name if present (e.g., "NVIDIA H100 80GB")
                memory_match = re.search(r'(\d+)GB', gpu_name)
                if memory_match:
                    gpu_memory = float(memory_match.group(1))
            
            # Get pricing for USD
            pricing = region.get('pricing', {}).get('USD', {})
            price_per_hour = pricing.get('hour', 0)
            
            # Get location info
            location = region.get('locations', {}).get('available', [])[0] if region.get('locations', {}).get('available') else None
            
            if not location:
                return None

            return RawCatalogItem(
                instance_name=plan.get('name', ''),
                location=location,
                price=price_per_hour,
                cpu=cpu_cores,
                memory=memory_gb,
                gpu_vendor='NVIDIA' if gpu_name and 'NVIDIA' in gpu_name else None,
                gpu_count=gpu_count,
                gpu_name=gpu_name,
                gpu_memory=gpu_memory,
                spot=False,
                disk_size=None,
            )
        except (KeyError, TypeError, ValueError) as e:
            logger.warning("Failed to process plan %s in %s: %s", plan.get('name', 'unknown'), region.get('name', 'unknown'), e)
            return None

================
File: gpuhunt/src/gpuhunt/providers/leadergpu.py
================
import logging
import re
from typing import List, Optional
from bs4 import BeautifulSoup
import requests

from gpuhunt._internal.models import QueryFilter, RawCatalogItem, AcceleratorVendor
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

def parse_memory(memory_str: str) -> float:
    """Parse memory string to get GB value"""
    if not memory_str:
        return 0.0
    match = re.search(r'(\d+(?:\.\d+)?)\s*(?:GB|GiB|G)', memory_str)
    return float(match.group(1)) if match else 0.0

def parse_cpu_cores(cpu_str: str) -> int:
    """Parse CPU string to get core count"""
    if not cpu_str:
        return 0
    match = re.search(r'(\d+)\s*(?:cores?|vCPU)', cpu_str, re.IGNORECASE)
    return int(match.group(1)) if match else 0

def parse_gpu_count_and_model(gpu_info: str) -> tuple[int, str]:
    """Parse GPU info to get count and model"""
    if not gpu_info:
        return 0, ""
    
    # Clean up the text
    gpu_info = gpu_info.replace('GPU:', '').strip()
    
    # Try to match patterns like "8 pcs RTX A6000" or "2 pcs H100"
    match = re.search(r'(\d+)\s*pcs\s*(?:NVIDIA\s*)?(?:RTX\s*)?(\w+(?:\s*\d+)?)', gpu_info)
    if match:
        count = int(match.group(1))
        model = match.group(2).strip()
        return count, model
        
    # Try to match other formats
    match = re.search(r'(\d+)x\s*(?:NVIDIA\s*)?(?:RTX\s*)?(\w+(?:\s*\d+)?)', gpu_info)
    if match:
        return int(match.group(1)), match.group(2).strip()
        
    # If no count found, assume 1
    match = re.search(r'(?:NVIDIA\s*)?(?:RTX\s*)?(\w+(?:\s*\d+)?)', gpu_info)
    if match:
        return 1, match.group(1).strip()
        
    return 1, gpu_info.replace('NVIDIA', '').replace('RTX', '').strip()

def parse_price(price_str: str) -> float:
    """Parse price string to get hourly rate in USD"""
    if not price_str:
        return 0.0
    match = re.search(r'(\d+(?:\.\d+)?)', price_str)
    if not match:
        return 0.0
    price = float(match.group(1))
    if 'month' in price_str:
        price = price / (24 * 30)  # Convert monthly to hourly
    elif 'week' in price_str:
        price = price / (24 * 7)   # Convert weekly to hourly
    elif 'day' in price_str:
        price = price / 24         # Convert daily to hourly
    elif 'minute' in price_str:
        price = price * 60         # Convert per-minute to hourly
    return round(price, 4)  # Round to 4 decimal places

class LeaderGPUProvider(AbstractProvider):
    """Provider for LeaderGPU instances"""
    
    NAME = "leadergpu"

    def __init__(self):
        super().__init__()

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        """Get GPU offerings from LeaderGPU
        
        Args:
            query_filter: Optional filter for the results
            balance_resources: Whether to balance resources based on GPU specs
            
        Returns:
            List of RawCatalogItem objects
        """
        url = "https://www.leadergpu.com/filter_servers"
        
        try:
            # Get JSON response and extract HTML from it
            response = requests.get(url).json()
            logger.debug(f"LeaderGPU API response: {response}")
            html_content = response.get('matchesHtml', '')
            if not html_content:
                logger.error("No HTML content found in LeaderGPU response")
                return []
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            gpu_sections = soup.find_all('section', class_='b-product-gpu')
            offers = []
            
            for section in gpu_sections:
                # Basic info from title
                title_div = section.find('div', class_='b-product-gpu-title')
                if not title_div:
                    continue
                
                # Extract GPU configuration
                config_div = section.find('div', class_='config-list')
                if not config_div:
                    continue
                
                # Get GPU info
                gpu_div = config_div.find('div', recursive=False)
                if not gpu_div:
                    continue
                    
                gpu_text = gpu_div.get_text(strip=True)
                gpu_count, gpu_model = parse_gpu_count_and_model(gpu_text)
                
                # Get GPU RAM
                gpu_ram = None
                cpu_info = None
                ram_info = None
                nvme_info = None
                
                for div in config_div.find_all('div', recursive=False):
                    text = div.get_text(strip=True)
                    if 'GPU RAM:' in text:
                        gpu_ram = div.find('span').get_text(strip=True) if div.find('span') else None
                    elif 'CPU:' in text:
                        cpu_info = div.find('span').get_text(strip=True) if div.find('span') else None
                    elif 'RAM:' in text:
                        ram_info = div.find('span').get_text(strip=True) if div.find('span') else None
                    elif 'NVME:' in text:
                        nvme_info = div.find('span').get_text(strip=True) if div.find('span') else None
                
                # Get price
                prices_div = section.find('div', class_='b-product-gpu-prices')
                hourly_price = 0.0
                if prices_div:
                    for li in prices_div.find_all('li', class_='d-flex'):
                        price_text = li.find('p', class_='text-bold').get_text(strip=True) if li.find('p', class_='text-bold') else None
                        if price_text:
                            price = parse_price(price_text)
                            if price > 0:
                                hourly_price = price
                                break
                
                # Create catalog item
                offer = RawCatalogItem(
                    instance_name=f"{gpu_model}-{gpu_count}x",
                    location="EU",  # LeaderGPU is based in Europe
                    price=hourly_price,
                    cpu=parse_cpu_cores(cpu_info) if cpu_info else 0,
                    memory=parse_memory(ram_info) if ram_info else 0,
                    gpu_vendor=AcceleratorVendor.NVIDIA,  # LeaderGPU only offers NVIDIA
                    gpu_count=gpu_count,
                    gpu_name=gpu_model,
                    gpu_memory=parse_memory(gpu_ram) if gpu_ram else 0,
                    spot=False,
                    disk_size=parse_memory(nvme_info) if nvme_info else 0
                )
                offers.append(offer)
            
            logger.info(f"Found {len(offers)} GPU instances from LeaderGPU")
            return offers
            
        except Exception as e:
            logger.error(f"Error scraping LeaderGPU: {str(e)}")
            return []

================
File: gpuhunt/src/gpuhunt/providers/linode.py
================
import logging
import json
import requests
from typing import List, Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers.scraper import ScraperProvider

logger = logging.getLogger(__name__)

class LinodeProvider(ScraperProvider):
    """Provider for Linode (Akamai Cloud) GPU instances using their API"""
    
    NAME = "linode"

    def __init__(self):
        super().__init__()

    @property
    def urls(self) -> List[str]:
        return ["https://api.linode.com/v4/linode/types"]

    def _get_pricing_data(self) -> str:
        """Get pricing data from Linode API"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
        }
        response = requests.get(self.urls[0], headers=headers, timeout=30)
        response.raise_for_status()
        return json.dumps(response.json())

    @property
    def prompt(self) -> str:
        return """
        Extract all GPU instances from the Linode API response. The data is in JSON format where GPU instances have "class": "gpu". For each GPU instance, provide:
        1. GPU model name (e.g. A100, A40) - remove any vendor prefix
        2. GPU memory in GB (as a number) - this is usually in the "label" field
        3. Number of GPUs per instance (as a number) - look for GPU count in description
        4. Price per hour in USD (as a number) - use the "price.hourly" field
        5. Location (set to "US" as instances are available in multiple regions)
        6. Number of CPU cores (as a number) - use "vcpus" field
        7. System RAM in GB (as a number) - use "memory" field divided by 1024 to convert from MB to GB
        8. Disk size in GB if available (as a number) - use "disk" field

        Important:
        - Only return instances where "class" is "gpu"
        - All numeric values should be numbers, not strings
        - The vendor is always "NVIDIA"
        - Memory is in MB in the API, convert to GB by dividing by 1024
        - For any missing numeric values, use: memory=0, count=1, price=0, cpu=0, ram=0
        - Do not return instances where ALL specifications are missing
        - If only some specifications are available, return those and use defaults for missing ones
        
        Return the data in this format:
        {
          "gpus": [
            {
              "name": "A100",
              "memory": 80,
              "count": 1,
              "price": 3.99,
              "location": "US",
              "cpu": 8,
              "ram": 64,
              "disk": 100,
              "spot": false,
              "vendor": "NVIDIA"
            },
            ... additional GPUs ...
          ]
        }
        """

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        """Override get method to use API data instead of webpage content"""
        try:
            content = self._get_pricing_data()
            gpus = self.scraper.scrape_url(self.urls[0], self.prompt, override_content=content)
        except Exception as e:
            logger.error(f"Error getting Linode pricing data: {str(e)}")
            return []

        # Convert GPUInfo objects to RawCatalogItem objects
        offers = []
        for gpu in gpus:
            offer = RawCatalogItem(
                instance_name=f"{gpu.name}-{gpu.count}x",
                location=gpu.location,
                price=gpu.price,
                cpu=gpu.cpu,
                memory=gpu.ram,
                gpu_vendor=gpu.vendor,
                gpu_count=gpu.count,
                gpu_name=gpu.name,
                gpu_memory=gpu.memory,
                spot=gpu.spot,
                disk_size=gpu.disk,
            )
            offers.append(offer)

        return sorted(offers, key=lambda i: i.price)

================
File: gpuhunt/src/gpuhunt/providers/nebius.py
================
import datetime
import logging
import re
import time
from collections import defaultdict
from typing import Literal, Optional, TypedDict

import bs4
import jwt
import requests

from gpuhunt import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
API_URL = "api.ai.nebius.cloud"
COMPUTE_SERVICE_ID = "bfa2pas77ftg9h3f2djj"
GPU_NAME_PLATFORM = {
    "A100": "gpu-standard-v3",
    "H100 PCIe": "standard-v3-h100-pcie",
    "Hopper H100 SXM (Type A)": "gpu-h100",
    "Hopper H100 SXM (Type B)": "gpu-h100-b",
    "L4": "standard-v3-l4",
    "L40": "standard-v3-l40",
    None: "standard-v2",
}
GPU_PLATFORMS = {
    "gpu-standard-v3": [
        [28, 119.0, 1, "A100", 80.0],
        [56, 238.0, 2, "A100", 80.0],
        [112, 476.0, 4, "A100", 80.0],
        [224, 952.0, 8, "A100", 80.0],
    ],
    "gpu-h100": [
        [20, 160.0, 1, "H100", 80.0],
        [40, 320.0, 2, "H100", 80.0],
        [80, 640.0, 4, "H100", 80.0],
        [160, 1280.0, 8, "H100", 80.0],
    ],
    "gpu-h100-b": [
        [20, 160.0, 1, "H100", 80.0],
        [40, 320.0, 2, "H100", 80.0],
        [80, 640.0, 4, "H100", 80.0],
        [160, 1280.0, 8, "H100", 80.0],
    ],
    "standard-v3-h100-pcie": [
        [24, 96.0, 1, "H100", 80.0],
        [48, 192.0, 2, "H100", 80.0],
    ],
    "standard-v3-l4": [
        [4, 16.0, 1, "L4", 24.0],
        [8, 32.0, 1, "L4", 24.0],
        [12, 48.0, 1, "L4", 24.0],
        [16, 64.0, 1, "L4", 24.0],
        [24, 96.0, 1, "L4", 24.0],
        [24, 96.0, 2, "L4", 24.0],
        [48, 192.0, 2, "L4", 24.0],
    ],
    "standard-v3-l40": [
        [8, 32.0, 1, "L40", 48.0],
        [12, 48.0, 1, "L40", 48.0],
        [16, 64.0, 1, "L40", 48.0],
        [24, 96.0, 1, "L40", 48.0],
        [48, 192.0, 2, "L40", 48.0],
    ],
}
CPU_PLATFORMS = {
    "standard-v2": {
        "cpus": [
            2,
            4,
            6,
            8,
            10,
            12,
            14,
            16,
            20,
            24,
            28,
            32,
            36,
            40,
            44,
            48,
            52,
            56,
            60,
        ],
        "ratios": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],
    }
}


class NebiusProvider(AbstractProvider):
    NAME = "nebius"

    def __init__(self, service_account: "ServiceAccount"):
        self.api_client = NebiusAPIClient(service_account)

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        zone = self.api_client.compute_zones_list()[0]["id"]
        skus = []
        page_token = None
        logger.info("Fetching SKUs")
        while True:
            page = self.api_client.billing_skus_list(
                filter=f'serviceId="{COMPUTE_SERVICE_ID}"', page_token=page_token
            )
            skus += page["skus"]
            page_token = page.get("nextPageToken")
            if page_token is None:
                break
        platform_resources = self.aggregate_skus(skus)
        offers = self.get_gpu_platforms(zone, platform_resources)
        offers += self.get_cpu_platforms(zone, platform_resources)
        return sorted(offers, key=lambda i: i.price)

    @staticmethod
    def get_gpu_platforms(
        zone: str, platform_resources: "PlatformResourcePrice"
    ) -> list[RawCatalogItem]:
        items = []
        for platform, presets in GPU_PLATFORMS.items():
            prices = platform_resources[platform]
            for cpu, memory, gpu_count, gpu_name, gpu_memory in presets:
                if "cpu" not in prices:
                    continue
                items.append(
                    RawCatalogItem(
                        instance_name=platform,
                        location=zone,
                        price=round(
                            cpu * prices["cpu"]
                            + memory * prices["ram"]
                            + gpu_count * prices["gpu"],
                            5,
                        ),
                        cpu=cpu,
                        memory=memory,
                        gpu_vendor=None,
                        gpu_count=gpu_count,
                        gpu_name=gpu_name,
                        gpu_memory=gpu_memory,
                        spot=False,
                        disk_size=None,
                    )
                )
        return items

    @staticmethod
    def get_cpu_platforms(
        zone: str, platform_resources: "PlatformResourcePrice"
    ) -> list[RawCatalogItem]:
        items = []
        for platform, limits in CPU_PLATFORMS.items():
            prices = platform_resources[platform]
            if "cpu" not in prices:
                continue
            for ratio in limits["ratios"]:
                for cpu in limits["cpus"]:
                    items.append(
                        RawCatalogItem(
                            instance_name=platform,
                            location=zone,
                            price=round(cpu * prices["cpu"] + cpu * ratio * prices["ram"], 5),
                            cpu=cpu,
                            memory=cpu * ratio,
                            gpu_vendor=None,
                            gpu_count=0,
                            gpu_name=None,
                            gpu_memory=None,
                            spot=False,
                            disk_size=None,
                        )
                    )
        return items

    @staticmethod
    def parse_gpu_platforms(raw_html: str) -> dict[str, list[list]]:
        """Parse GPU platforms from Nebius docs.

        Returns:
            Dict of platform name to a list of presets.
            Each preset contains: [cpu, memory, gpu_count, gpu_name, gpu_memory]
        """
        soup = bs4.BeautifulSoup(raw_html, "html.parser")
        configs = soup.find("h2", id="config").find_next_sibling("ul").find_all("li")
        platforms = {}
        for li in configs:
            platform = li.find("p").find("code").text
            gpu_name = re.search(r" ([A-Z]+\d+)[ \n]", li.find("p").text).group(1)
            items = []
            for tr in li.find("tbody").find_all("tr"):
                tds = tr.find_all("td")
                gpu_count = int(tds[0].text.strip(" *"))
                items.append(
                    [
                        int(tds[2].text),
                        float(tds[3].text),
                        gpu_count,
                        gpu_name,
                        int(tds[1].text) / gpu_count,
                    ]
                )
            platforms[platform] = items
        return platforms

    @staticmethod
    def parse_cpu_platforms(raw_html: str) -> dict[str, dict[str, list]]:
        """Parse CPU platforms from Nebius docs.

        Returns:
            Dict of platform name to Dict of resource name to a list of values.
        """
        soup = bs4.BeautifulSoup(raw_html, "html.parser")
        configs = (
            soup.find(
                "p",
                string=re.compile(
                    r"The computing resources may have the following configurations:"
                ),
            )
            .find_next_sibling("ul")
            .find_all("li")
        )
        platforms = {}
        for li in configs:
            platform = li.find("p").find("code").text
            tds = li.find("tbody").find("td", string="100%").find_next_siblings("td")
            platforms[platform] = {
                "cpus": [int(i) for i in tds[0].text.translate({"\n": "", " ": ""}).split(",")],
                "ratios": [
                    float(i) for i in tds[1].text.translate({"\n": "", " ": ""}).split(",")
                ],
            }
        return platforms

    def aggregate_skus(self, skus: list[dict]) -> "PlatformResourcePrice":
        vm_resources = {
            "GPU": "gpu",
            "RAM": "ram",
            "100% vCPU": "cpu",
        }
        vm_name_re = re.compile(
            r"((?:Intel|AMD) .+?)(?: with Nvidia (.+))?"
            rf"\. ({'|'.join(vm_resources)})(?: — (preemptible).*)?$"
        )
        platform_resources = defaultdict(dict)
        for sku in skus:
            if (r := vm_name_re.match(sku["name"])) is None:
                continue  # storage, images, snapshots, infiniband
            cpu_name, gpu_name, resource_name, spot = r.groups()
            if spot is not None:
                continue
            if gpu_name not in GPU_NAME_PLATFORM:
                logger.warning("Unknown GPU name: %s", gpu_name)
                continue
            platform_resources[GPU_NAME_PLATFORM[gpu_name]][vm_resources[resource_name]] = (
                self.get_sku_price(sku["pricingVersions"])
            )

        return platform_resources

    @staticmethod
    def get_sku_price(pricing_versions: list[dict]) -> Optional[float]:
        now = datetime.datetime.now(datetime.timezone.utc)
        price = None
        for version in sorted(pricing_versions, key=lambda p: p["effectiveTime"]):
            # I guess it's the price for on-demand instances
            if version["type"] != "STREET_PRICE":
                continue
            if datetime.datetime.fromisoformat(version["effectiveTime"]) > now:
                break
            # I guess we should take the first pricing expression
            price = float(version["pricingExpressions"][0]["rates"][0]["unitPrice"])
        return price


class NebiusAPIClient:
    # reference: https://nebius.ai/docs/api-design-guide/
    def __init__(self, service_account: "ServiceAccount"):
        self._service_account = service_account
        self._s = requests.Session()
        self._expires_at = 0

    def get_token(self):
        now = int(time.time())
        if now + 60 < self._expires_at:
            return
        logger.debug("Refreshing IAM token")
        expires_at = now + 3600
        payload = {
            "aud": self.url("iam", "/tokens"),
            "iss": self._service_account["service_account_id"],
            "iat": now,
            "exp": expires_at,
        }
        jwt_token = jwt.encode(
            payload,
            self._service_account["private_key"],
            algorithm="PS256",
            headers={"kid": self._service_account["id"]},
        )

        resp = requests.post(payload["aud"], json={"jwt": jwt_token}, timeout=10)
        resp.raise_for_status()
        iam_token = resp.json()["iamToken"]
        self._s.headers["Authorization"] = f"Bearer {iam_token}"
        self._expires_at = expires_at

    def billing_skus_list(
        self,
        filter: Optional[str] = None,
        page_size: Optional[int] = 1000,
        page_token: Optional[str] = None,
    ) -> "BillingSkusListResponse":
        logger.debug("Fetching SKUs")
        params = {
            "currency": "USD",
            "pageSize": page_size,
        }
        if filter is not None:
            params["filter"] = filter
        if page_token is not None:
            params["pageToken"] = page_token
        self.get_token()
        resp = self._s.get(self.url("billing", "/skus"), params=params)
        resp.raise_for_status()
        return resp.json()

    def compute_zones_list(self) -> list[dict]:
        logger.debug("Fetching compute zones")
        self.get_token()
        resp = self._s.get(self.url("compute", "/zones"))
        resp.raise_for_status()
        return resp.json()["zones"]

    def url(self, service: str, path: str, version="v1") -> str:
        return f"https://{service}.{API_URL.rstrip('/')}/{service}/{version}/{path.lstrip('/')}"


class ServiceAccount(TypedDict):
    id: str
    service_account_id: str
    created_at: str
    key_algorithm: str
    public_key: str
    private_key: str


class BillingSkusListResponse(TypedDict):
    skus: list[dict]
    nextPageToken: Optional[str]


PlatformResourcePrice = dict[str, dict[Literal["cpu", "ram", "gpu"], float]]

================
File: gpuhunt/src/gpuhunt/providers/oci.py
================
import logging
import re
from collections.abc import Iterable
from dataclasses import asdict, dataclass
from typing import Annotated, Optional

import oci
from oci.identity.models import Region
from pydantic import BaseModel, Field
from requests import Session
from typing_extensions import TypedDict

from gpuhunt._internal.constraints import KNOWN_NVIDIA_GPUS
from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt._internal.utils import to_camel_case
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
COST_ESTIMATOR_URL_TEMPLATE = "https://www.oracle.com/a/ocom/docs/cloudestimator2/data/{resource}"
COST_ESTIMATOR_REQUEST_TIMEOUT = 10


class OCICredentials(TypedDict):
    user: Optional[str]
    key_content: Optional[str]
    fingerprint: Optional[str]
    tenancy: Optional[str]
    region: Optional[str]


class OCIProvider(AbstractProvider):
    NAME = "oci"

    def __init__(self, credentials: OCICredentials):
        self.api_client = oci.identity.IdentityClient(
            credentials if all(credentials.values()) else oci.config.from_file()
        )
        self.cost_estimator = CostEstimator()

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        shapes = self.cost_estimator.get_shapes()
        products = self.cost_estimator.get_products()
        regions: list[Region] = self.api_client.list_regions().data

        result = []

        for shape in shapes.items:
            if (
                shape.hidden
                or shape.status != "ACTIVE"
                or shape.shape_type.value not in ("vm", "bm")
                or shape.sub_type.value not in ("standard", "gpu", "optimized")
                or ".A1." in shape.name
            ):
                continue

            try:
                resources = shape_to_resources(shape, products)
            except CostEstimatorDataError as e:
                logger.warning(
                    "Skipping shape %s due to unexpected Cost Estimator data: %s", shape.name, e
                )
                continue

            catalog_item = RawCatalogItem(
                instance_name=shape.name,
                location=None,
                price=resources.total_price(),
                cpu=resources.cpu.vcpus,
                memory=resources.memory.gbs,
                gpu_vendor=None,
                gpu_count=resources.gpu.units_count,
                gpu_name=resources.gpu.name,
                gpu_memory=resources.gpu.unit_memory_gb,
                spot=False,
                disk_size=None,
            )
            result.extend(self._duplicate_item_in_regions(catalog_item, regions))

        return sorted(result, key=lambda i: i.price)

    @staticmethod
    def _duplicate_item_in_regions(
        item: RawCatalogItem, regions: Iterable[Region]
    ) -> list[RawCatalogItem]:
        result = []
        for region in regions:
            regional_item = RawCatalogItem(**item.dict())
            regional_item.location = region.name
            result.append(regional_item)
        return result


class CostEstimatorTypeField(BaseModel):
    value: str


class CostEstimatorShapeProduct(BaseModel):
    type: CostEstimatorTypeField
    part_number: str
    qty: int

    class Config:
        alias_generator = to_camel_case


class CostEstimatorShape(BaseModel):
    name: str
    hidden: bool
    status: str
    bundle_memory_qty: int
    gpu_qty: Optional[int]
    gpu_memory_qty: Optional[int]
    processor_type: CostEstimatorTypeField
    shape_type: CostEstimatorTypeField
    sub_type: CostEstimatorTypeField
    products: list[CostEstimatorShapeProduct]

    class Config:
        alias_generator = to_camel_case

    def is_arm_cpu(self):
        is_ampere_gpu = self.sub_type.value == "gpu" and (
            "GPU4" in self.name or "GPU.A10" in self.name
        )
        # the data says A10 and A100 GPU instances are ARM, but they are not
        return self.processor_type.value == "arm" and not is_ampere_gpu

    def get_gpu_unit_memory_gb(self) -> Optional[float]:
        if self.gpu_memory_qty and self.gpu_qty:
            return self.gpu_memory_qty / self.gpu_qty
        return None


class CostEstimatorShapeList(BaseModel):
    items: list[CostEstimatorShape]


class CostEstimatorPrice(BaseModel):
    model: str
    value: float


class CostEstimatorPriceLocalization(BaseModel):
    currency_code: str
    prices: list[CostEstimatorPrice]

    class Config:
        alias_generator = to_camel_case


class CostEstimatorProduct(BaseModel):
    part_number: str
    billing_model: str
    price_type: Annotated[str, Field(alias="pricetype")]
    currency_code_localizations: list[CostEstimatorPriceLocalization]

    class Config:
        alias_generator = to_camel_case

    def find_price_l10n(self, currency_code: str) -> Optional[CostEstimatorPriceLocalization]:
        return next(
            filter(
                lambda price: price.currency_code == currency_code,
                self.currency_code_localizations,
            ),
            None,
        )


class CostEstimatorProductList(BaseModel):
    items: list[CostEstimatorProduct]

    def find(self, part_number: str) -> Optional[CostEstimatorProduct]:
        return next(filter(lambda product: product.part_number == part_number, self.items), None)


class CostEstimator:
    def __init__(self):
        self.session = Session()

    def get_shapes(self) -> CostEstimatorShapeList:
        return self._get("shapes.json", CostEstimatorShapeList)

    def get_products(self) -> CostEstimatorProductList:
        return self._get("products.json", CostEstimatorProductList)

    def _get(self, resource: str, ResponseModel: type[BaseModel]):
        url = COST_ESTIMATOR_URL_TEMPLATE.format(resource=resource)
        resp = self.session.get(url, timeout=COST_ESTIMATOR_REQUEST_TIMEOUT)
        resp.raise_for_status()
        return ResponseModel.parse_raw(resp.content)


class CostEstimatorDataError(Exception):
    pass


@dataclass
class CPUConfiguration:
    vcpus: int
    price: float


@dataclass
class MemoryConfiguration:
    gbs: int
    price: float


@dataclass
class GPUConfiguration:
    units_count: int
    unit_memory_gb: Optional[float]
    name: Optional[str]
    price: float

    def __post_init__(self):
        d = asdict(self)
        if any(d.values()) and not all(d.values()):
            raise CostEstimatorDataError(f"Incomplete GPU parameters: {self}")


@dataclass
class ResourcesConfiguration:
    cpu: CPUConfiguration
    memory: MemoryConfiguration
    gpu: GPUConfiguration

    def total_price(self) -> float:
        return self.cpu.price + self.memory.price + self.gpu.price


def shape_to_resources(
    shape: CostEstimatorShape, products: CostEstimatorProductList
) -> ResourcesConfiguration:
    cpu = None
    gpu = GPUConfiguration(units_count=0, unit_memory_gb=None, name=None, price=0.0)
    memory = MemoryConfiguration(gbs=shape.bundle_memory_qty, price=0.0)

    for product in shape.products:
        product_details = products.find(product.part_number)
        if product_details is None:
            raise CostEstimatorDataError(f"Could not find product {product.part_number!r}")
        product_price = get_product_price_usd_per_hour(product_details)

        if product.type.value == "ocpu":
            vcpus = product.qty if shape.is_arm_cpu() else product.qty * 2
            if shape.gpu_qty:
                gpu = GPUConfiguration(
                    units_count=shape.gpu_qty,
                    unit_memory_gb=shape.get_gpu_unit_memory_gb(),
                    name=get_gpu_name(shape.name),
                    price=product_price * shape.gpu_qty,
                )
                cpu = CPUConfiguration(vcpus=vcpus, price=0.0)
            else:
                cpu = CPUConfiguration(vcpus=vcpus, price=product_price * product.qty)

        elif product.type.value == "memory":
            memory = MemoryConfiguration(gbs=product.qty, price=product_price * product.qty)

        else:
            raise CostEstimatorDataError(f"Unknown product type {product.type.value!r}")

    if cpu is None:
        raise CostEstimatorDataError("No ocpu product")

    return ResourcesConfiguration(cpu, memory, gpu)


def get_product_price_usd_per_hour(product: CostEstimatorProduct) -> float:
    if product.billing_model != "UCM":
        raise CostEstimatorDataError(
            f"Billing model for product {product.part_number!r} is {product.billing_model!r}"
        )
    if product.price_type != "HOUR":
        raise CostEstimatorDataError(
            f"Price type for product {product.part_number!r} is {product.price_type!r}"
        )
    price_l10n = product.find_price_l10n("USD")
    if price_l10n is None:
        raise CostEstimatorDataError(f"No USD price for product {product.part_number!r}")
    if len(price_l10n.prices) != 1:
        raise CostEstimatorDataError(
            f"Product {product.part_number!r} has {len(price_l10n.prices)} USD prices"
        )
    price = price_l10n.prices[0]
    if price.model != "PAY_AS_YOU_GO":
        raise CostEstimatorDataError(
            f"Pricing model for product {product.part_number!r} is {price.model!r}"
        )
    return price.value


def get_gpu_name(shape_name: str) -> Optional[str]:
    parts = re.split(r"[\.-]", shape_name.upper())

    if "GPU4" in parts:
        return "A100"
    if "GPU3" in parts:
        return "V100"
    if "GPU2" in parts:
        return "P100"

    if "GPU" in parts:
        gpu_name_index = parts.index("GPU") + 1
        if gpu_name_index < len(parts):
            gpu_name = parts[gpu_name_index]

            for gpu in KNOWN_NVIDIA_GPUS:
                if gpu.name.upper() == gpu_name:
                    return gpu.name
    return None

================
File: gpuhunt/src/gpuhunt/providers/runpod.py
================
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from itertools import chain
from typing import Optional

import requests
from requests import RequestException

from gpuhunt._internal.constraints import KNOWN_AMD_GPUS
from gpuhunt._internal.models import AcceleratorVendor, QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
API_URL = "https://api.runpod.io/graphql"


class RunpodProvider(AbstractProvider):
    NAME = "runpod"

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        offers = self.fetch_offers()
        return sorted(offers, key=lambda i: i.price)

    def fetch_offers(self) -> list[RawCatalogItem]:
        offers = [get_raw_catalog(pod_type) for pod_type in self.list_pods()]
        return list(chain.from_iterable(offers))

    @staticmethod
    def list_pods() -> list[dict]:
        payload_gpu_types = {"query": gpu_types_query, "variables": {}}
        try:
            gpu_types = make_request(payload_gpu_types)
        except RequestException as e:
            logger.exception("Failed to make request for GPU types: %s", e)
            raise

        with ThreadPoolExecutor(max_workers=10) as executor:
            futures = [
                executor.submit(get_pods, query_variable)
                for query_variable in build_query_variables(gpu_types)
            ]
        offers = []
        for future in as_completed(futures):
            try:
                result = future.result()
                offers.append(result)
            except RequestException as e:
                logger.exception("Failed to get pods data: %s", e)
        return list(chain.from_iterable(offers))


def gpu_vendor_and_name(gpu_id: str) -> Optional[tuple[AcceleratorVendor, str]]:
    if not gpu_id:
        return None
    return GPU_MAP.get(gpu_id)


def build_query_variables(gpu_types: list[dict]) -> list[dict]:
    # Filter dataCenters by 'listed: True'
    listed_data_centers = [dc["id"] for dc in gpu_types["data"]["dataCenters"] if dc["listed"]]

    # Find the maximum of maxGpuCount
    max_gpu_count = max(gpu["maxGpuCount"] for gpu in gpu_types["data"]["gpuTypes"])

    # Generate the variables list
    variables = []
    for dc_id in listed_data_centers:
        for gpu_count in range(1, max_gpu_count + 1):
            variables.append(
                {
                    "dataCenterId": dc_id,
                    "gpuCount": gpu_count,  # gpuCount is mandatory
                    "minDisk": None,
                    "minMemoryInGb": None,
                    "minVcpuCount": None,
                    "secureCloud": None,
                }
            )

    return variables


def get_pods(query_variable: dict) -> list[dict]:
    pods = make_request(get_pods_query_payload(query_variable))["data"]["gpuTypes"]
    offers = []
    for pod in pods:
        listed_gpu_vendor_and_name = gpu_vendor_and_name(pod["id"])
        availability = pod["lowestPrice"]["stockStatus"]
        if listed_gpu_vendor_and_name is not None and availability is not None:
            offers.append(
                get_offers(
                    pod,
                    data_center_id=query_variable["dataCenterId"],
                    gpu_count=query_variable["gpuCount"],
                    gpu_vendor=listed_gpu_vendor_and_name[0],
                    gpu_name=listed_gpu_vendor_and_name[1],
                )
            )
        elif listed_gpu_vendor_and_name is None and availability is not None:
            logger.warning(f"{pod['id']} missing in runpod GPU_MAP")
    return offers


def get_offers(
    pod: dict, *, data_center_id, gpu_count, gpu_vendor: AcceleratorVendor, gpu_name: str
) -> dict:
    return {
        "id": pod["id"],
        "data_center_id": data_center_id,
        "secure_price": pod["securePrice"],
        "secure_spot_price": pod["secureSpotPrice"],
        "community_price": pod["communityPrice"],
        "community_spot_price": pod["communitySpotPrice"],
        "cpu": pod["lowestPrice"]["minVcpu"],
        "memory": pod["lowestPrice"]["minMemory"],
        "gpu": gpu_count,
        "display_name": pod["displayName"],
        "gpu_memory": pod["memoryInGb"],
        "gpu_vendor": gpu_vendor.value,
        "gpu_name": gpu_name,
    }


def get_pods_query_payload(query_variable: dict) -> dict:
    payload_secure_gpu_types = {
        "query": query_pod_types,
        "variables": {"lowestPriceInput": query_variable},
    }
    return payload_secure_gpu_types


def make_request(payload: dict):
    resp = requests.post(API_URL, json=payload, timeout=10)
    if resp.ok:
        data = resp.json()
        return data
    resp.raise_for_status()


def get_raw_catalog(offer: dict) -> list[RawCatalogItem]:
    catalog_items = []

    if offer["secure_price"] is not None:
        catalog_items.append(
            RawCatalogItem(
                instance_name=offer["id"],
                location=offer["data_center_id"],
                price=float(offer["secure_price"] * offer["gpu"]),
                cpu=offer["cpu"],
                memory=offer["memory"],
                gpu_vendor=offer["gpu_vendor"],
                gpu_count=offer["gpu"],
                gpu_name=offer["gpu_name"],
                gpu_memory=offer["gpu_memory"],
                spot=False,
                disk_size=None,
            )
        )
    if (offer["secure_spot_price"] or 0) > 0:
        catalog_items.append(
            RawCatalogItem(
                instance_name=offer["id"],
                location=offer["data_center_id"],
                price=float(offer["secure_spot_price"] * offer["gpu"]),
                cpu=offer["cpu"],
                memory=offer["memory"],
                gpu_vendor=offer["gpu_vendor"],
                gpu_count=offer["gpu"],
                gpu_name=offer["gpu_name"],
                gpu_memory=offer["gpu_memory"],
                spot=True,
                disk_size=None,
            )
        )

    return catalog_items


def get_gpu_map() -> dict[str, tuple[AcceleratorVendor, str]]:
    payload_gpus = {
        "query": "query GpuTypes { gpuTypes { id manufacturer displayName memoryInGb } }"
    }
    response = make_request(payload_gpus)
    gpu_map: dict[str, tuple[AcceleratorVendor, str]] = {}
    for gpu_type in response["data"]["gpuTypes"]:
        try:
            vendor = AcceleratorVendor.cast(gpu_type["manufacturer"])
        except ValueError:
            continue
        gpu_name = get_gpu_name(vendor, gpu_type["displayName"])
        if gpu_name:
            gpu_map[gpu_type["id"]] = (vendor, gpu_name)
    return gpu_map


def get_gpu_name(vendor: AcceleratorVendor, name: str) -> Optional[str]:
    if vendor == AcceleratorVendor.NVIDIA:
        return get_nvidia_gpu_name(name)
    if vendor == AcceleratorVendor.AMD:
        return get_amd_gpu_name(name)
    return None


def get_nvidia_gpu_name(name: str) -> Optional[str]:
    if "V100" in name:
        return "V100"
    if name == "H100 NVL":
        return "H100NVL"
    if name.startswith(("A", "L", "H")):
        gpu_name, _, _ = name.partition(" ")
        return gpu_name
    if name.startswith("RTX A"):
        return name.lstrip("RTX ").replace(" ", "")
    if name.startswith("RTX"):
        return name.replace(" ", "")
    return None


def get_amd_gpu_name(name: str) -> Optional[str]:
    for gpu in KNOWN_AMD_GPUS:
        if gpu.name == name:
            return name
    return None


GPU_MAP = get_gpu_map()

gpu_types_query = """
query GpuTypes {
  countryCodes
  dataCenters {
    id
    name
    listed
    __typename
  }
  gpuTypes {
    maxGpuCount
    maxGpuCount
    maxGpuCountCommunityCloud
    maxGpuCountSecureCloud
    minPodGpuCount
    id
    displayName
    memoryInGb
    secureCloud
    communityCloud
    __typename
  }
}
"""

query_pod_types = """
query GpuTypes($lowestPriceInput: GpuLowestPriceInput, $gpuTypesInput: GpuTypeFilter) {
  gpuTypes(input: $gpuTypesInput) {
    lowestPrice(input: $lowestPriceInput) {
      minimumBidPrice
      uninterruptablePrice
      minVcpu
      minMemory
      stockStatus
      compliance
      countryCode
      __typename
    }
    maxGpuCount
    id
    displayName
    memoryInGb
    securePrice
    secureSpotPrice
    communityPrice
    communitySpotPrice
    oneMonthPrice
    threeMonthPrice
    sixMonthPrice
    secureSpotPrice
    __typename
  }
}
"""

================
File: gpuhunt/src/gpuhunt/providers/scaleway.py
================
import logging
from typing import List, Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers.scraper import ScraperProvider

logger = logging.getLogger(__name__)

class ScalewayProvider(ScraperProvider):
    """Provider for Scaleway GPU instances using web scraping"""
    
    NAME = "scaleway"

    def __init__(self):
        super().__init__()

    @property
    def urls(self) -> List[str]:
        return ["https://www.scaleway.com/en/pricing/gpu/"]

    @property
    def prompt(self) -> str:
        return """
        Extract all GPU instances from the Scaleway pricing page. For each GPU instance, provide:
        1. GPU model name (e.g. A4000, A5000, H100) - remove any vendor prefix
        2. GPU memory in GB (as a number)
        3. Number of GPUs per instance (as a number)
        4. Price per hour in USD (convert from EUR using 1 EUR = 1.10 USD, return as a number)
        5. Location (either Paris or Amsterdam)
        6. Number of CPU cores (as a number)
        7. System RAM in GB (as a number)
        8. Disk size in GB if available (as a number)

        Important:
        - Return ALL GPU instances you find
        - If a GPU name has a format like "L40s-1-48G", convert it to just "L40"
        - All numeric values should be numbers, not strings
        - Prices should be in USD (multiply EUR by 1.10)
        - The vendor is always "NVIDIA" unless explicitly stated as AMD
        
        Return the data in this format:
        {
          "gpus": [
            {
              "name": "A4000",
              "memory": 16,
              "count": 1,
              "price": 1.50,
              "location": "Paris",
              "cpu": 8,
              "ram": 32,
              "disk": 256,
              "spot": false,
              "vendor": "NVIDIA"
            },
            ... additional GPUs ...
          ]
        }
        """

================
File: gpuhunt/src/gpuhunt/providers/scraper.py
================
from cmd import PROMPT
import logging
import os
from typing import Optional, Dict, Any, List
import json
import requests
from abc import ABC, abstractmethod
from dataclasses import dataclass
import openai
from openai import OpenAI
from pydantic import BaseModel, Field
from gpuhunt._internal.models import QueryFilter, RawCatalogItem, AcceleratorVendor
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

@dataclass
class GPUInfo:
    """Information about a GPU offering from a provider"""
    name: str
    memory: float
    count: int
    price: float
    location: str
    cpu: int
    ram: float
    disk: Optional[float] = None
    spot: bool = False
    vendor: AcceleratorVendor = AcceleratorVendor.NVIDIA

class GPUSchema(BaseModel):
    """Schema for GPU information extraction"""
    name: str = Field(description="Name of the GPU, name can only be the model of the GPU, without the name of the manufacturer, ie: Nvidia H100->H100; AMD MIX3000 -> MIX3000 ")
    memory: float = Field(description="Memory of the GPU in GB")
    count: int = Field(description="Number of GPUs")
    price: float = Field(description="Price per hour in USD.")
    location: str = Field(description="Location/region of the GPU")
    cpu: int = Field(description="Number of CPU cores")
    ram: float = Field(description="Amount of RAM in GB")
    disk: Optional[float] = Field(None, description="Disk size in GB")

class WebScraper:
    """Base scraper that uses requests and OpenAI to extract GPU information"""

    def __init__(self, openai_api_key: Optional[str] = None):
        """Initialize the scraper
        
        Args:
            openai_api_key: OpenAI API key. If not provided, will try to get from OPENAI_API_KEY env var
        """
        self.api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY environment variable must be set")
        
        self.client = OpenAI(api_key=self.api_key)
        # Cache for scraped results
        self._cache: Dict[str, list[Dict[str, Any]]] = {}

    def scrape_url(self, url: str, prompt: str, override_content: Optional[str] = None) -> List[GPUInfo]:
        """Scrape GPU information from a URL or provided content
        
        Args:
            url: URL to scrape (or API endpoint if using override_content)
            prompt: Custom prompt for the scraper
            override_content: Optional content to use instead of scraping the URL
            
        Returns:
            List of GPUInfo objects containing GPU information
        """
        if url in self._cache:
            raw_results = self._cache[url]
        else:
            try:
                # Get the content either from override or by scraping
                content = override_content
                if content is None:
                    # Get the webpage content
                    headers = {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                    }
                    response = requests.get(url, headers=headers, timeout=30)
                    response.raise_for_status()
                    content = response.text

                # Use OpenAI to extract structured data
                messages = [
                    {"role": "system", "content": "You are a helpful assistant that extracts GPU information from webpages and returns it as JSON. Be sure to convert monthly prices to hourly by dividing by (24 * 30)."},
                    {"role": "user", "content": f"Here is the content. Extract the information and return it as JSON:\n\n{content}\n\n{prompt}"}
                ]
                
                completion = self.client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=messages,
                    temperature=0,
                    response_format={"type": "json_object"}
                )
                
                result = json.loads(completion.choices[0].message.content)
                # logger.info(f"Raw OpenAI result: {result}")
                
                # Expect result to be a list of GPU instances
                raw_results = result.get('gpus', [])
                if not isinstance(raw_results, list):
                    raw_results = [raw_results]
                
                # Cache the results
                self._cache[url] = raw_results

            except Exception as e:
                logger.error(f"Error scraping {url}: {str(e)}")
                return []

        # Convert raw results to GPUInfo objects
        logger.info(f"Scraped {len(raw_results)} GPUs from {url}")
        gpu_infos = []
        for result in raw_results:
            # Skip entries with all None values
            if all(result.get(k) is None for k in ["name", "memory", "count", "price", "cpu", "ram"]):
                continue
                
            try:
                gpu_infos.append(GPUInfo(
                    name=result.get("name", "Unknown"),
                    memory=float(result.get("memory", 0)),
                    count=int(result.get("count", 1)),
                    price=float(result.get("price", 0)),
                    location=result.get("location", "Unknown"),
                    cpu=int(result.get("cpu", 0)),
                    ram=float(result.get("ram", 0)),
                    disk=float(result.get("disk")) if result.get("disk") else None,
                    spot=bool(result.get("spot", False)),
                    vendor=AcceleratorVendor.AMD if result.get("vendor", "").upper() == "AMD" else AcceleratorVendor.NVIDIA
                ))
            except (ValueError, TypeError) as e:
                logger.error(f"Error parsing GPU info {result}: {str(e)}")
                continue
                
        return gpu_infos

class ScraperProvider(AbstractProvider, ABC):
    """Base class for providers that use web scraping"""
    
    def __init__(self, openai_api_key: Optional[str] = None):
        """Initialize the scraper provider
        
        Args:
            openai_api_key: OpenAI API key. If not provided, will try to get from OPENAI_API_KEY env var
        """
        self.scraper = WebScraper(openai_api_key)

    @property
    @abstractmethod
    def urls(self) -> List[str]:
        """URLs to scrape"""
        pass

    @property
    @abstractmethod
    def prompt(self) -> str:
        """Custom prompt for the scraper"""
        pass

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        """Get GPU offerings from all configured URLs
        
        Args:
            query_filter: Optional filter for the results
            balance_resources: Whether to balance resources based on GPU specs
            
        Returns:
            List of RawCatalogItem objects
        """
        all_gpus = []
        for url in self.urls:
            gpus = self.scraper.scrape_url(url, self.prompt)
            all_gpus.extend(gpus)

        # Convert GPUInfo objects to RawCatalogItem objects
        offers = []
        for gpu in all_gpus:
            offer = RawCatalogItem(
                instance_name=f"{gpu.name}-{gpu.count}x",
                location=gpu.location,
                price=gpu.price,
                cpu=gpu.cpu,
                memory=gpu.ram,
                gpu_vendor=gpu.vendor,
                gpu_count=gpu.count,
                gpu_name=gpu.name,
                gpu_memory=gpu.memory,
                spot=gpu.spot,
                disk_size=gpu.disk,
            )
            offers.append(offer)

        return sorted(offers, key=lambda i: i.price)

================
File: gpuhunt/src/gpuhunt/providers/seeweb.py
================
import logging
from typing import List, Optional

from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers.scraper import ScraperProvider

logger = logging.getLogger(__name__)

class SeewebProvider(ScraperProvider):
    """Provider for Seeweb GPU instances using web scraping"""
    
    NAME = "seeweb"

    def __init__(self):
        super().__init__()

    @property
    def urls(self) -> List[str]:
        return ["https://www.seeweb.it/en/products/cloud-server-gpu"]

    @property
    def prompt(self) -> str:
        return """
        Extract all GPU instances from the Seeweb GPU Cloud Server pricing page. For each GPU instance, provide:
        1. GPU model name (e.g. A4000, A5000, A6000) - remove any vendor prefix
        2. GPU memory in GB (as a number)
        3. Number of GPUs per instance (as a number)
        4. Price per hour in USD (convert from EUR using 1 EUR = 1.10 USD, return as a number)
        5. Location (set to "Italy" as all instances are in Italy)
        6. Number of CPU cores (as a number)
        7. System RAM in GB (as a number)
        8. Disk size in GB if available (as a number)

        Important:
        - Return ALL GPU instances you find
        - All numeric values should be numbers, not strings
        - Convert monthly prices to hourly by dividing by (24 * 30)
        - Convert EUR to USD by multiplying by 1.10
        - The vendor is always "NVIDIA"
        - Pay attention to both vCPU and RAM specifications
        - Look for SSD/NVMe storage sizes
        
        Return the data in this format:
        {
          "gpus": [
            {
              "name": "A4000",
              "memory": 16,
              "count": 1,
              "price": 1.50,
              "location": "Italy",
              "cpu": 8,
              "ram": 32,
              "disk": 100,
              "spot": false,
              "vendor": "NVIDIA"
            },
            ... additional GPUs ...
          ]
        }
        """

================
File: gpuhunt/src/gpuhunt/providers/tensordock.py
================
import logging
from math import ceil
from typing import Optional, TypeVar, Union

import requests

from gpuhunt._internal.constraints import get_compute_capability, is_between
from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

# https://documenter.getpostman.com/view/20973002/2s8YzMYRDc#2b4a3db0-c162-438c-aae4-6a88afc96fdb
marketplace_hostnodes_url = "https://marketplace.tensordock.com/api/v0/client/deploy/hostnodes"
marketplace_gpus = {
    "a100-pcie-80gb": "A100",
    "geforcegtx1070-pcie-8gb": "GTX1070",
    "geforcertx3060-pcie-12gb": "RTX3060",
    "geforcertx3060ti-pcie-8gb": "RTX3060Ti",
    "geforcertx3060tilhr-pcie-8gb": "RTX3060TiLHR",
    "geforcertx3070-pcie-8gb": "RTX3070",
    "geforcertx3070ti-pcie-8gb": "RTX3070Ti",
    "geforcertx3080-pcie-10gb": "RTX3080",
    "geforcertx3080ti-pcie-12gb": "RTX3080Ti",
    "geforcertx3090-pcie-24gb": "RTX3090",
    "geforcertx4090-pcie-24gb": "RTX4090",
    "l40-pcie-48gb": "L40",
    "rtxa4000-pcie-16gb": "A4000",
    "rtxa5000-pcie-24gb": "A5000",
    "rtxa6000-pcie-48gb": "A6000",
    "v100-pcie-16gb": "V100",
}

RAM_PER_VRAM = 2
RAM_PER_CORE = 6
CPU_DIV = 2  # has to be even
RAM_DIV = 2  # has to be even


class TensorDockProvider(AbstractProvider):
    NAME = "tensordock"

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        logger.info("Fetching TensorDock offers")

        hostnodes = requests.get(marketplace_hostnodes_url, timeout=10).json()["hostnodes"]
        offers = []
        for hostnode, details in hostnodes.items():
            location = details["location"]["country"].lower().replace(" ", "")
            if query_filter is not None:
                offers += self.optimize_offers(
                    query_filter,
                    details["specs"],
                    hostnode,
                    location,
                    balance_resources=balance_resources,
                )
            else:  # pick maximum possible configuration
                for gpu_name, gpu in details["specs"]["gpu"].items():
                    if gpu["amount"] == 0:
                        continue
                    offers.append(
                        RawCatalogItem(
                            instance_name=hostnode,
                            location=location,
                            price=round(
                                sum(
                                    details["specs"][key]["price"]
                                    * details["specs"][key]["amount"]
                                    for key in ("cpu", "ram", "storage")
                                )
                                + gpu["amount"] * gpu["price"],
                                5,
                            ),
                            cpu=round_down(details["specs"]["cpu"]["amount"], 2),
                            memory=float(round_down(details["specs"]["ram"]["amount"], 2)),
                            gpu_vendor=None,
                            gpu_count=gpu["amount"],
                            gpu_name=convert_gpu_name(gpu_name),
                            gpu_memory=float(gpu["vram"]),
                            spot=False,
                            disk_size=float(details["specs"]["storage"]["amount"]),
                        )
                    )
        return sorted(offers, key=lambda i: i.price)

    @staticmethod
    def optimize_offers(
        q: QueryFilter,
        specs: dict,
        instance_name: str,
        location: str,
        balance_resources: bool = True,
    ) -> list[RawCatalogItem]:
        """
        Picks the best offer for the given query filter
        Doesn't respect max values, additional filtering is required

        Args:
            q: query filter
            specs: hostnode specs
            instance_name: hostnode `instance_name`
            location: hostnode `location`
            balance_resources: if True, will override query filter min values
        """
        offers = []
        for gpu_model, gpu_info in specs["gpu"].items():
            # filter by single gpu characteristics
            if not is_between(gpu_info["vram"], q.min_gpu_memory, q.max_gpu_memory):
                continue
            gpu_name = convert_gpu_name(gpu_model)
            if q.gpu_name is not None and gpu_name.lower() not in map(str.lower, q.gpu_name):
                continue
            cc = get_compute_capability(gpu_name)
            if not cc or not is_between(cc, q.min_compute_capability, q.max_compute_capability):
                continue

            for gpu_count in range(1, gpu_info["amount"] + 1):  # try all possible gpu counts
                if not is_between(gpu_count, q.min_gpu_count, q.max_gpu_count):
                    continue
                total_gpu_memory = gpu_count * gpu_info["vram"]
                if not is_between(
                    total_gpu_memory, q.min_total_gpu_memory, q.max_total_gpu_memory
                ):
                    continue

                # we can't take 100% of CPU/RAM/storage if we don't take all GPUs
                multiplier = 0.75 if gpu_count < gpu_info["amount"] else 1
                available_memory = round_down(multiplier * specs["ram"]["amount"], RAM_DIV)
                available_cpu = round_down(multiplier * specs["cpu"]["amount"], CPU_DIV)
                available_disk = int(multiplier * specs["storage"]["amount"])

                memory = None
                if q.min_memory is not None:
                    if q.min_memory > available_memory:
                        continue
                    memory = round_up(
                        max_none(
                            q.min_memory,
                            gpu_count,  # 1 GB per GPU at least
                            q.min_cpu,  # 1 GB per CPU at least
                        ),
                        RAM_DIV,
                    )
                if memory is None or balance_resources:
                    memory = max_none(
                        memory,
                        min_none(
                            available_memory,
                            round_up(RAM_PER_VRAM * total_gpu_memory, RAM_DIV),
                            round_down(q.max_memory, RAM_DIV),  # can be None
                        ),
                    )

                cpu = None
                if q.min_cpu is not None:
                    if q.min_cpu > available_cpu:
                        continue
                    # 1 CPU per GPU at least
                    cpu = round_up(max(q.min_cpu, gpu_count), CPU_DIV)
                if cpu is None or balance_resources:
                    cpu = max_none(
                        cpu,
                        min_none(
                            available_cpu,
                            round_up(ceil(memory / RAM_PER_CORE), CPU_DIV),
                            round_down(q.max_cpu, CPU_DIV),  # can be None
                        ),
                    )

                disk_size = None
                if q.min_disk_size is not None:
                    if q.min_disk_size > available_disk:
                        continue
                    disk_size = q.min_disk_size
                if disk_size is None or balance_resources:
                    disk_size = max_none(
                        disk_size,
                        min_none(
                            available_disk,
                            max(memory, total_gpu_memory),
                            q.max_disk_size,  # can be None
                        ),
                    )

                price = round(
                    memory * specs["ram"]["price"]
                    + cpu * specs["cpu"]["price"]
                    + disk_size * specs["storage"]["price"]
                    + gpu_count * gpu_info["price"],
                    5,
                )

                offer = RawCatalogItem(
                    instance_name=instance_name,
                    location=location,
                    price=price,
                    cpu=cpu,
                    memory=float(memory),
                    gpu_vendor=None,
                    gpu_name=gpu_name,
                    gpu_count=gpu_count,
                    gpu_memory=float(gpu_info["vram"]),
                    spot=False,
                    disk_size=disk_size,
                )
                offers.append(offer)
                break  # stop increasing gpu count
        return offers


def round_up(value: Optional[Union[int, float]], step: int) -> Optional[int]:
    if value is None:
        return None
    return round_down(value + step - 1, step)


def round_down(value: Optional[Union[int, float]], step: int) -> Optional[int]:
    if value is None:
        return None
    return value // step * step


T = TypeVar("T", bound=Union[int, float])


def min_none(*args: Optional[T]) -> T:
    return min(v for v in args if v is not None)


def max_none(*args: Optional[T]) -> T:
    return max(v for v in args if v is not None)


def convert_gpu_name(model: str) -> str:
    """
    >>> convert_gpu_name("geforcegtx1070-pcie-8gb")
    'GTX1070'
    >>> convert_gpu_name("geforcertx1111ti-pcie-13gb")
    'RTX1111Ti'
    >>> convert_gpu_name("a100-pcie-40gb")
    'A100'
    """
    if model in marketplace_gpus:
        return marketplace_gpus[model]
    model = model.split("-")[0]
    prefix = "geforce"
    if model.startswith(prefix):
        model = model[len(prefix) :]
    return model.upper().replace("TI", "Ti")

================
File: gpuhunt/src/gpuhunt/providers/vastai.py
================
import copy
import logging
from collections import defaultdict
from typing import Any, Literal, Optional, Union

import requests

from gpuhunt._internal.constraints import correct_gpu_memory_gib
from gpuhunt._internal.models import QueryFilter, RawCatalogItem
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)
bundles_url = "https://console.vast.ai/api/v0/bundles/"
kilo = 1000
Operators = Literal["lt", "lte", "eq", "gte", "gt"]
FilterValue = Union[int, float, str, bool]


class VastAIProvider(AbstractProvider):
    NAME = "vastai"

    def __init__(self, extra_filters: Optional[dict[str, dict[Operators, FilterValue]]] = None):
        self.extra_filters = extra_filters

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        filters: dict[str, Any] = self.make_filters(query_filter or QueryFilter())
        if self.extra_filters:
            for key, constraints in self.extra_filters.items():
                for op, value in constraints.items():
                    filters[key][op] = value
        filters["rentable"]["eq"] = True
        filters["rented"]["eq"] = False
        filters["limit"] = 1000
        filters["order"] = [["score", "desc"]]
        resp = requests.post(bundles_url, json=filters, timeout=10)
        resp.raise_for_status()
        data = resp.json()

        instance_offers = []
        for offer in data["offers"]:
            cpu_cores = offer["cpu_cores"]
            # although this is not stated in the docs, the value can be None
            if cpu_cores:
                memory = float(
                    int(offer["cpu_ram"] * offer["cpu_cores_effective"] / cpu_cores / kilo)
                )
            else:
                memory = 0.0
            disk_size = query_filter and query_filter.min_disk_size or offer["disk_space"]
            if not self.satisfies_filters(offer, filters):
                logger.warning("Offer %s does not satisfy filters", offer["id"])
                continue
            gpu_name = get_gpu_name(offer["gpu_name"])
            gpu_memory = correct_gpu_memory_gib(gpu_name, offer["gpu_ram"])
            ondemand_offer = RawCatalogItem(
                instance_name=str(offer["id"]),
                location=get_location(offer["geolocation"]),
                # storage_cost is $/gb/month
                price=round(
                    offer["dph_base"] + disk_size * offer["storage_cost"] / 30 / 24,
                    5,
                ),
                cpu=int(offer["cpu_cores_effective"]),
                memory=memory,
                gpu_vendor=None,
                gpu_count=offer["num_gpus"],
                gpu_name=gpu_name,
                gpu_memory=float(gpu_memory),
                spot=False,
                disk_size=disk_size,
            )
            instance_offers.append(ondemand_offer)

            spot_offer = copy.deepcopy(ondemand_offer)
            spot_offer.price = round(offer["min_bid"], 5)
            spot_offer.spot = True
            instance_offers.append(spot_offer)
        return instance_offers

    @staticmethod
    def make_filters(q: QueryFilter) -> dict[str, dict[Operators, FilterValue]]:
        filters = defaultdict(dict)
        if q.min_cpu is not None:
            filters["cpu_cores"]["gte"] = q.min_cpu
        if q.max_cpu is not None:
            filters["cpu_cores"]["lte"] = q.max_cpu
        if q.min_memory is not None:
            filters["cpu_ram"]["gte"] = q.min_memory * kilo
        if q.max_memory is not None:
            filters["cpu_ram"]["lte"] = q.max_memory * kilo
        if q.min_gpu_count is not None:
            filters["num_gpus"]["gte"] = q.min_gpu_count
        if q.max_gpu_count is not None:
            filters["num_gpus"]["lte"] = q.max_gpu_count
        # We cannot reliably filter by GPU memory, because it is not the same for a specific GPU model
        if q.min_disk_size is not None:
            filters["disk_space"]["gte"] = q.min_disk_size
        if q.max_disk_size is not None:
            filters["disk_space"]["lte"] = q.max_disk_size
        if q.min_price is not None:
            filters["dph_total"]["gte"] = q.min_price
        if q.max_price is not None:
            filters["dph_total"]["lte"] = q.max_price
        # TODO(egor-s): add compute capability info for all GPUs
        if q.min_compute_capability is not None:
            filters["compute_capability"]["gte"] = compute_cap(q.min_compute_capability)
        if q.max_compute_capability is not None:
            filters["compute_capability"]["lte"] = compute_cap(q.max_compute_capability)
        return filters

    @staticmethod
    def satisfies_filters(offer: dict, filters: dict[str, dict[Operators, FilterValue]]) -> bool:
        for key in filters:
            if key not in offer:
                continue
            for op, value in filters[key].items():
                if op == "lt" and offer[key] >= value:
                    return False
                if op == "lte" and offer[key] > value:
                    return False
                if op == "eq" and offer[key] != value:
                    return False
                if op == "gte" and offer[key] < value:
                    return False
                if op == "gt" and offer[key] <= value:
                    return False
        return True


def get_gpu_name(gpu_name: str) -> str:
    gpu_name = gpu_name.replace("RTX A", "A").replace("Tesla ", "").replace("Q ", "")
    if gpu_name.startswith("A100 "):
        return "A100"
    if gpu_name.startswith("H100 ") and "NVL" not in gpu_name:
        return "H100"
    return gpu_name.replace(" ", "")


def get_location(location: Optional[str]) -> str:
    if location is None:
        return ""
    try:
        city, country = location.replace(", ", ",").split(",")
        location = f"{country}-{city}"
    except ValueError:
        pass
    return location.lower().replace(" ", "")


def compute_cap(cc: tuple[int, int]) -> str:
    """
    >>> compute_cap((7, 0))
    '700'
    >>> compute_cap((7, 5))
    '750'
    """
    major, minor = cc
    return f"{major}{str(minor).ljust(2, '0')}"

================
File: gpuhunt/src/gpuhunt/providers/vultr.py
================
import logging
from typing import Any, Optional

import requests
from requests import Response

from gpuhunt import QueryFilter, RawCatalogItem
from gpuhunt._internal.constraints import KNOWN_AMD_GPUS, KNOWN_NVIDIA_GPUS
from gpuhunt._internal.models import AcceleratorVendor
from gpuhunt.providers import AbstractProvider

logger = logging.getLogger(__name__)

API_URL = "https://api.vultr.com/v2"

EXCLUSION_LIST = ["GH200"]


class VultrProvider(AbstractProvider):
    NAME = "vultr"

    def get(
        self, query_filter: Optional[QueryFilter] = None, balance_resources: bool = True
    ) -> list[RawCatalogItem]:
        offers = fetch_offers()
        return sorted(offers, key=lambda i: i.price)


def fetch_offers() -> Optional[list[RawCatalogItem]]:
    """Fetch plans with types:
    1. Cloud GPU (vcg),
    2. Bare Metal (vbm),
    3. and other CPU plans, including:
        Cloud Compute (vc2),
        High Frequency Compute (vhf),
        High Performance (vhp),
        All optimized Cloud Types (voc)"""
    bare_metal_plans_response = _make_request("GET", "/plans-metal?per_page=500")
    other_plans_response = _make_request("GET", "/plans?type=all&per_page=500")
    return convert_response_to_raw_catalog_items(bare_metal_plans_response, other_plans_response)


def convert_response_to_raw_catalog_items(
    bare_metal_plans_response: Response, other_plans_response: Response
) -> list[RawCatalogItem]:
    catalog_items = []

    bare_metal_plans = bare_metal_plans_response.json()["plans_metal"]
    other_plans = other_plans_response.json()["plans"]

    for plan in bare_metal_plans:
        for location in plan["locations"]:
            catalog_item = get_bare_metal_plans(plan, location)
            if catalog_item:
                catalog_items.append(catalog_item)

    for plan in other_plans:
        for location in plan["locations"]:
            catalog_item = get_instance_plans(plan, location)
            if catalog_item:
                catalog_items.append(catalog_item)

    return catalog_items


def get_bare_metal_plans(plan: dict, location: str) -> Optional[RawCatalogItem]:
    gpu_count, gpu_name, gpu_memory, gpu_vendor = 0, None, None, None
    if "gpu" in plan["id"]:
        if plan["id"] not in BARE_METAL_GPU_DETAILS:
            logger.warning("Skipping unknown GPU plan %s", plan["id"])
            return None
        gpu_count, gpu_name, gpu_memory = BARE_METAL_GPU_DETAILS[plan["id"]]
        if gpu_name in EXCLUSION_LIST:
            return None
        gpu_vendor = get_gpu_vendor(gpu_name)
        if gpu_vendor is None:
            logger.warning("Unknown GPU vendor for plan %s, skipping", plan["id"])
            return None
    return RawCatalogItem(
        instance_name=plan["id"],
        location=location,
        price=plan["hourly_cost"],
        cpu=plan["cpu_threads"],
        memory=plan["ram"] / 1024,
        gpu_count=gpu_count,
        gpu_name=gpu_name,
        gpu_memory=gpu_memory,
        gpu_vendor=gpu_vendor,
        spot=False,
        disk_size=plan["disk"],
    )


def get_instance_plans(plan: dict, location: str) -> Optional[RawCatalogItem]:
    plan_type = plan["type"]
    if plan_type in ["vc2", "vhf", "vhp", "voc"]:
        return RawCatalogItem(
            instance_name=plan["id"],
            location=location,
            price=plan["hourly_cost"],
            cpu=plan["vcpu_count"],
            memory=plan["ram"] / 1024,
            gpu_count=0,
            gpu_name=None,
            gpu_memory=None,
            gpu_vendor=None,
            spot=False,
            disk_size=plan["disk"],
        )
    elif plan_type == "vcg":
        gpu_name = plan["gpu_type"].split("_")[1] if "_" in plan["gpu_type"] else None
        if gpu_name in EXCLUSION_LIST:
            logger.info(f"Excluding plan with GPU {gpu_name} as it is not supported.")
            return None
        gpu_vendor = get_gpu_vendor(gpu_name)
        gpu_memory_gb = plan["gpu_vram_gb"]
        gpu_count = (
            max(1, gpu_memory_gb // get_gpu_memory(gpu_name)) if gpu_name else 0
        )  # For fractional GPU,
        # gpu_count=1
        return RawCatalogItem(
            instance_name=plan["id"],
            location=location,
            price=plan["hourly_cost"],
            cpu=plan["vcpu_count"],
            memory=plan["ram"] / 1024,
            gpu_count=gpu_count,
            gpu_name=gpu_name,
            gpu_memory=gpu_memory_gb / gpu_count,
            gpu_vendor=gpu_vendor,
            spot=False,
            disk_size=plan["disk"],
        )


def get_gpu_memory(gpu_name: str) -> float:
    if gpu_name.upper() == "A100":
        return 80  # VULTR A100 instances have 80GB
    for gpu in KNOWN_NVIDIA_GPUS:
        if gpu.name.upper() == gpu_name.upper():
            return gpu.memory

    for gpu in KNOWN_AMD_GPUS:
        if gpu.name.upper() == gpu_name.upper():
            return gpu.memory
    logger.warning(f"Unknown GPU {gpu_name}")


def get_gpu_vendor(gpu_name: Optional[str]) -> Optional[str]:
    if gpu_name is None:
        return None
    for gpu in KNOWN_NVIDIA_GPUS:
        if gpu.name.upper() == gpu_name.upper():
            return AcceleratorVendor.NVIDIA.value
    for gpu in KNOWN_AMD_GPUS:
        if gpu.name.upper() == gpu_name.upper():
            return AcceleratorVendor.AMD.value
    return None


def _make_request(method: str, path: str, data: Any = None) -> Response:
    response = requests.request(
        method=method,
        url=API_URL + path,
        json=data,
        timeout=30,
    )
    response.raise_for_status()
    return response


BARE_METAL_GPU_DETAILS = {
    "vbm-48c-1024gb-4-a100-gpu": (4, "A100", 80),
    "vbm-112c-2048gb-8-h100-gpu": (8, "H100", 80),
    "vbm-112c-2048gb-8-a100-gpu": (8, "A100", 80),
    "vbm-64c-2048gb-8-l40-gpu": (8, "L40S", 48),
    "vbm-72c-480gb-gh200-gpu": (1, "GH200", 96),
    "vbm-256c-2048gb-8-mi300x-gpu": (8, "MI300X", 192),
}

================
File: gpuhunt/src/gpuhunt/__init__.py
================
# ruff: noqa: F401
import warnings

from gpuhunt._internal.catalog import Catalog
from gpuhunt._internal.constraints import (
    KNOWN_ACCELERATORS,
    KNOWN_AMD_GPUS,
    KNOWN_NVIDIA_GPUS,
    KNOWN_TPUS,
    correct_gpu_memory_gib,
    matches,
)
from gpuhunt._internal.default import default_catalog, query
from gpuhunt._internal.models import (
    AcceleratorInfo,
    AcceleratorVendor,
    AMDGPUInfo,
    CatalogItem,
    NvidiaGPUInfo,
    QueryFilter,
    RawCatalogItem,
    TPUInfo,
)

# Deprecated aliases
GPUInfo: type[NvidiaGPUInfo]
KNOWN_GPUS: list[NvidiaGPUInfo]


def _warn_renamed(old: str, new: str) -> None:
    warnings.warn(
        f"{old} has been renamed to {new}, the old name is deprecated and will be removed.",
        DeprecationWarning,
        stacklevel=2,
    )


def __getattr__(name):
    if name == "GPUInfo":
        _warn_renamed("GPUInfo", "NvidiaGPUInfo")
        return NvidiaGPUInfo
    if name == "KNOWN_GPUS":
        _warn_renamed("KNOWN_GPUS", "KNOWN_NVIDIA_GPUS")
        return KNOWN_NVIDIA_GPUS
    raise AttributeError(f"module {__name__!r} has no attribute {name!r}")

================
File: gpuhunt/src/gpuhunt/__main__.py
================
import argparse
import logging
import os
import sys

import gpuhunt._internal.storage as storage


def main():
    parser = argparse.ArgumentParser(prog="python3 -m gpuhunt")
    parser.add_argument(
        "provider",
        choices=[
            "aws",
            "azure",
            "crusoe",
            "cudo",
            "datacrunch",
            "gcp",
            "genesiscloud",
            "lambdalabs",
            "leadergpu",
            "linode",
            "oci",
            "runpod",
            "seeweb",
            "tensordock",
            "vastai",
            "vultr",
            "latitude",
            "scaleway",
        ],
    )
    parser.add_argument("--output", required=True)
    parser.add_argument("--no-filter", action="store_true")
    args = parser.parse_args()
    logging.basicConfig(
        level=logging.INFO,
        stream=sys.stdout,
        format="%(asctime)s %(levelname)s %(message)s",
    )

    if args.provider == "aws":
        from gpuhunt.providers.aws import AWSProvider

        provider = AWSProvider(os.getenv("AWS_CACHE_PATH"))
    elif args.provider == "azure":
        from gpuhunt.providers.azure import AzureProvider

        provider = AzureProvider(os.getenv("AZURE_SUBSCRIPTION_ID"))
    elif args.provider == "crusoe":
        from gpuhunt.providers.crusoe import CrusoeProvider

        provider = CrusoeProvider()
    elif args.provider == "cudo":
        from gpuhunt.providers.cudo import CudoProvider

        provider = CudoProvider()
    elif args.provider == "datacrunch":
        from gpuhunt.providers.datacrunch import DataCrunchProvider

        provider = DataCrunchProvider(
            os.getenv("DATACRUNCH_CLIENT_ID"), os.getenv("DATACRUNCH_CLIENT_SECRET")
        )
    elif args.provider == "gcp":
        from gpuhunt.providers.gcp import GCPProvider

        provider = GCPProvider(os.getenv("GCP_PROJECT_ID"))
    elif args.provider == "genesiscloud":
        from gpuhunt.providers.genesiscloud import GenesisCloudProvider

        provider = GenesisCloudProvider()
    elif args.provider == "lambdalabs":
        from gpuhunt.providers.lambdalabs import LambdaLabsProvider

        provider = LambdaLabsProvider(os.getenv("LAMBDALABS_TOKEN"))
    elif args.provider == "leadergpu":
        from gpuhunt.providers.leadergpu import LeaderGPUProvider

        provider = LeaderGPUProvider()
    elif args.provider == "linode":
        from gpuhunt.providers.linode import LinodeProvider

        provider = LinodeProvider()
    elif args.provider == "oci":
        from gpuhunt.providers.oci import OCICredentials, OCIProvider

        provider = OCIProvider(
            OCICredentials(
                user=os.getenv("OCI_CLI_USER"),
                key_content=os.getenv("OCI_CLI_KEY_CONTENT"),
                fingerprint=os.getenv("OCI_CLI_FINGERPRINT"),
                tenancy=os.getenv("OCI_CLI_TENANCY"),
                region=os.getenv("OCI_CLI_REGION"),
            )
        )
    elif args.provider == "runpod":
        from gpuhunt.providers.runpod import RunpodProvider

        provider = RunpodProvider()
    elif args.provider == "seeweb":
        from gpuhunt.providers.seeweb import SeewebProvider

        provider = SeewebProvider()
    elif args.provider == "tensordock":
        from gpuhunt.providers.tensordock import TensorDockProvider

        provider = TensorDockProvider()
    elif args.provider == "vastai":
        from gpuhunt.providers.vastai import VastAIProvider

        provider = VastAIProvider()
    elif args.provider == "vultr":
        from gpuhunt.providers.vultr import VultrProvider

        provider = VultrProvider()
    elif args.provider == "latitude":
        from gpuhunt.providers.latitude import LatitudeProvider
        provider = LatitudeProvider()
    elif args.provider == "scaleway":
        from gpuhunt.providers.scaleway import ScalewayProvider 
        provider = ScalewayProvider()
    else:
        exit(f"Unknown provider {args.provider}")

    logging.info("Fetching offers for %s", args.provider)
    offers = provider.get()
    if not args.no_filter:
        offers = provider.filter(offers)
    storage.dump(offers, args.output)


if __name__ == "__main__":
    main()

================
File: gpuhunt/src/gpuhunt/version.py
================
__version__ = "0.0.0"

================
File: gpuhunt/src/integrity_tests/conftest.py
================
import os
from pathlib import Path

import pytest


@pytest.fixture
def catalog_dir() -> Path:
    return Path(os.environ["CATALOG_DIR"])

================
File: gpuhunt/src/integrity_tests/test_all.py
================
import csv
import os
from pathlib import Path

import pytest

files = sorted(Path(os.environ["CATALOG_DIR"]).glob("*.csv"))


def catalog_name(catalog) -> str:
    return catalog.name


class TestAllCatalogs:
    @pytest.fixture(params=files, ids=catalog_name)
    def catalog(self, request):
        yield request.param

    def test_non_zero_cost(self, catalog):
        reader = csv.DictReader(catalog.open())
        for row in reader:
            assert float(row["price"]) != pytest.approx(0), str(row)

================
File: gpuhunt/src/integrity_tests/test_aws.py
================
from pathlib import Path

import pytest


@pytest.fixture
def data(catalog_dir: Path) -> str:
    return (catalog_dir / "aws.csv").read_text()


class TestAWSCatalog:
    def test_m5_large_regions(self, data: str):
        instance = "m5.large"
        regions = [
            "af-south-1",
            "ap-east-1",
            "ap-northeast-1",
            "ap-northeast-2",
            "ap-northeast-3",
            "ap-south-1",
            "ap-south-2",
            "ap-southeast-1",
            "ap-southeast-2",
            "ap-southeast-3",
            "ap-southeast-4",
            "ca-central-1",
            "eu-central-1",
            "eu-central-2",
            "eu-north-1",
            "eu-south-1",
            "eu-south-2",
            "eu-west-1",
            "eu-west-2",
            "eu-west-3",
            "il-central-1",
            "me-central-1",
            "me-south-1",
            "sa-east-1",
            "us-east-1",
            "us-east-2",
            "us-gov-east-1",
            "us-gov-west-1",
            "us-west-1",
            "us-west-2",
            "us-west-2-lax-1",
        ]
        assert all(f"\n{instance},{i}," in data for i in regions)

    def test_spots_presented(self, data: str):
        assert ",True," in data

    def test_gpu_presented(self, data: str):
        gpus = [
            # AWS pricing csv does not include H200 (p5e.) offers.
            # TODO: Add CapacityBlocks offers to support H200.
            # "H200",
            "H100",
            "A100",
            "A10G",
            "T4",
            "V100",
            "L40S",
            "L4",
        ]
        assert all(f",{i}," in data for i in gpus)

================
File: gpuhunt/src/integrity_tests/test_azure.py
================
import csv
from pathlib import Path

import pytest


@pytest.fixture
def data_rows(catalog_dir: Path) -> list[dict]:
    with open(catalog_dir / "azure.csv") as f:
        return list(csv.DictReader(f))


class TestAzureCatalog:
    def test_standard_d2s_v3_locations(self, data_rows: list[dict]):
        expected_locations = {
            "attatlanta1",
            "attdallas1",
            "attdetroit1",
            "attnewyork1",
            "australiacentral",
            "australiacentral2",
            "australiaeast",
            "australiasoutheast",
            "australiasoutheast",
            "brazilsouth",
            "brazilsoutheast",
            "canadacentral",
            "canadaeast",
            "centralindia",
            "centralus",
            "eastasia",
            "eastus",
            "eastus2",
            "francecentral",
            "francesouth",
            "germanynorth",
            "germanywestcentral",
            "israelcentral",
            "italynorth",
            "japaneast",
            "japanwest",
            "jioindiacentral",
            "jioindiawest",
            "koreacentral",
            "koreasouth",
            "mexicocentral",
            "newzealandnorth",
            "northcentralus",
            "northeurope",
            "norwayeast",
            "norwaywest",
            "polandcentral",
            "qatarcentral",
            "sgxsingapore1",
            "southafricanorth",
            "southafricawest",
            "southcentralus",
            "southeastasia",
            "southindia",
            "spaincentral",
            "swedencentral",
            "swedensouth",
            "switzerlandnorth",
            "switzerlandwest",
            "uaecentral",
            "uaenorth",
            "uksouth",
            "ukwest",
            "usgovarizona",
            "usgovtexas",
            "usgovvirginia",
            "westcentralus",
            "westeurope",
            "westindia",
            "westus",
            "westus2",
            "westus3",
        }
        locations = set(
            row["location"] for row in data_rows if row["instance_name"] == "Standard_D2s_v3"
        )
        assert expected_locations == locations

    def test_spots_presented(self, data_rows: list[dict]):
        assert any(row["spot"] == "True" for row in data_rows)

    def test_ondemand_presented(self, data_rows: list[dict]):
        assert any(row["spot"] == "False" for row in data_rows)

    def test_gpu_presented(self, data_rows: list[dict]):
        expected_gpus = {
            "A100",
            "A10",
            "T4",
            "V100",
        }
        gpus = set(row["gpu_name"] for row in data_rows if row["gpu_name"])
        assert expected_gpus == gpus

    def test_both_a100_presented(self, data_rows: list[dict]):
        expected_gpu_memory = {"40.0", "80.0"}
        gpu_memory = set(row["gpu_memory"] for row in data_rows if row["gpu_name"] == "A100")
        assert expected_gpu_memory == gpu_memory

================
File: gpuhunt/src/integrity_tests/test_datacrunch.py
================
import csv
from collections import Counter
from pathlib import Path

import pytest

from gpuhunt.providers.datacrunch import ALL_AMD_GPUS, GPU_MAP


@pytest.fixture
def data_rows(catalog_dir: Path) -> list[dict]:
    file = catalog_dir / "datacrunch.csv"
    reader = csv.DictReader(file.open())
    return list(reader)


def select_row(rows, name: str) -> list[str]:
    return [r[name] for r in rows if r[name]]


def test_locations(data_rows):
    expected = {
        "FIN-01",
        "FIN-02",
        "ICE-01",
    }
    locations = select_row(data_rows, "location")
    assert set(locations) == expected

    count = Counter(locations)
    for loc in expected:
        assert count[loc] > 1


def test_spot(data_rows):
    spots = select_row(data_rows, "spot")

    expected = set(("True", "False"))
    assert set(spots) == expected

    count = Counter(spots)
    for spot_key in ("True", "False"):
        assert count[spot_key] > 1


def test_price(data_rows):
    prices = select_row(data_rows, "price")
    assert min(float(p) for p in prices) > 0


def test_gpu_present(data_rows):
    refs = [name for name in GPU_MAP.values() if name not in ALL_AMD_GPUS]
    gpus = select_row(data_rows, "gpu_name")
    assert set(gpus) == set(refs)

================
File: gpuhunt/src/integrity_tests/test_gcp.py
================
from pathlib import Path

import pytest


@pytest.fixture
def data(catalog_dir: Path) -> str:
    return (catalog_dir / "gcp.csv").read_text()


class TestGCPCatalog:
    def test_e2_highcpu_2_zones(self, data: str):
        zones = [
            "asia-east1-a",
            "asia-east1-b",
            "asia-east1-c",
            "asia-east2-a",
            "asia-east2-b",
            "asia-east2-c",
            "asia-northeast1-a",
            "asia-northeast1-b",
            "asia-northeast1-c",
            "asia-northeast2-a",
            "asia-northeast2-b",
            "asia-northeast2-c",
            "asia-northeast3-a",
            "asia-northeast3-b",
            "asia-northeast3-c",
            "asia-south1-a",
            "asia-south1-b",
            "asia-south1-c",
            "asia-south2-a",
            "asia-south2-b",
            "asia-south2-c",
            "asia-southeast1-a",
            "asia-southeast1-b",
            "asia-southeast1-c",
            "asia-southeast2-a",
            "asia-southeast2-b",
            "asia-southeast2-c",
            "australia-southeast1-a",
            "australia-southeast1-b",
            "australia-southeast1-c",
            "australia-southeast2-a",
            "australia-southeast2-b",
            "australia-southeast2-c",
            "europe-central2-a",
            "europe-central2-b",
            "europe-central2-c",
            "europe-north1-a",
            "europe-north1-b",
            "europe-north1-c",
            "europe-southwest1-a",
            "europe-southwest1-b",
            "europe-southwest1-c",
            "europe-west1-b",
            "europe-west1-c",
            "europe-west1-d",
            "europe-west10-a",
            "europe-west10-b",
            "europe-west10-c",
            "europe-west12-a",
            "europe-west12-b",
            "europe-west12-c",
            "europe-west2-a",
            "europe-west2-b",
            "europe-west2-c",
            "europe-west3-a",
            "europe-west3-b",
            "europe-west3-c",
            "europe-west4-a",
            "europe-west4-b",
            "europe-west4-c",
            "europe-west6-a",
            "europe-west6-b",
            "europe-west6-c",
            "europe-west8-a",
            "europe-west8-b",
            "europe-west8-c",
            "europe-west9-a",
            "europe-west9-b",
            "europe-west9-c",
            "me-central1-a",
            "me-central1-b",
            "me-central1-c",
            "me-central2-a",
            "me-central2-b",
            "me-central2-c",
            "me-west1-a",
            "me-west1-b",
            "me-west1-c",
            "northamerica-northeast1-a",
            "northamerica-northeast1-b",
            "northamerica-northeast1-c",
            "northamerica-northeast2-a",
            "northamerica-northeast2-b",
            "northamerica-northeast2-c",
            "southamerica-east1-a",
            "southamerica-east1-b",
            "southamerica-east1-c",
            "southamerica-west1-a",
            "southamerica-west1-b",
            "southamerica-west1-c",
            "us-central1-a",
            "us-central1-b",
            "us-central1-c",
            "us-central1-f",
            "us-east1-b",
            "us-east1-c",
            "us-east1-d",
            "us-east4-a",
            "us-east4-b",
            "us-east4-c",
            "us-east5-a",
            "us-east5-b",
            "us-east5-c",
            "us-south1-a",
            "us-south1-b",
            "us-south1-c",
            "us-west1-a",
            "us-west1-b",
            "us-west1-c",
            "us-west2-a",
            "us-west2-b",
            "us-west2-c",
            "us-west3-a",
            "us-west3-b",
            "us-west3-c",
            "us-west4-a",
            "us-west4-b",
            "us-west4-c",
        ]
        assert all(f"\ne2-highcpu-2,{i}," in data for i in zones)

    def test_spots_presented(self, data: str):
        assert ",True," in data

    def test_ondemand_presented(self, data: str):
        assert ",False," in data

    def test_gpu_presented(self, data: str):
        gpus = [
            "H100",
            "A100",
            "L4",
            "T4",
            "V100",
            "P100",
        ]
        assert all(f",{i}," in data for i in gpus)

    def test_tpu_presented(self, data: str):
        gpus = [
            "v2",
            "v3",
            "v5litepod",
            "v5p",
        ]
        assert all(gpu in data for gpu in gpus)

    def test_both_a100_presented(self, data: str):
        assert ",A100,40.0," in data
        assert ",A100,80.0," in data

================
File: gpuhunt/src/integrity_tests/test_nebius.py
================
from pathlib import Path

import pytest


@pytest.fixture
def data(catalog_dir: Path) -> str:
    return (catalog_dir / "nebius.csv").read_text()


class TestNebiusCatalog:
    @pytest.mark.xfail
    def test_zone_presented(self, data: str):
        assert ",eu-north1-c," in data

    @pytest.mark.xfail
    def test_gpu_presented(self, data: str):
        gpus = [
            "A100",
            "L4",
            "L40",
            "H100",
        ]
        assert all(f",{i}," in data for i in gpus)

    @pytest.mark.xfail
    def test_h100_platforms(self, data: str):
        platforms = [
            "gpu-h100",
            "gpu-h100-b",
            "standard-v3-h100-pcie",
        ]
        assert all(f"\n{i}," in data for i in platforms)

    @pytest.mark.xfail
    def test_no_spots(self, data: str):
        assert ",True\n" not in data

================
File: gpuhunt/src/integrity_tests/test_oci.py
================
import csv
from operator import itemgetter
from pathlib import Path

import pytest


@pytest.fixture
def data_rows(catalog_dir: Path) -> list[dict]:
    with open(catalog_dir / "oci.csv") as f:
        return list(csv.DictReader(f))


@pytest.mark.parametrize("gpu", ["P100", "V100", "A10", "A100", "H100", ""])
def test_gpu_present(gpu: str, data_rows: list[dict]):
    assert gpu in map(itemgetter("gpu_name"), data_rows)


def test_on_demand_present(data_rows: list[dict]):
    assert "False" in map(itemgetter("spot"), data_rows)


@pytest.mark.parametrize("prefix", ["VM.Standard", "BM.Standard", "VM.GPU", "BM.GPU"])
def test_family_present(prefix: str, data_rows: list[dict]):
    assert any(name.startswith(prefix) for name in map(itemgetter("instance_name"), data_rows))


def test_quantity_decreases_as_query_complexity_increases(data_rows: list[dict]):
    zero_or_one_gpu = list(filter(lambda row: int(row["gpu_count"]) in (0, 1), data_rows))
    zero_gpu = list(filter(lambda row: int(row["gpu_count"]) == 0, data_rows))
    one_gpu = list(filter(lambda row: int(row["gpu_count"]) == 1, data_rows))

    assert len(data_rows) > len(zero_or_one_gpu)
    assert len(zero_or_one_gpu) > len(zero_gpu)
    assert len(zero_gpu) > len(one_gpu)

================
File: gpuhunt/src/integrity_tests/test_runpod.py
================
import csv
from collections import Counter
from pathlib import Path

import pytest

from gpuhunt.providers.runpod import GPU_MAP


@pytest.fixture
def data_rows(catalog_dir: Path) -> list[dict]:
    file = catalog_dir / "runpod.csv"
    reader = csv.DictReader(file.open())
    return list(reader)


def select_row(rows, name: str) -> list[str]:
    return [r[name] for r in rows if r[name]]


def test_locations(data_rows):
    expected = {
        "CA-MTL-1",
        "CA-MTL-2",
        "CA-MTL-3",
        "EU-NL-1",
        "EU-RO-1",
        "EU-SE-1",
        "EUR-IS-1",
        "EUR-IS-2",
        "US-GA-1",
        "US-OR-1",
        "US-TX-3",
    }
    locations = set(select_row(data_rows, "location"))
    assert len(locations) >= len(expected) - 3


def test_spot(data_rows):
    spots = select_row(data_rows, "spot")

    expected = set(("True", "False"))
    assert set(spots) == expected

    count = Counter(spots)
    for spot_key in ("True", "False"):
        assert count[spot_key] > 1


def test_price(data_rows):
    prices = select_row(data_rows, "price")
    assert min(float(p) for p in prices) > 0


def test_gpu_present(data_rows):
    refs = set(name for _, name in GPU_MAP.values())
    gpus = set(select_row(data_rows, "gpu_name"))
    assert len(refs & gpus) > 7

================
File: gpuhunt/src/tests/_internal/test_catalog.py
================
from typing import Union
from unittest.mock import Mock

import gpuhunt._internal.catalog as internal_catalog
from gpuhunt import Catalog, CatalogItem, RawCatalogItem
from gpuhunt.providers.tensordock import TensorDockProvider
from gpuhunt.providers.vastai import VastAIProvider


class TestQuery:
    def test_query_merge(self):
        catalog = Catalog(balance_resources=False, auto_reload=False)

        tensordock = TensorDockProvider()
        tensordock.get = Mock(return_value=[catalog_item(price=1), catalog_item(price=3)])
        catalog.add_provider(tensordock)

        vastai = VastAIProvider()
        vastai.get = Mock(return_value=[catalog_item(price=2), catalog_item(price=1)])
        catalog.add_provider(vastai)

        assert catalog.query(provider=["tensordock", "vastai"]) == [
            catalog_item(provider="tensordock", price=1),
            catalog_item(provider="vastai", price=2),
            catalog_item(provider="vastai", price=1),
            catalog_item(provider="tensordock", price=3),
        ]

    def test_no_providers_some_not_loaded(self):
        catalog = Catalog(balance_resources=False, auto_reload=False)

        tensordock = TensorDockProvider()
        tensordock.get = Mock(return_value=[catalog_item(price=1)])
        catalog.add_provider(tensordock)

        internal_catalog.OFFLINE_PROVIDERS = []
        assert catalog.query() == [
            catalog_item(provider="tensordock", price=1),
        ]

    def test_provider_filter(self):
        catalog = Catalog(balance_resources=False, auto_reload=False)
        catalog.add_provider(tensordock := TensorDockProvider())
        catalog.add_provider(vastai := VastAIProvider())

        tensordock_offers = [catalog_item(price=1)]
        vastai_offers = [catalog_item(price=2), catalog_item(price=3)]

        tensordock.get = Mock(return_value=tensordock_offers)
        vastai.get = Mock(return_value=vastai_offers)

        assert len(catalog.query(provider="tensordock")) == 1
        assert len(catalog.query(provider="Tensordock")) == 1
        assert len(catalog.query(provider="vastai")) == 2
        assert len(catalog.query(provider="VastAI")) == 2
        assert len(catalog.query(provider=["tensordock", "VastAI"])) == 3

    def test_gpu_name_filter(self):
        catalog = Catalog(balance_resources=False, auto_reload=False)
        catalog.add_provider(tensordock := TensorDockProvider())

        tensordock.get = Mock(
            return_value=[
                catalog_item(gpu_name="A10"),
                catalog_item(gpu_name="A100"),
                catalog_item(gpu_name="a100"),
            ]
        )

        assert len(catalog.query(gpu_name="V100")) == 0
        assert len(catalog.query(gpu_name="A10")) == 1
        assert len(catalog.query(gpu_name="a10")) == 1
        assert len(catalog.query(gpu_name="A100")) == 2
        assert len(catalog.query(gpu_name="a100")) == 2
        assert len(catalog.query(gpu_name=["a10", "A100"])) == 3


def catalog_item(**kwargs) -> Union[CatalogItem, RawCatalogItem]:
    values = dict(
        instance_name="instance",
        cpu=1,
        memory=1,
        gpu_vendor="nvidia",
        gpu_count=1,
        gpu_name="gpu",
        gpu_memory=1,
        location="location",
        price=1,
        spot=False,
        disk_size=None,
    )
    values.update(kwargs)
    if "provider" in values:
        return CatalogItem(**values)
    return RawCatalogItem(**values)

================
File: gpuhunt/src/tests/_internal/test_constraints.py
================
import pytest

from gpuhunt import CatalogItem, QueryFilter
from gpuhunt._internal.constraints import correct_gpu_memory_gib, matches
from gpuhunt._internal.models import AcceleratorVendor


@pytest.fixture
def item() -> CatalogItem:
    return CatalogItem(
        instance_name="large",
        location="us-east-1",
        price=1.2,
        cpu=16,
        memory=64.0,
        gpu_vendor=AcceleratorVendor.NVIDIA,
        gpu_count=1,
        gpu_name="A100",
        gpu_memory=40.0,
        spot=False,
        provider="aws",
        disk_size=None,
    )


@pytest.fixture
def cpu_items() -> list[CatalogItem]:
    datacrunch = CatalogItem(
        instance_name="CPU.120V.480G",
        location="ICE-01",
        price=3.0,
        cpu=120,
        memory=480.0,
        gpu_vendor=None,
        gpu_count=0,
        gpu_name=None,
        gpu_memory=0.0,
        spot=False,
        provider="datacrunch",
        disk_size=None,
    )
    nebius = CatalogItem(
        instance_name="standard-v2",
        location="eu-north1-c",
        price=1.4016,
        cpu=48,
        memory=288.0,
        gpu_vendor=None,
        gpu_count=0,
        gpu_name=None,
        gpu_memory=None,
        spot=False,
        provider="nebius",
        disk_size=None,
    )
    return [datacrunch, nebius]


class TestMatches:
    def test_empty(self, item: CatalogItem):
        assert matches(item, QueryFilter())

    def test_cpu(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_cpu=16))
        assert matches(item, QueryFilter(max_cpu=16))
        assert not matches(item, QueryFilter(min_cpu=32))
        assert not matches(item, QueryFilter(max_cpu=8))

    def test_memory(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_memory=64.0))
        assert matches(item, QueryFilter(max_memory=64.0))
        assert not matches(item, QueryFilter(min_memory=128.0))
        assert not matches(item, QueryFilter(max_memory=32.0))

    def test_gpu_vendor_nvidia(self, item: CatalogItem):
        assert matches(item, QueryFilter(gpu_vendor=AcceleratorVendor.NVIDIA))
        assert not matches(item, QueryFilter(gpu_vendor=AcceleratorVendor.AMD))

    def test_gpu_vendor_amd(self, item: CatalogItem):
        item.gpu_vendor = AcceleratorVendor.AMD
        assert matches(item, QueryFilter(gpu_vendor=AcceleratorVendor.AMD))
        assert not matches(item, QueryFilter(gpu_vendor=AcceleratorVendor.NVIDIA))

    def test_gpu_count(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_gpu_count=1))
        assert matches(item, QueryFilter(max_gpu_count=1))
        assert not matches(item, QueryFilter(min_gpu_count=2))
        assert not matches(item, QueryFilter(max_gpu_count=0))

    def test_gpu_memory(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_gpu_memory=40.0))
        assert matches(item, QueryFilter(max_gpu_memory=40.0))
        assert not matches(item, QueryFilter(min_gpu_memory=80.0))
        assert not matches(item, QueryFilter(max_gpu_memory=20.0))

    def test_gpu_name(self, item: CatalogItem):
        assert matches(item, QueryFilter(gpu_name=["a100"]))
        assert matches(item, QueryFilter(gpu_name=["A100"]))
        assert not matches(item, QueryFilter(gpu_name=["A10"]))

    def test_gpu_name_with_filter_setattr(self, item: CatalogItem):
        q = QueryFilter()
        q.gpu_name = ["a100"]
        assert matches(item, q)
        q.gpu_name = ["A100"]
        assert matches(item, q)
        q.gpu_name = ["A10"]
        assert not matches(item, q)

    def test_total_gpu_memory(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_total_gpu_memory=40.0))
        assert matches(item, QueryFilter(max_total_gpu_memory=40.0))
        assert not matches(item, QueryFilter(min_total_gpu_memory=80.0))
        assert not matches(item, QueryFilter(max_total_gpu_memory=20.0))

    def test_price(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_price=1.2))
        assert matches(item, QueryFilter(max_price=1.2))
        assert not matches(item, QueryFilter(min_price=1.3))
        assert not matches(item, QueryFilter(max_price=1.1))

    def test_spot(self, item: CatalogItem):
        assert matches(item, QueryFilter(spot=False))
        assert not matches(item, QueryFilter(spot=True))

    def test_compute_capability(self, item: CatalogItem):
        assert matches(item, QueryFilter(min_compute_capability=(8, 0)))
        assert matches(item, QueryFilter(max_compute_capability=(8, 0)))
        assert not matches(item, QueryFilter(min_compute_capability=(8, 1)))
        assert not matches(item, QueryFilter(max_compute_capability=(7, 9)))

    def test_compute_capability_not_nvidia(self, item: CatalogItem):
        item.gpu_vendor = AcceleratorVendor.AMD
        assert not matches(item, QueryFilter(min_compute_capability=(8, 0)))
        assert not matches(item, QueryFilter(max_compute_capability=(8, 0)))

    def test_ti_gpu(self):
        item = CatalogItem(
            instance_name="large",
            location="us-east-1",
            price=1.2,
            cpu=16,
            memory=64.0,
            gpu_count=1,
            gpu_vendor=AcceleratorVendor.NVIDIA,
            gpu_name="RTX3060Ti",  # case-sensitive
            gpu_memory=8.0,
            spot=False,
            provider="aws",
            disk_size=None,
        )
        assert matches(item, QueryFilter(gpu_name=["RTX3060TI"]))

    def test_provider(self, cpu_items):
        assert matches(cpu_items[0], QueryFilter(provider=["datacrunch"]))
        assert matches(cpu_items[0], QueryFilter(provider=["DataCrunch"]))
        assert not matches(cpu_items[0], QueryFilter(provider=["nebius"]))

        assert matches(cpu_items[1], QueryFilter(provider=["nebius"]))
        assert matches(cpu_items[1], QueryFilter(provider=["Nebius"]))
        assert not matches(cpu_items[1], QueryFilter(provider=["datacrunch"]))

    def test_provider_with_filter_setattr(self, cpu_items):
        q = QueryFilter()
        q.provider = ["datacrunch"]
        assert matches(cpu_items[0], q)
        q.provider = ["DataCrunch"]
        assert matches(cpu_items[0], q)
        q.provider = ["nebius"]
        assert not matches(cpu_items[0], q)


@pytest.mark.parametrize(
    ("gpu_name", "memory_mib", "expected_memory_gib"),
    [
        ("H100NVL", 95830.0, 94),
        ("L40S", 46068.0, 48),
        ("A10G", 23028.0, 24),
        ("A10", 4096.0, 4),
        ("unknown", 8200.1, 8),
    ],
)
def test_correct_gpu_memory(gpu_name: str, memory_mib: float, expected_memory_gib: int) -> None:
    assert correct_gpu_memory_gib(gpu_name, memory_mib) == expected_memory_gib

================
File: gpuhunt/src/tests/_internal/test_models.py
================
from typing import Union

import pytest

from gpuhunt._internal.constraints import KNOWN_AMD_GPUS
from gpuhunt._internal.models import (
    AcceleratorVendor,
    AMDArchitecture,
    CatalogItem,
    Optional,
    RawCatalogItem,
)

NVIDIA = AcceleratorVendor.NVIDIA
GOOGLE = AcceleratorVendor.GOOGLE
AMD = AcceleratorVendor.AMD


@pytest.mark.parametrize(
    ["gpu_count", "gpu_vendor", "gpu_name", "expected_gpu_vendor", "expected_gpu_name"],
    [
        pytest.param(None, None, None, None, None, id="none-gpu"),
        pytest.param(0, None, None, None, None, id="zero-gpu"),
        pytest.param(1, None, "A100", "nvidia", "A100", id="one-gpu"),
        pytest.param(1, None, "tpu-v3", "google", "v3", id="one-tpu-vendor-not-set"),
        pytest.param(1, "google", "tpu-v5p", "google", "v5p", id="one-tpu-vendor-is-set"),
        pytest.param(1, AMD, "MI300X", "amd", "MI300X", id="cast-enum-to-string"),
    ],
)
def test_raw_catalog_item_gpu_vendor_heuristic(
    gpu_count: Optional[int],
    gpu_vendor: Union[AcceleratorVendor, str, None],
    gpu_name: Optional[str],
    expected_gpu_vendor: Optional[str],
    expected_gpu_name: Optional[str],
):
    dct = {}
    if gpu_vendor is not None:
        dct["gpu_vendor"] = gpu_vendor
    if gpu_count is not None:
        dct["gpu_count"] = gpu_count
    if gpu_name is not None:
        dct["gpu_name"] = gpu_name

    item = RawCatalogItem.from_dict(dct)

    assert item.gpu_vendor == expected_gpu_vendor
    assert item.gpu_name == expected_gpu_name


@pytest.mark.parametrize(
    ["gpu_count", "gpu_vendor", "gpu_name", "expected_gpu_vendor"],
    [
        pytest.param(None, None, None, None, id="none-gpu"),
        pytest.param(0, None, None, None, id="zero-gpu"),
        pytest.param(1, None, None, NVIDIA, id="one-gpu-no-name"),
        pytest.param(1, None, "v3", NVIDIA, id="one-gpu-with-any-name"),
        pytest.param(1, "amd", "MI300X", AMD, id="cast-string-to-enum"),
    ],
)
def test_catalog_item_gpu_vendor_heuristic(
    gpu_count: Optional[int],
    gpu_vendor: Union[AcceleratorVendor, str, None],
    gpu_name: Optional[str],
    expected_gpu_vendor: Optional[str],
):
    item = CatalogItem(
        instance_name="test-instance",
        location="eu-west-1",
        price=1.0,
        cpu=1,
        memory=32.0,
        gpu_vendor=gpu_vendor,
        gpu_count=gpu_count,
        gpu_name=gpu_name,
        gpu_memory=8.0,
        spot=False,
        disk_size=100.0,
        provider="test",
    )

    assert item.gpu_vendor == expected_gpu_vendor


@pytest.mark.parametrize(
    ["model", "architecture", "expected_memory"],
    [
        pytest.param("MI325X", AMDArchitecture.CDNA3, 288, id="MI325X"),
        pytest.param("MI308X", AMDArchitecture.CDNA3, 128, id="MI308X"),
        pytest.param("MI300X", AMDArchitecture.CDNA3, 192, id="MI300X"),
        pytest.param("MI300A", AMDArchitecture.CDNA3, 128, id="MI300A"),
        pytest.param("MI250X", AMDArchitecture.CDNA2, 128, id="MI250X"),
        pytest.param("MI250", AMDArchitecture.CDNA2, 128, id="MI250"),
        pytest.param("MI210", AMDArchitecture.CDNA2, 64, id="MI210"),
        pytest.param("MI100", AMDArchitecture.CDNA, 32, id="MI100"),
    ],
)
def test_amd_gpu_architecture(model: str, architecture: AMDArchitecture, expected_memory: int):
    for gpu in KNOWN_AMD_GPUS:
        if gpu.name == model:
            assert gpu.architecture == architecture
            assert gpu.memory == expected_memory
            return
    # If we get here, the test should fail since we could not find the GPU in our known list.
    assert False

================
File: gpuhunt/src/tests/_internal/test_utils.py
================
import pytest

from gpuhunt._internal.utils import to_camel_case


@pytest.mark.parametrize(
    ["before", "after"],
    [
        ["spam_ham_eggs", "spamHamEggs"],
        ["spam__ham__eggs", "spamHamEggs"],
        ["__spam_ham_eggs__", "spamHamEggs"],
        ["spamHam_eggs", "spamHamEggs"],
        ["spamHamEggs", "spamHamEggs"],
        ["SpamHam_eggs", "SpamHamEggs"],
        ["spam", "spam"],
        ["", ""],
    ],
)
def test_to_camel_case(before, after):
    assert to_camel_case(before) == after

================
File: gpuhunt/src/tests/providers/test_cudo.py
================
import pytest

import gpuhunt._internal.catalog as internal_catalog
from gpuhunt import Catalog
from gpuhunt.providers.cudo import (
    CudoProvider,
    get_balanced_disk_size,
    get_balanced_memory,
    get_memory,
    gpu_name,
)


@pytest.fixture
def machine_types() -> list[dict]:
    return [
        {
            "dataCenterId": "br-saopaulo-1",
            "machineType": "cascade-lake",
            "cpuModel": "Cascadelake-Server-noTSX",
            "gpuModel": "RTX 3080",
            "gpuModelId": "nvidia-rtx-3080",
            "minVcpuPerMemoryGib": 0.25,
            "maxVcpuPerMemoryGib": 1,
            "minVcpuPerGpu": 1,
            "maxVcpuPerGpu": 13,
            "vcpuPriceHr": {"value": "0.002500"},
            "memoryGibPriceHr": {"value": "0.003800"},
            "gpuPriceHr": {"value": "0.05"},
            "minStorageGibPriceHr": {"value": "0.00013"},
            "ipv4PriceHr": {"value": "0.005500"},
            "maxVcpuFree": 76,
            "totalVcpuFree": 377,
            "maxMemoryGibFree": 227,
            "totalMemoryGibFree": 1132,
            "maxGpuFree": 5,
            "totalGpuFree": 24,
            "maxStorageGibFree": 42420,
            "totalStorageGibFree": 42420,
        },
        {
            "dataCenterId": "no-luster-1",
            "machineType": "epyc-rome-rtx-a5000",
            "cpuModel": "EPYC-Rome",
            "gpuModel": "RTX A5000",
            "gpuModelId": "nvidia-rtx-a5000",
            "minVcpuPerMemoryGib": 0.259109,
            "maxVcpuPerMemoryGib": 1.036437,
            "minVcpuPerGpu": 1,
            "maxVcpuPerGpu": 16,
            "vcpuPriceHr": {"value": "0.002100"},
            "memoryGibPriceHr": {"value": "0.003400"},
            "gpuPriceHr": {"value": "0.520000"},
            "minStorageGibPriceHr": {"value": "0.000107"},
            "ipv4PriceHr": {"value": "0.003500"},
            "renewableEnergy": False,
            "maxVcpuFree": 116,
            "totalVcpuFree": 208,
            "maxMemoryGibFree": 219,
            "totalMemoryGibFree": 390,
            "maxGpuFree": 4,
            "totalGpuFree": 7,
            "maxStorageGibFree": 1170,
            "totalStorageGibFree": 1170,
        },
    ]


def test_get_offers_with_query_filter(mocker, machine_types):
    catalog = Catalog(balance_resources=False, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types)
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(provider=["cudo"], min_gpu_count=1, max_gpu_count=1)
    assert len(query_result) >= 1, "No offers found"


def test_get_offers_for_gpu_name(mocker, machine_types):
    catalog = Catalog(balance_resources=True, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types)
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(provider=["cudo"], min_gpu_count=1, gpu_name=["A5000"])
    assert len(query_result) >= 1, "No offers found"


def test_get_offers_for_gpu_memory(mocker, machine_types):
    catalog = Catalog(balance_resources=True, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types)
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(provider=["cudo"], min_gpu_count=1, min_gpu_memory=16)
    assert len(query_result) >= 1, "No offers found"


def test_get_offers_for_compute_capability(mocker, machine_types):
    catalog = Catalog(balance_resources=True, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types)
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(provider=["cudo"], min_gpu_count=1, min_compute_capability=(8, 6))
    assert len(query_result) >= 1, "No offers found"


def test_get_offers_no_query_filter(mocker, machine_types):
    catalog = Catalog(balance_resources=True, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types)
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(provider=["cudo"])
    assert len(query_result) >= 1, "No offers found"


def test_optimize_offers_2(mocker, machine_types):
    catalog = Catalog(balance_resources=True, auto_reload=False)
    cudo = CudoProvider()
    cudo.list_vm_machine_types = mocker.Mock(return_value=machine_types[0:1])
    internal_catalog.ONLINE_PROVIDERS = ["cudo"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(cudo)
    query_result = catalog.query(
        provider=["cudo"], min_cpu=2, min_gpu_count=1, max_gpu_count=1, min_memory=8
    )
    machine_type = machine_types[0]
    balance_resource = True
    available_disk = machine_type["maxStorageGibFree"]
    gpu_memory = get_memory(gpu_name(machine_type["gpuModel"]))
    max_memory = None
    max_disk_size = None
    min_disk_size = None

    assert len(query_result) >= 1

    for config in query_result:
        min_cpus_for_memory = machine_type["minVcpuPerMemoryGib"] * config.cpu
        max_cpus_for_memory = machine_type["maxVcpuPerMemoryGib"] * config.memory
        min_cpus_for_gpu = machine_type["minVcpuPerGpu"] * config.gpu_count
        assert config.cpu >= min_cpus_for_memory, (
            f"VM config does not meet the minimum CPU:Memory requirement. Required minimum CPUs: "
            f"{min_cpus_for_memory}, Found: {config.cpu}"
        )
        assert config.cpu <= max_cpus_for_memory, (
            f"VM config exceeds the maximum CPU:Memory allowance. Allowed maximum CPUs: "
            f"{max_cpus_for_memory}, Found: {config.cpu}"
        )
        assert config.cpu >= min_cpus_for_gpu, (
            f"VM config does not meet the minimum CPU:GPU requirement. "
            f"Required minimum CPUs: {min_cpus_for_gpu}, Found: {config.cpu}"
        )
        # Perform the balance resource checks if balance_resource is True
        if balance_resource:
            expected_memory = get_balanced_memory(config.gpu_count, gpu_memory, max_memory)
            expected_disk_size = get_balanced_disk_size(
                available_disk,
                config.memory,
                config.gpu_count * gpu_memory,
                max_disk_size,
                min_disk_size,
            )

            assert config.memory == expected_memory, (
                f"Memory allocation does not match the expected balanced memory. "
                f"Expected: {expected_memory}, Found: {config.memory}"
            )
            assert config.disk_size == expected_disk_size, (
                f"Disk size allocation does not match the expected balanced disk size. "
                f"Expected: {expected_disk_size}, Found: {config.disk_size}"
            )

================
File: gpuhunt/src/tests/providers/test_datacrunch.py
================
import dataclasses

import pytest

import gpuhunt._internal.catalog as internal_catalog
from gpuhunt import AcceleratorVendor, Catalog, CatalogItem, RawCatalogItem
from gpuhunt.providers.datacrunch import (
    DataCrunchProvider,
    InstanceType,
    generate_instances,
    get_gpu_name,
    transform_instance,
)


@pytest.fixture
def raw_instance_types() -> list[dict]:
    # datacrunch.instance_types.get()
    one_gpu = {
        "best_for": [
            "Gargantuan ML models",
            "Multi-GPU training",
            "FP64 HPC",
            "NVLINK",
        ],
        "cpu": {"description": "30 CPU", "number_of_cores": 30},
        "deploy_warning": "H100: Use Nvidia driver 535 or higher for best performance",
        "description": "Dedicated Hardware Instance",
        "gpu": {"description": "1x H100 SXM5 80GB", "number_of_gpus": 1},
        "gpu_memory": {"description": "80GB GPU RAM", "size_in_gigabytes": 80},
        "id": "c01dd00d-0000-480b-ae4e-d429115d055b",
        "instance_type": "1H100.80S.30V",
        "memory": {"description": "120GB RAM", "size_in_gigabytes": 120},
        "model": "H100 80GB",
        "name": "H100 SXM5 80GB",
        "p2p": "",
        "price_per_hour": "3.95",
        "spot_price": "1.70",
        "storage": {"description": "dynamic"},
    }

    two_gpu = {
        "best_for": ["Large ML models", "FP32 calculations", "Single-GPU training"],
        "cpu": {"description": "20 CPU", "number_of_cores": 20},
        "deploy_warning": None,
        "description": "Dedicated Hardware Instance",
        "gpu": {"description": "2x NVIDIA RTX A6000 48GB", "number_of_gpus": 2},
        "gpu_memory": {"description": "96GB GPU RAM", "size_in_gigabytes": 96},
        "id": "07cf5dc1-a5d2-4972-ae4e-d429115d055b",
        "instance_type": "2A6000.20V",
        "memory": {"description": "120GB RAM", "size_in_gigabytes": 120},
        "model": "RTX A6000",
        "name": "NVIDIA RTX A6000 48GB",
        "p2p": "",
        "price_per_hour": "1.98",
        "spot_price": "0.70",
        "storage": {"description": "dynamic"},
    }

    cpu_instance = {
        "best_for": ["Running services", "API server", "Data transfers"],
        "cpu": {"description": "120 CPU", "number_of_cores": 120},
        "deploy_warning": None,
        "description": "Dedicated Hardware Instance",
        "gpu": {"description": "", "number_of_gpus": 0},
        "gpu_memory": {"description": "", "size_in_gigabytes": 0},
        "id": "ccc00007-a5d2-4972-ae4e-d429115d055b",
        "instance_type": "CPU.120V.480G",
        "memory": {"description": "480GB RAM", "size_in_gigabytes": 480},
        "model": "CPU Node",
        "name": "AMD EPYC",
        "p2p": "",
        "price_per_hour": "3.00",
        "spot_price": "1.50",
        "storage": {"description": "dynamic"},
    }

    minimal = {
        "best_for": [
            "Small ML models",
            "Multi-GPU training",
            "FP64 calculations",
            "NVLINK",
        ],
        "cpu": {"description": "6 CPU", "number_of_cores": 6},
        "deploy_warning": None,
        "description": "Dedicated Hardware Instance",
        "gpu": {"description": "1x NVIDIA Tesla V100 16GB", "number_of_gpus": 1},
        "gpu_memory": {"description": "16GB GPU RAM", "size_in_gigabytes": 16},
        "id": "04cf5dc1-a5d2-4972-ae4e-d429115d055b",
        "instance_type": "1V100.6V",
        "memory": {"description": "23GB RAM", "size_in_gigabytes": 23},
        "model": "Tesla V100",
        "name": "NVIDIA Tesla V100 16GB",
        "p2p": "",
        "price_per_hour": "0.89",
        "spot_price": "0.25",
        "storage": {"description": "225GB NVME", "size_in_gigabytes": 225},
    }

    return [one_gpu, two_gpu, cpu_instance, minimal]


@pytest.fixture
def availabilities() -> list[dict]:
    # datacrunch.instances.get_availabilities(is_spot=True)
    data = [
        {
            "location_code": "FIN-01",
            "availabilities": [
                "1A100.22V",
                "1RTX6000ADA.10V",
                "8RTX6000ADA.80V",
                "2A6000.20V",
                "1V100.6V",
                "2V100.10V",
                "4V100.20V",
                "8V100.48V",
                "CPU.4V.16G",
                "CPU.8V.32G",
                "CPU.16V.64G",
                "CPU.32V.128G",
                "CPU.64V.256G",
                "CPU.96V.384G",
            ],
        },
        {
            "location_code": "ICE-01",
            "availabilities": [
                "CPU.4V.16G",
                "CPU.8V.32G",
                "CPU.16V.64G",
                "CPU.32V.128G",
                "CPU.64V.256G",
                "CPU.96V.384G",
                "CPU.120V.480G",
            ],
        },
    ]
    return data


@pytest.fixture
def locations():
    # datacrunch.locations.get()
    return [
        {"code": "FIN-01", "name": "Finland 1", "country_code": "FI"},
        {"code": "FIN-02", "name": "Finland 2", "country_code": "FI"},
        {"code": "ICE-01", "name": "Iceland 1", "country_code": "IS"},
    ]


def instance_types(raw_instance_type: dict) -> InstanceType:
    instance = InstanceType(
        id=raw_instance_type["id"],
        instance_type=raw_instance_type["instance_type"],
        price_per_hour=raw_instance_type["price_per_hour"],
        spot_price_per_hour=raw_instance_type["spot_price"],
        description=raw_instance_type["description"],
        cpu=raw_instance_type["cpu"],
        gpu=raw_instance_type["gpu"],
        memory=raw_instance_type["memory"],
        gpu_memory=raw_instance_type["gpu_memory"],
        storage=raw_instance_type["storage"],
    )
    return instance


def list_available_instances(raw_instance_types, locations):
    spots = (True, False)
    locations = [loc["loc"] for loc in locations]
    instances = [instance_types(raw_instance_types[0])]
    list_instances = generate_instances(spots, locations, instances)

    assert len(list_instances) == 4
    assert [i.price for i in list_instances if i.spot] == [1, 70] * 2
    assert [i.price for i in list_instances if not i.spot] == [3.95] * 2


def test_gpu_name(caplog):
    assert get_gpu_name("1x H100 SXM5 80GB") == "H100"
    assert get_gpu_name("") is None


def transform(raw_catalog_items: list[RawCatalogItem]) -> list[CatalogItem]:
    items = []
    for raw in raw_catalog_items:
        item = CatalogItem(provider="datacrunch", **dataclasses.asdict(raw))
        items.append(item)
    return items


def test_available_query(mocker, raw_instance_types):
    catalog = Catalog(balance_resources=False, auto_reload=False)

    instance_type = instance_types(raw_instance_types[0])

    mocker.patch("datacrunch.DataCrunchClient.__init__", return_value=None)
    datacrunch = DataCrunchProvider("EXAMPLE", "EXAMPLE")
    datacrunch._get_instance_types = mocker.Mock(return_value=[instance_type])
    datacrunch._get_locations = mocker.Mock(return_value=[{"code": "FIN-01"}])

    internal_catalog.ONLINE_PROVIDERS = ["datacrunch"]
    internal_catalog.OFFLINE_PROVIDERS = []

    catalog.add_provider(datacrunch)
    query_result = catalog.query(provider=["datacrunch"])

    assert len(query_result) == 2

    expected_spot = CatalogItem(
        instance_name="1H100.80S.30V",
        location="FIN-01",
        price=1.7,
        cpu=30,
        memory=120.0,
        gpu_vendor=AcceleratorVendor.NVIDIA,
        gpu_count=1,
        gpu_name="H100",
        gpu_memory=80.0,
        spot=True,
        provider="datacrunch",
        disk_size=None,
    )
    expected_non_spot = CatalogItem(
        instance_name="1H100.80S.30V",
        location="FIN-01",
        price=3.95,
        cpu=30,
        memory=120.0,
        gpu_vendor=AcceleratorVendor.NVIDIA,
        gpu_count=1,
        gpu_name="H100",
        gpu_memory=80.0,
        spot=False,
        provider="datacrunch",
        disk_size=None,
    )
    assert [r for r in query_result if r.spot] == [expected_spot]
    assert [r for r in query_result if not r.spot] == [expected_non_spot]


def test_available_query_with_instance(mocker, raw_instance_types):
    catalog = Catalog(balance_resources=False, auto_reload=False)

    instance_type = instance_types(raw_instance_types[-1])
    print(instance_type)

    mocker.patch("datacrunch.DataCrunchClient.__init__", return_value=None)
    datacrunch = DataCrunchProvider("EXAMPLE", "EXAMPLE")
    datacrunch._get_instance_types = mocker.Mock(return_value=[instance_type])
    datacrunch._get_locations = mocker.Mock(return_value=[{"code": "FIN-01"}])

    internal_catalog.ONLINE_PROVIDERS = ["datacrunch"]
    internal_catalog.OFFLINE_PROVIDERS = []

    catalog.add_provider(datacrunch)
    query_result = catalog.query(provider=["datacrunch"])

    print(query_result)

    assert len(query_result) == 2

    expected_spot = CatalogItem(
        instance_name="1V100.6V",
        location="FIN-01",
        price=0.25,
        cpu=6,
        memory=23.0,
        gpu_vendor=AcceleratorVendor.NVIDIA,
        gpu_count=1,
        gpu_name="V100",
        gpu_memory=16.0,
        spot=True,
        provider="datacrunch",
        disk_size=None,
    )
    expected_non_spot = CatalogItem(
        instance_name="1V100.6V",
        location="FIN-01",
        price=0.89,
        cpu=6,
        memory=23.0,
        gpu_vendor=AcceleratorVendor.NVIDIA,
        gpu_count=1,
        gpu_name="V100",
        gpu_memory=16.0,
        spot=False,
        provider="datacrunch",
        disk_size=None,
    )

    assert [r for r in query_result if r.spot] == [expected_spot]
    assert [r for r in query_result if not r.spot] == [expected_non_spot]


def test_transform_instance(raw_instance_types):
    location = "ICE-01"
    is_spot = True
    item = transform_instance(instance_types(raw_instance_types[1]), is_spot, location)

    expected = RawCatalogItem(
        instance_name="2A6000.20V",
        location="ICE-01",
        price=0.7,
        cpu=20,
        memory=120,
        gpu_vendor=AcceleratorVendor.NVIDIA.value,
        gpu_count=2,
        gpu_name="A6000",
        gpu_memory=96 / 2,
        spot=True,
        disk_size=None,
    )

    assert RawCatalogItem.from_dict(item) == expected


def test_cpu_instance(raw_instance_types):
    location = "ICE-01"
    is_spot = False
    item = transform_instance(instance_types(raw_instance_types[2]), is_spot, location)

    expected = RawCatalogItem(
        instance_name="CPU.120V.480G",
        location="ICE-01",
        price=3,
        cpu=120,
        memory=480,
        gpu_vendor=None,
        gpu_count=0,
        gpu_name=None,
        gpu_memory=0,
        spot=False,
        disk_size=None,
    )

    assert RawCatalogItem.from_dict(item) == expected


def test_order(mocker, raw_instance_types):
    catalog = Catalog(balance_resources=False, auto_reload=False)

    types = map(instance_types, raw_instance_types)

    mocker.patch("datacrunch.DataCrunchClient.__init__", return_value=None)
    datacrunch = DataCrunchProvider("EXAMPLE", "EXAMPLE")
    datacrunch._get_instance_types = mocker.Mock(return_value=list(types))
    datacrunch._get_locations = mocker.Mock(return_value=[{"code": "FIN-01"}])

    internal_catalog.ONLINE_PROVIDERS = ["datacrunch"]
    internal_catalog.OFFLINE_PROVIDERS = []

    catalog.add_provider(datacrunch)
    query_result = catalog.query(provider=["datacrunch"])

    assert len(query_result) == 8

    assert [r.price for r in query_result] == sorted(r.price for r in query_result)

================
File: gpuhunt/src/tests/providers/test_oci.py
================
import pytest

from gpuhunt.providers.oci import get_gpu_name


@pytest.mark.parametrize(
    ("shape_name", "gpu_name"),
    [
        ("VM.GPU.A10.2", "A10"),
        ("BM.GPU.A100-v2.8", "A100"),
        ("BM.GPU4.8", "A100"),
        ("VM.GPU3.4", "V100"),
        ("VM.GPU2.1", "P100"),
        ("BM.GPU.H100.8", "H100"),
        ("VM.Standard2.8", None),
        ("VM.Notgpu.A10", None),
    ],
)
def test_get_gpu_name(shape_name, gpu_name):
    assert get_gpu_name(shape_name) == gpu_name

================
File: gpuhunt/src/tests/providers/test_providers.py
================
import importlib
import inspect
import pkgutil

import pytest

import gpuhunt.providers
from gpuhunt._internal.catalog import OFFLINE_PROVIDERS, ONLINE_PROVIDERS


@pytest.fixture()
def providers():
    """List of all provider classes"""
    members = []
    for module_info in pkgutil.walk_packages(gpuhunt.providers.__path__):
        module = importlib.import_module(
            f".{module_info.name}",
            package="gpuhunt.providers",
        )
        for _, member in inspect.getmembers(module):
            if not inspect.isclass(member):
                continue
            if member.__name__.islower():
                continue  # skip builtins to avoid CPython bug #89489 in `issubclass` below
            if not issubclass(member, gpuhunt.providers.AbstractProvider):
                continue
            if member.__name__ == "AbstractProvider":
                continue
            if member.NAME == "nebius":  # The provider has been temporarily disabled
                continue
            members.append(member)
    assert members
    return members


def test_catalog_providers_is_unique():
    CATALOG_PROVIDERS = OFFLINE_PROVIDERS + ONLINE_PROVIDERS
    assert len(set(CATALOG_PROVIDERS)) == len(CATALOG_PROVIDERS)


def test_all_providers_have_a_names(providers):
    names = [p.NAME for p in providers]
    assert gpuhunt.providers.AbstractProvider.NAME not in names
    assert len(set(names)) == len(names)


def test_catalog_providers(providers):
    CATALOG_PROVIDERS = OFFLINE_PROVIDERS + ONLINE_PROVIDERS
    names = [p.NAME for p in providers]
    assert set(CATALOG_PROVIDERS) == set(names)
    assert len(CATALOG_PROVIDERS) == len(names)

================
File: gpuhunt/src/tests/providers/test_scaleway.py
================
import os
import pytest
import responses

from gpuhunt._internal.models import AcceleratorVendor
from gpuhunt.providers.scaleway import ScalewayProvider

@pytest.fixture
def mock_env(monkeypatch):
    monkeypatch.setenv("OPENAI_API_KEY", "test-key")

@pytest.fixture
def provider(mock_env):
    return ScalewayProvider()

@responses.activate
def test_scrape_scaleway(provider):
    # Mock response for Scaleway pricing page
    responses.add(
        responses.GET,
        "https://www.scaleway.com/en/pricing/gpu/",
        body="""
        <html>
            <body>
                <div class="pricing-table">
                    <div class="gpu-instances">
                        <h2>GPU Instances</h2>
                        <div class="instance">
                            <h3>RENDER-S</h3>
                            <ul>
                                <li>NVIDIA RTX A4000 GPU</li>
                                <li>8 CPU cores</li>
                                <li>32 GB RAM</li>
                                <li>256 GB SSD</li>
                                <li>€1.36/hour</li>
                            </ul>
                        </div>
                        <div class="instance">
                            <h3>GPU-5000-S</h3>
                            <ul>
                                <li>NVIDIA A5000 GPU</li>
                                <li>12 CPU cores</li>
                                <li>64 GB RAM</li>
                                <li>512 GB SSD</li>
                                <li>€2.27/hour</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </body>
        </html>
        """,
        status=200,
    )

    offers = provider.get()
    assert len(offers) == 2

    # Check RENDER-S instance
    render_s = next(o for o in offers if o.instance_name == "A4000-1x")
    assert render_s.location in ["Paris", "Amsterdam"]
    assert render_s.price == pytest.approx(1.50)  # €1.36 * 1.10
    assert render_s.cpu == 8
    assert render_s.memory == 32
    assert render_s.gpu_vendor == AcceleratorVendor.NVIDIA
    assert render_s.gpu_count == 1
    assert render_s.gpu_name == "A4000"
    assert render_s.gpu_memory == 16
    assert render_s.disk_size == 256

    # Check GPU-5000-S instance
    gpu_5000 = next(o for o in offers if o.instance_name == "A5000-1x")
    assert gpu_5000.location in ["Paris", "Amsterdam"]
    assert gpu_5000.price == pytest.approx(2.50)  # €2.27 * 1.10
    assert gpu_5000.cpu == 12
    assert gpu_5000.memory == 64
    assert gpu_5000.gpu_vendor == AcceleratorVendor.NVIDIA
    assert gpu_5000.gpu_count == 1
    assert gpu_5000.gpu_name == "A5000"
    assert gpu_5000.gpu_memory == 24
    assert gpu_5000.disk_size == 512

@responses.activate
def test_scrape_error(provider):
    # Mock failed response
    responses.add(
        responses.GET,
        "https://www.scaleway.com/en/pricing/gpu/",
        status=500,
    )

    offers = provider.get()
    assert len(offers) == 0  # Should return empty list on error

def test_missing_api_key(monkeypatch):
    monkeypatch.delenv("OPENAI_API_KEY", raising=False)
    with pytest.raises(ValueError, match="OPENAI_API_KEY environment variable must be set"):
        ScalewayProvider()

================
File: gpuhunt/src/tests/providers/test_tensordock.py
================
import pytest

from gpuhunt import QueryFilter
from gpuhunt._internal.models import RawCatalogItem
from gpuhunt.providers.tensordock import TensorDockProvider


@pytest.fixture
def specs() -> dict:
    return {
        "cpu": {"amount": 256, "price": 0.003, "type": "Intel Xeon Platinum 8352Y"},
        "gpu": {
            "l40-pcie-48gb": {
                "amount": 8,
                "gtx": False,
                "pcie": True,
                "price": 1.05,
                "rtx": False,
                "vram": 48,
            }
        },
        "ram": {"amount": 1495, "price": 0.002},
        "storage": {"amount": 10252, "price": 5e-05},
    }


class TestTensorDockMinimalConfiguration:
    def test_no_requirements(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(), specs, "", "")
        assert offers == make_offers(specs, cpu=16, memory=96, disk_size=96, gpu_count=1)

    def test_min_cpu_no_balance(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(
            QueryFilter(min_cpu=4), specs, "", "", balance_resources=False
        )
        assert offers == make_offers(specs, cpu=4, memory=96, disk_size=96, gpu_count=1)

    def test_min_cpu(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(min_cpu=4), specs, "", "")
        assert offers == make_offers(specs, cpu=16, memory=96, disk_size=96, gpu_count=1)

    def test_too_many_min_cpu(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(min_cpu=1000), specs, "", "")
        assert offers == []

    def test_min_memory_no_balance(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(
            QueryFilter(min_memory=3), specs, "", "", balance_resources=False
        )
        assert offers == make_offers(specs, cpu=2, memory=4, disk_size=48, gpu_count=1)

    def test_min_memory(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(min_memory=3), specs, "", "")
        assert offers == make_offers(specs, cpu=16, memory=96, disk_size=96, gpu_count=1)

    def test_too_large_min_memory(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(min_memory=2000), specs, "", "")
        assert offers == []

    def test_min_gpu_count(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(min_gpu_count=2), specs, "", "")
        assert offers == make_offers(specs, cpu=32, memory=192, disk_size=192, gpu_count=2)

    def test_min_no_gpu(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(QueryFilter(max_gpu_count=0), specs, "", "")
        assert offers == []

    def test_min_total_gpu_memory(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(
            QueryFilter(min_total_gpu_memory=100), specs, "", ""
        )
        assert offers == make_offers(specs, cpu=48, memory=288, disk_size=288, gpu_count=3)

    def test_controversial_gpu(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(
            QueryFilter(min_total_gpu_memory=100, max_gpu_count=2), specs, "", ""
        )
        assert offers == []

    def test_all_cpu_all_gpu(self, specs: dict):
        offers = TensorDockProvider.optimize_offers(
            QueryFilter(min_cpu=256, min_gpu_count=1), specs, "", ""
        )
        assert offers == make_offers(specs, cpu=256, memory=768, disk_size=768, gpu_count=8)


def make_offers(
    specs: dict, cpu: int, memory: float, disk_size: float, gpu_count: int
) -> list[RawCatalogItem]:
    gpu = list(specs["gpu"].values())[0]
    price = cpu * specs["cpu"]["price"]
    price += memory * specs["ram"]["price"]
    price += disk_size * specs["storage"]["price"]
    price += gpu_count * gpu["price"]
    return [
        RawCatalogItem(
            instance_name="",
            location="",
            price=round(price, 5),
            cpu=cpu,
            memory=memory,
            gpu_vendor=None,
            gpu_count=gpu_count,
            gpu_name="L40",
            gpu_memory=gpu["vram"],
            spot=False,
            disk_size=disk_size,
        )
    ]

================
File: gpuhunt/src/tests/providers/test_vultr.py
================
import gpuhunt._internal.catalog as internal_catalog
from gpuhunt import Catalog
from gpuhunt.providers.vultr import VultrProvider, fetch_offers

bare_metal = {
    "plans_metal": [
        {
            "id": "vbm-256c-2048gb-8-mi300x-gpu",
            "physical_cpus": 2,
            "cpu_count": 128,
            "cpu_cores": 128,
            "cpu_threads": 256,
            "cpu_model": "EPYC 9534",
            "cpu_mhz": 2450,
            "ram": 2321924,
            "disk": 3576,
            "disk_count": 8,
            "bandwidth": 10240,
            "monthly_cost": 11773.44,
            "hourly_cost": 17.52,
            "monthly_cost_preemptible": 9891.84,
            "hourly_cost_preemptible": 14.72,
            "type": "NVMe",
            "locations": ["ord"],
        },
        {
            "id": "vbm-112c-2048gb-8-h100-gpu",
            "physical_cpus": 2,
            "cpu_count": 112,
            "cpu_cores": 112,
            "cpu_threads": 224,
            "cpu_model": "Platinum 8480+",
            "cpu_mhz": 2000,
            "ram": 2097152,
            "disk": 960,
            "disk_count": 2,
            "bandwidth": 15360,
            "monthly_cost": 16074.24,
            "hourly_cost": 23.92,
            "monthly_cost_preemptible": 12364.8,
            "hourly_cost_preemptible": 18.4,
            "type": "NVMe",
            "locations": ["sea"],
        },
    ]
}

vm_instances = {
    "plans": [
        {
            "id": "vcg-a100-1c-6g-4vram",
            "vcpu_count": 1,
            "ram": 6144,
            "disk": 70,
            "disk_count": 1,
            "bandwidth": 1024,
            "monthly_cost": 90,
            "hourly_cost": 0.123,
            "type": "vcg",
            "locations": ["ewr"],
            "gpu_vram_gb": 4,
            "gpu_type": "NVIDIA_A100",
        },
        {
            "id": "vcg-a100-12c-120g-80vram",
            "vcpu_count": 12,
            "ram": 122880,
            "disk": 1400,
            "disk_count": 1,
            "bandwidth": 10240,
            "monthly_cost": 1750,
            "hourly_cost": 2.397,
            "type": "vcg",
            "locations": ["ewr"],
            "gpu_vram_gb": 80,
            "gpu_type": "NVIDIA_A100",
        },
        {
            "id": "vcg-a100-6c-60g-40vram",
            "vcpu_count": 12,
            "ram": 61440,
            "disk": 1400,
            "disk_count": 1,
            "bandwidth": 10240,
            "monthly_cost": 800,
            "hourly_cost": 1.397,
            "type": "vcg",
            "locations": ["ewr"],
            "gpu_vram_gb": 40,
            "gpu_type": "NVIDIA_A100",
        },
    ]
}


def test_fetch_offers(requests_mock):
    # Mocking the responses for the API endpoints
    requests_mock.get("https://api.vultr.com/v2/plans-metal?per_page=500", json=bare_metal)
    requests_mock.get("https://api.vultr.com/v2/plans?type=all&per_page=500", json=vm_instances)

    # Fetch offers and verify results
    assert len(fetch_offers()) == 5
    catalog = Catalog(balance_resources=False, auto_reload=False)
    vultr = VultrProvider()
    internal_catalog.ONLINE_PROVIDERS = ["vultr"]
    internal_catalog.OFFLINE_PROVIDERS = []
    catalog.add_provider(vultr)
    assert len(catalog.query(provider=["vultr"], min_gpu_count=1, max_gpu_count=1)) == 3
    assert len(catalog.query(provider=["vultr"], min_gpu_memory=80, max_gpu_count=1)) == 1
    assert len(catalog.query(provider=["vultr"], gpu_vendor="amd")) == 1
    assert len(catalog.query(provider=["vultr"], gpu_name="MI300X")) == 1

================
File: gpuhunt/tests/providers/test_leadergpu.py
================
import os
import pytest
import responses
import json

from gpuhunt._internal.models import AcceleratorVendor
from gpuhunt.providers.leadergpu import LeaderGPUProvider, parse_memory, parse_cpu_cores, parse_gpu_count_and_model, parse_price

def test_parse_memory():
    assert parse_memory("16GB") == 16.0
    assert parse_memory("32 GB") == 32.0
    assert parse_memory("64GiB") == 64.0
    assert parse_memory("128 G") == 128.0
    assert parse_memory("invalid") == 0.0
    assert parse_memory(None) == 0.0

def test_parse_cpu_cores():
    assert parse_cpu_cores("32 cores") == 32
    assert parse_cpu_cores("64 vCPU") == 64
    assert parse_cpu_cores("16 Core") == 16
    assert parse_cpu_cores("invalid") == 0
    assert parse_cpu_cores(None) == 0

def test_parse_gpu_count_and_model():
    assert parse_gpu_count_and_model("4x NVIDIA RTX 4090") == (4, "RTX 4090")
    assert parse_gpu_count_and_model("8x A100") == (8, "A100")
    assert parse_gpu_count_and_model("NVIDIA H100") == (1, "H100")
    assert parse_gpu_count_and_model(None) == (0, "")

def test_parse_price():
    assert parse_price("€1200/month") == pytest.approx(1200 / (24 * 30))
    assert parse_price("€300/week") == pytest.approx(300 / (24 * 7))
    assert parse_price("€50/day") == pytest.approx(50 / 24)
    assert parse_price("€0.02/minute") == pytest.approx(0.02 * 60)
    assert parse_price("invalid") == 0.0
    assert parse_price(None) == 0.0

@pytest.fixture
def provider():
    return LeaderGPUProvider()

@responses.activate
def test_scrape_leadergpu(provider):
    # Mock JSON response from LeaderGPU
    mock_response = {
        "matchesHtml": """
        <section class="b-product-gpu">
            <div class="b-product-gpu-title">
                <a href="/server_configurations/123">4x RTX 4090 Server</a>
            </div>
            <div class="config-list">
                <div>GPU: <p>4x NVIDIA RTX 4090</p></div>
                <div>GPU RAM: <span>24 GB</span></div>
                <div>CPU: <span>32 cores</span></div>
                <div>RAM: <span>256 GB</span></div>
                <div>NVME: <span>2 TB</span></div>
            </div>
            <div class="b-product-gpu-prices">
                <li class="d-flex"><p>€1200/month</p></li>
                <li class="d-flex"><p>€300/week</p></li>
            </div>
        </section>
        <section class="b-product-gpu">
            <div class="b-product-gpu-title">
                <a href="/server_configurations/456">8x A100 Server</a>
            </div>
            <div class="config-list">
                <div>GPU: <p>8x NVIDIA A100</p></div>
                <div>GPU RAM: <span>80 GB</span></div>
                <div>CPU: <span>64 cores</span></div>
                <div>RAM: <span>512 GB</span></div>
                <div>NVME: <span>4 TB</span></div>
            </div>
            <div class="b-product-gpu-prices">
                <li class="d-flex"><p>€4800/month</p></li>
            </div>
        </section>
        """
    }
    
    responses.add(
        responses.GET,
        "https://www.leadergpu.com/filter_servers?filterExpression=os%3Awindows_server%3Bavailable_server%3Bavailable_server_next3d%3Bmonth%3A1",
        json=mock_response,
        status=200,
    )

    offers = provider.get()
    assert len(offers) == 2

    # Check 4x RTX 4090 instance
    rtx_4090 = next(o for o in offers if o.instance_name == "RTX 4090-4x")
    assert rtx_4090.location == "EU"
    assert rtx_4090.price == pytest.approx(1200 / (24 * 30))  # Convert monthly to hourly
    assert rtx_4090.cpu == 32
    assert rtx_4090.memory == 256
    assert rtx_4090.gpu_vendor == AcceleratorVendor.NVIDIA
    assert rtx_4090.gpu_count == 4
    assert rtx_4090.gpu_name == "RTX 4090"
    assert rtx_4090.gpu_memory == 24
    assert rtx_4090.disk_size == 2048  # 2TB in GB

    # Check 8x A100 instance
    a100 = next(o for o in offers if o.instance_name == "A100-8x")
    assert a100.location == "EU"
    assert a100.price == pytest.approx(4800 / (24 * 30))  # Convert monthly to hourly
    assert a100.cpu == 64
    assert a100.memory == 512
    assert a100.gpu_vendor == AcceleratorVendor.NVIDIA
    assert a100.gpu_count == 8
    assert a100.gpu_name == "A100"
    assert a100.gpu_memory == 80
    assert a100.disk_size == 4096  # 4TB in GB

@responses.activate
def test_scrape_error(provider):
    # Mock failed response
    responses.add(
        responses.GET,
        "https://www.leadergpu.com/filter_servers?filterExpression=os%3Awindows_server%3Bavailable_server%3Bavailable_server_next3d%3Bmonth%3A1",
        status=500,
    )

    offers = provider.get()
    assert len(offers) == 0  # Should return empty list on error

================
File: gpuhunt/README.md
================
[![](https://img.shields.io/pypi/v/gpuhunt)](https://pypi.org/project/gpuhunt/)

Easy access to GPU pricing data for major cloud providers: AWS, Azure, GCP, etc.
The catalog includes details about prices, locations, CPUs, RAM, GPUs, and spots (interruptible instances).

## Usage

```python
import gpuhunt

items = gpuhunt.query(
    min_memory=16,
    min_cpu=8,
    min_gpu_count=1,
    max_price=1.0,
)

print(*items, sep="\n")
```

List of all available filters:

* `provider`: name of the provider to filter by. If not specified, all providers will be used. One or many
* `min_cpu`: minimum number of CPUs
* `max_cpu`: maximum number of CPUs
* `min_memory`: minimum amount of RAM in GB
* `max_memory`: maximum amount of RAM in GB
* `min_gpu_count`: minimum number of GPUs
* `max_gpu_count`: maximum number of GPUs
* `gpu_name`: name of the GPU to filter by. If not specified, all GPUs will be used. One or many
* `min_gpu_memory`: minimum amount of GPU VRAM in GB for each GPU
* `max_gpu_memory`: maximum amount of GPU VRAM in GB for each GPU
* `min_total_gpu_memory`: minimum amount of GPU VRAM in GB for all GPUs combined
* `max_total_gpu_memory`: maximum amount of GPU VRAM in GB for all GPUs combined
* `min_disk_size`: minimum disk size in GB (not fully supported)
* `max_disk_size`: maximum disk size in GB (not fully supported)
* `min_price`: minimum price per hour in USD
* `max_price`: maximum price per hour in USD
* `min_compute_capability`: minimum compute capability of the GPU
* `max_compute_capability`: maximum compute capability of the GPU
* `spot`: if `False`, only ondemand offers will be returned. If `True`, only spot offers will be returned

## Advanced usage

```python
from gpuhunt import Catalog

catalog = Catalog()
catalog.load(version="20240508")
items = catalog.query()

print(*items, sep="\n")
```

## Supported providers

* AWS
* Azure
* Cudo Compute
* DataCrunch
* GCP
* LambdaLabs
* OCI
* RunPod
* TensorDock
* Vast AI

## See also

* [dstack](https://github.com/dstackai/dstack)

================
File: middleware/auth.py
================
from functools import wraps
from flask import request, jsonify, g
from firebase_admin import auth


def require_auth():
    def decorator(f):
        @wraps(f)
        def decorated_function(*args, **kwargs):
            auth_header = request.headers.get('Authorization')
            if not auth_header:
                return jsonify({'error': 'No authorization header'}), 401

            try:
                # Remove 'Bearer ' from token
                id_token = auth_header.split(' ')[1]
                # Verify the token
                decoded_token = auth.verify_id_token(id_token)
                # Set the user ID in flask.g
                g.user_id = decoded_token['uid']
                return f(*args, **kwargs)
            except Exception as e:
                print(f"Auth error: {str(e)}")
                return jsonify({'error': 'Invalid token'}), 401
        return decorated_function
    return decorator

================
File: migrations/versions/1c11b26cc472_update_gpu_schema_for_gpuhunt_.py
================
"""Update GPU schema for gpuhunt integration

Revision ID: 1c11b26cc472
Revises: 
Create Date: 2025-01-14 21:22:58.101309

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '1c11b26cc472'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('gpu_listings', schema=None) as batch_op:
        batch_op.add_column(sa.Column('instance_name', sa.String(length=255), nullable=False))
        batch_op.add_column(sa.Column('gpu_name', sa.String(length=255), nullable=True))
        batch_op.add_column(sa.Column('gpu_vendor', sa.String(length=50), nullable=True))
        batch_op.add_column(sa.Column('gpu_count', sa.Integer(), nullable=False))
        batch_op.add_column(sa.Column('gpu_memory', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('cpu', sa.Integer(), nullable=True))
        batch_op.add_column(sa.Column('memory', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('disk_size', sa.Float(), nullable=True))
        batch_op.add_column(sa.Column('last_updated', sa.DateTime(), nullable=False))
        batch_op.drop_column('price_metric')
        batch_op.drop_column('description')
        batch_op.drop_column('flops')
        batch_op.drop_column('number_of_gpus')
        batch_op.drop_column('vram')
        batch_op.drop_column('image_url')
        batch_op.drop_column('name')
        batch_op.drop_column('reliability')

    with op.batch_alter_table('gpu_price_history', schema=None) as batch_op:
        batch_op.add_column(sa.Column('location', sa.String(length=255), nullable=False))
        batch_op.add_column(sa.Column('spot', sa.Boolean(), nullable=True))
        batch_op.drop_column('region')
        batch_op.drop_column('cpu_count')
        batch_op.drop_column('memory_gb')
        batch_op.drop_column('provider')
        batch_op.drop_column('spot_price')

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('gpu_price_history', schema=None) as batch_op:
        batch_op.add_column(sa.Column('spot_price', sa.BOOLEAN(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('provider', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('memory_gb', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('cpu_count', sa.INTEGER(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('region', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
        batch_op.drop_column('spot')
        batch_op.drop_column('location')

    with op.batch_alter_table('gpu_listings', schema=None) as batch_op:
        batch_op.add_column(sa.Column('reliability', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('name', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('image_url', sa.VARCHAR(length=255), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('vram', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('number_of_gpus', sa.INTEGER(), autoincrement=False, nullable=True))
        batch_op.add_column(sa.Column('flops', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('description', sa.TEXT(), autoincrement=False, nullable=False))
        batch_op.add_column(sa.Column('price_metric', sa.VARCHAR(length=10), autoincrement=False, nullable=False))
        batch_op.drop_column('last_updated')
        batch_op.drop_column('disk_size')
        batch_op.drop_column('memory')
        batch_op.drop_column('cpu')
        batch_op.drop_column('gpu_memory')
        batch_op.drop_column('gpu_count')
        batch_op.drop_column('gpu_vendor')
        batch_op.drop_column('gpu_name')
        batch_op.drop_column('instance_name')

    # ### end Alembic commands ###

================
File: migrations/env.py
================
import logging
from logging.config import fileConfig

from flask import current_app

from alembic import context

# this is the Alembic Config object, which provides
# access to the values within the .ini file in use.
config = context.config

# Interpret the config file for Python logging.
# This line sets up loggers basically.
fileConfig(config.config_file_name)
logger = logging.getLogger('alembic.env')


def get_engine():
    try:
        # this works with Flask-SQLAlchemy<3 and Alchemical
        return current_app.extensions['migrate'].db.get_engine()
    except (TypeError, AttributeError):
        # this works with Flask-SQLAlchemy>=3
        return current_app.extensions['migrate'].db.engine


def get_engine_url():
    try:
        return get_engine().url.render_as_string(hide_password=False).replace(
            '%', '%%')
    except AttributeError:
        return str(get_engine().url).replace('%', '%%')


# add your model's MetaData object here
# for 'autogenerate' support
# from myapp import mymodel
# target_metadata = mymodel.Base.metadata
config.set_main_option('sqlalchemy.url', get_engine_url())
target_db = current_app.extensions['migrate'].db

# other values from the config, defined by the needs of env.py,
# can be acquired:
# my_important_option = config.get_main_option("my_important_option")
# ... etc.


def get_metadata():
    if hasattr(target_db, 'metadatas'):
        return target_db.metadatas[None]
    return target_db.metadata


def run_migrations_offline():
    """Run migrations in 'offline' mode.

    This configures the context with just a URL
    and not an Engine, though an Engine is acceptable
    here as well.  By skipping the Engine creation
    we don't even need a DBAPI to be available.

    Calls to context.execute() here emit the given string to the
    script output.

    """
    url = config.get_main_option("sqlalchemy.url")
    context.configure(
        url=url, target_metadata=get_metadata(), literal_binds=True
    )

    with context.begin_transaction():
        context.run_migrations()


def run_migrations_online():
    """Run migrations in 'online' mode.

    In this scenario we need to create an Engine
    and associate a connection with the context.

    """

    # this callback is used to prevent an auto-migration from being generated
    # when there are no changes to the schema
    # reference: http://alembic.zzzcomputing.com/en/latest/cookbook.html
    def process_revision_directives(context, revision, directives):
        if getattr(config.cmd_opts, 'autogenerate', False):
            script = directives[0]
            if script.upgrade_ops.is_empty():
                directives[:] = []
                logger.info('No changes in schema detected.')

    conf_args = current_app.extensions['migrate'].configure_args
    if conf_args.get("process_revision_directives") is None:
        conf_args["process_revision_directives"] = process_revision_directives

    connectable = get_engine()

    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=get_metadata(),
            **conf_args
        )

        with context.begin_transaction():
            context.run_migrations()


if context.is_offline_mode():
    run_migrations_offline()
else:
    run_migrations_online()

================
File: models/gpu_listing.py
================
from utils.database import db 
from datetime import datetime

class Host(db.Model):
    __tablename__ = 'hosts'
    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)  # This will store the provider name
    description = db.Column(db.Text, nullable=False)
    url = db.Column(db.String(255), nullable=True)

    def to_dict(self):
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'url': self.url
        }

class GPUListing(db.Model):
    __tablename__ = 'gpu_listings'

    id = db.Column(db.Integer, primary_key=True)
    instance_name = db.Column(db.String(255), nullable=False)
    gpu_name = db.Column(db.String(255), nullable=True)
    gpu_vendor = db.Column(db.String(50), nullable=True)  # NVIDIA, AMD, or GOOGLE
    gpu_count = db.Column(db.Integer, nullable=False)
    gpu_memory = db.Column(db.Float, nullable=True)  # in GB
    current_price = db.Column(db.Float, nullable=False)  # Lowest current price
    price_change = db.Column(db.String(10), nullable=False, default="0%")
    cpu = db.Column(db.Integer, nullable=True)
    memory = db.Column(db.Float, nullable=True)  # in GB
    disk_size = db.Column(db.Float, nullable=True)  # in GB
    host_id = db.Column(db.Integer, db.ForeignKey('hosts.id'), nullable=False)
    last_updated = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)

    # Relationships
    host = db.relationship('Host', backref='listings')
    price_points = db.relationship('GPUPricePoint', backref='gpu', lazy='dynamic')
    price_history = db.relationship('GPUPriceHistory', backref='gpu', lazy='dynamic')

    def __init__(self, instance_name, gpu_name, gpu_vendor, gpu_count, gpu_memory, 
                 current_price, cpu, memory, disk_size, host_id):
        self.instance_name = instance_name
        self.gpu_name = gpu_name
        self.gpu_vendor = gpu_vendor
        self.gpu_count = gpu_count
        self.gpu_memory = gpu_memory
        self.current_price = current_price
        self.cpu = cpu
        self.memory = memory
        self.disk_size = disk_size
        self.host_id = host_id
        self.last_updated = datetime.utcnow()

    def to_dict(self):
        return {
            'id': self.id,
            'instance_name': self.instance_name,
            'gpu_name': self.gpu_name,
            'gpu_vendor': self.gpu_vendor,
            'gpu_count': self.gpu_count,
            'gpu_memory': self.gpu_memory,
            'current_price': self.current_price,
            'price_change': self.price_change,
            'cpu': self.cpu,
            'memory': self.memory,
            'disk_size': self.disk_size,
            'provider': self.host.name,
            'last_updated': self.last_updated.isoformat()
        }

class GPUPricePoint(db.Model):
    """Real-time price points for each GPU instance in different regions"""
    __tablename__ = 'gpu_price_points'

    id = db.Column(db.Integer, primary_key=True)
    gpu_listing_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=False)
    price = db.Column(db.Float, nullable=False)
    location = db.Column(db.String(255), nullable=False)
    spot = db.Column(db.Boolean, default=False)
    last_updated = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)

    def to_dict(self):
        return {
            'id': self.id,
            'price': self.price,
            'location': self.location,
            'spot': self.spot,
            'last_updated': self.last_updated.isoformat()
        }

class GPUPriceHistory(db.Model):
    """Historical price records for each GPU instance"""
    __tablename__ = 'gpu_price_history'

    id = db.Column(db.Integer, primary_key=True)
    gpu_listing_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=False)
    price = db.Column(db.Float, nullable=False)
    date = db.Column(db.DateTime, nullable=False, default=datetime.utcnow)
    location = db.Column(db.String(255), nullable=False)
    spot = db.Column(db.Boolean, default=False)

    def to_dict(self):
        return {
            'id': self.id,
            'price': self.price,
            'date': self.date.isoformat(),
            'location': self.location,
            'spot': self.spot
        }

================
File: models/project.py
================
from utils.database import db
from datetime import datetime

class Project(db.Model):
    __tablename__ = "projects"

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(255), nullable=False)
    description = db.Column(db.Text, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    user_id = db.Column(db.Integer, db.ForeignKey('users.id'), nullable=False)
    
    # Relationship with GPUs through association table
    gpus = db.relationship('GPUListing', secondary='project_gpus', backref=db.backref('projects', lazy='dynamic'))

    def to_dict(self):
        return {
            'id': self.id,
            'name': self.name,
            'description': self.description,
            'created_at': self.created_at.isoformat(),
            'updated_at': self.updated_at.isoformat(),
            'gpus': [gpu.to_dict() for gpu in self.gpus]
        }

class ProjectGPU(db.Model):
    __tablename__ = 'project_gpus'
    
    project_id = db.Column(db.Integer, db.ForeignKey('projects.id'), primary_key=True)
    gpu_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), primary_key=True)
    added_at = db.Column(db.DateTime, default=datetime.utcnow)

================
File: models/user_preferences.py
================
from utils.database import db
from datetime import datetime

class RentedGPU(db.Model):
    __tablename__ = 'rented_gpus'
    
    id = db.Column(db.Integer, primary_key=True)
    gpu_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=False)
    is_active = db.Column(db.Boolean, default=True)
    rental_start = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)
    rental_end = db.Column(db.DateTime, nullable=True)
    
    # Relationship with GPUListing
    gpu = db.relationship('GPUListing', backref='rentals')

    def to_dict(self):
        return {
            'id': self.gpu.id,
            'name': self.gpu.name,
            'isActive': self.is_active,
            'rentalStart': self.rental_start.isoformat(),
            'rentalEnd': self.rental_end.isoformat() if self.rental_end else None
        }

class PriceAlert(db.Model):
    __tablename__ = 'price_alerts'
    
    id = db.Column(db.Integer, primary_key=True)
    gpu_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=True)  # Nullable for type-based alerts
    gpu_type = db.Column(db.String(255), nullable=True)  # For type-based alerts
    target_price = db.Column(db.Float, nullable=False)
    is_type_alert = db.Column(db.Boolean, default=False, nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)
    
    # Relationship with GPUListing (only for individual GPU alerts)
    gpu = db.relationship('GPUListing', backref='price_alerts')

    def to_dict(self):
        alert_id = f"type_{self.gpu_type}" if self.is_type_alert else str(self.gpu_id)
        return {
            alert_id: {
                'targetPrice': self.target_price,
                'isTypeAlert': self.is_type_alert,
                'gpuType': self.gpu_type if self.is_type_alert else None,
                'createdAt': self.created_at.isoformat()
            }
        }

class SelectedGPU(db.Model):
    __tablename__ = 'selected_gpus'
    
    id = db.Column(db.Integer, primary_key=True)
    gpu_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    # Relationships
    gpu = db.relationship('GPUListing', backref=db.backref('selected_by', lazy=True))
    
    def to_dict(self):
        return {
            'id': self.id,
            'gpu_id': self.gpu_id,
            'created_at': self.created_at.isoformat(),
            'gpu': self.gpu.to_dict() if self.gpu else None
        }

class FavoriteGPU(db.Model):
    __tablename__ = 'favorite_gpus'
    
    id = db.Column(db.Integer, primary_key=True)
    gpu_id = db.Column(db.Integer, db.ForeignKey('gpu_listings.id'), nullable=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow, nullable=False)
    
    # Relationship with GPUListing
    gpu = db.relationship('GPUListing', backref='favorites')

    def to_dict(self):
        return {
            'id': self.gpu.id,
            'name': self.gpu.name,
            'host_name': self.gpu.host.name
        }

================
File: models/user.py
================
from utils.database import db
from datetime import datetime


class User(db.Model):
    __tablename__ = "users"

    id = db.Column(db.Integer, primary_key=True)
    firebase_uid = db.Column(db.String(255), unique=True, nullable=False)
    email = db.Column(db.String(255), nullable=False)
    organization = db.Column(db.String(255))
    email_verified = db.Column(db.Boolean, default=False)
    disabled = db.Column(db.Boolean, default=False)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    last_login = db.Column(db.DateTime, default=datetime.utcnow)
    first_name = db.Column(db.String(255), nullable=False)
    last_name = db.Column(db.String(255), nullable=False)
    experience_level = db.Column(db.String(50), default="beginner")
    referral_source = db.Column(db.String(50), default="")

    # Relationships with preference models
    # rented_gpus = db.relationship("RentedGPU", backref=db.backref("user", lazy=True))
    # price_alerts = db.relationship("PriceAlert", backref=db.backref("user", lazy=True))
    # selected_gpus = db.relationship("SelectedGPU", backref=db.backref("user", lazy=True))
    # favorite_gpus = db.relationship("FavoriteGPU", backref=db.backref("user", lazy=True))

    # Add projects relationship
    projects = db.relationship('Project', backref='user', lazy=True)

    def __repr__(self):
        return f"<User {self.email}>"

    def to_dict(self):
        return {
            "id": self.id,
            "firebase_uid": self.firebase_uid,
            "email": self.email,
            "organization": self.organization,
            "email_verified": self.email_verified,
            "disabled": self.disabled,
            "created_at": self.created_at.isoformat(),
            "last_login": self.last_login.isoformat(),
            "first_name": self.first_name,
            "last_name": self.last_name,
            "experience_level": self.experience_level,
            "referral_source": self.referral_source,
            "projects": [project.to_dict() for project in self.projects]
        }

    @staticmethod
    def from_firebase_user(firebase_user):
        """Create or update user from Firebase user data"""
        return {
            "firebase_uid": firebase_user["uid"],
            "email": firebase_user.get("email"),
            "first_name": firebase_user.get("name", "").split()[0],
            "last_name": " ".join(firebase_user.get("name", "").split()[1:]),
            "email_verified": firebase_user.get("email_verified", False),
            "disabled": firebase_user.get("disabled", False),
        }

================
File: routes/gpu_listings.py
================
from flask import Blueprint, jsonify, request
from models.gpu_listing import GPUListing, Host, GPUPriceHistory, GPUPricePoint
from utils.database import db
from datetime import datetime

bp = Blueprint("gpu", __name__)


@bp.route("/get_all", methods=["GET"])
def get_all_gpus():
    try:
        listings = GPUListing.query.all()
        print(f"Found {len(listings)} GPU listings")
        result = [listing.to_dict() for listing in listings]
        print(f"Converted {len(result)} listings to dict")
        return jsonify(result)
    except Exception as e:
        print(f"Error fetching GPUs: {str(e)}")
        return jsonify({"error": "Failed to fetch GPUs"}), 500


@bp.route("/search", methods=["GET"])
def search_gpus():
    try:
        query = request.args.get("q", "")
        listings = GPUListing.query.filter(GPUListing.name.ilike(f"%{query}%")).all()
        return jsonify([listing.to_dict() for listing in listings])
    except Exception as e:
        print(f"Error searching GPUs: {str(e)}")
        return jsonify({"error": "Failed to search GPUs"}), 500


@bp.route("/<int:id>", methods=["GET"])
def get_gpu(id):
    try:
        listing = GPUListing.query.get_or_404(id)
        return jsonify(listing.to_dict())
    except Exception as e:
        print(f"Error fetching GPU {id}: {str(e)}")
        return jsonify({"error": f"Failed to fetch GPU {id}"}), 500


@bp.route("/hosts", methods=["GET"])
def get_hosts():
    try:
        hosts = Host.query.all()
        return jsonify([host.to_dict() for host in hosts])
    except Exception as e:
        print(f"Error fetching hosts: {str(e)}")
        return jsonify({"error": "Failed to fetch hosts"}), 500


@bp.route("/get_gpus/<int:page_number>", methods=["GET"])
def get_paginated_gpus(page_number):
    try:
        # Calculate pagination parameters
        per_page = 200
        
        # Get paginated results
        paginated_listings = GPUListing.query.order_by(GPUListing.id).paginate(
            page=page_number, per_page=per_page, error_out=False
        )
        
        if not paginated_listings.items and page_number > 1:
            return jsonify({"error": "Page number exceeds available pages"}), 404
            
        # Calculate total pages
        total_gpus = GPUListing.query.count()
        total_pages = (total_gpus + per_page - 1) // per_page
        
        return jsonify({
            "gpus": [listing.to_dict() for listing in paginated_listings.items],
            "current_page": page_number,
            "total_pages": total_pages,
            "total_gpus": total_gpus,
            "gpus_per_page": per_page
        })
    except Exception as e:
        print(f"Error fetching GPUs for page {page_number}: {str(e)}")
        return jsonify({"error": f"Failed to fetch GPUs for page {page_number}"}), 500


@bp.route("/api/gpu/filtered", methods=["GET"])
def get_filtered_gpus():
    try:
        # Get query parameters with defaults
        gpu_name = request.args.get("gpu_name")
        gpu_vendor = request.args.get("gpu_vendor")
        min_gpu_count = request.args.get("min_gpu_count", type=int)
        max_gpu_count = request.args.get("max_gpu_count", type=int)
        min_gpu_memory = request.args.get("min_gpu_memory", type=float)
        max_gpu_memory = request.args.get("max_gpu_memory", type=float)
        min_cpu = request.args.get("min_cpu", type=int)
        max_cpu = request.args.get("max_cpu", type=int)
        min_memory = request.args.get("min_memory", type=float)
        max_memory = request.args.get("max_memory", type=float)
        min_price = request.args.get("min_price", type=float)
        max_price = request.args.get("max_price", type=float)
        provider = request.args.get("provider")
        sort_by = request.args.get("sort_by", "current_price")
        sort_order = request.args.get("sort_order", "asc")
        page = request.args.get("page", 1, type=int)
        per_page = request.args.get("per_page", 20, type=int)

        # Start with base query
        query = GPUListing.query

        # Apply filters
        if gpu_name:
            query = query.filter(GPUListing.gpu_name.ilike(f"%{gpu_name}%"))
        if gpu_vendor:
            query = query.filter(GPUListing.gpu_vendor == gpu_vendor)
        if min_gpu_count is not None:
            query = query.filter(GPUListing.gpu_count >= min_gpu_count)
        if max_gpu_count is not None:
            query = query.filter(GPUListing.gpu_count <= max_gpu_count)
        if min_gpu_memory is not None:
            query = query.filter(GPUListing.gpu_memory >= min_gpu_memory)
        if max_gpu_memory is not None:
            query = query.filter(GPUListing.gpu_memory <= max_gpu_memory)
        if min_cpu is not None:
            query = query.filter(GPUListing.cpu >= min_cpu)
        if max_cpu is not None:
            query = query.filter(GPUListing.cpu <= max_cpu)
        if min_memory is not None:
            query = query.filter(GPUListing.memory >= min_memory)
        if max_memory is not None:
            query = query.filter(GPUListing.memory <= max_memory)
        if min_price is not None:
            query = query.filter(GPUListing.current_price >= min_price)
        if max_price is not None:
            query = query.filter(GPUListing.current_price <= max_price)
        if provider:
            query = query.join(Host).filter(Host.name == provider)

        # Apply sorting
        sort_column = getattr(GPUListing, sort_by, GPUListing.current_price)
        if sort_order == "desc":
            sort_column = sort_column.desc()
        query = query.order_by(sort_column)

        # Apply pagination
        paginated_listings = query.paginate(page=page, per_page=per_page, error_out=False)
        
        return jsonify({
            "gpus": [listing.to_dict() for listing in paginated_listings.items],
            "current_page": page,
            "total_pages": paginated_listings.pages,
            "total_items": paginated_listings.total,
            "items_per_page": per_page
        })

    except Exception as e:
        print(f"Error filtering GPUs: {str(e)}")
        return jsonify({"error": "Failed to filter GPUs"}), 500


@bp.route("/api/gpu/vendors", methods=["GET"])
def get_gpu_vendors():
    try:
        vendors = db.session.query(GPUListing.gpu_vendor).distinct().all()
        # Extract vendors from tuples and filter out None values
        vendor_list = [vendor[0] for vendor in vendors if vendor[0] is not None]
        return jsonify(vendor_list)
    except Exception as e:
        print(f"Error fetching GPU vendors: {str(e)}")
        return jsonify({"error": "Failed to fetch GPU vendors"}), 500


@bp.route("/api/gpu/<int:gpu_id>/price-history", methods=["GET"])
def get_gpu_price_history(gpu_id):
    try:
        # Get query parameters
        start_date = request.args.get("start_date")
        end_date = request.args.get("end_date")

        # Start with base query
        query = GPUPriceHistory.query.filter(GPUPriceHistory.gpu_listing_id == gpu_id)

        # Apply date filters if provided
        if start_date:
            start_datetime = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
            query = query.filter(GPUPriceHistory.date >= start_datetime)
        if end_date:
            end_datetime = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
            query = query.filter(GPUPriceHistory.date <= end_datetime)

        # Order by date
        query = query.order_by(GPUPriceHistory.date)

        # Execute query and convert to dict
        price_history = query.all()
        return jsonify([price.to_dict() for price in price_history])

    except ValueError as e:
        print(f"Invalid date format: {str(e)}")
        return jsonify({"error": "Invalid date format. Please use ISO format (YYYY-MM-DD)"}), 400
    except Exception as e:
        print(f"Error fetching price history for GPU {gpu_id}: {str(e)}")
        return jsonify({"error": f"Failed to fetch price history for GPU {gpu_id}"}), 500


@bp.route("/api/gpu/<int:gpu_id>/price-points", methods=["GET"])
def get_gpu_price_points(gpu_id):
    try:
        # Get all current price points for the GPU
        price_points = GPUPricePoint.query.filter(
            GPUPricePoint.gpu_listing_id == gpu_id
        ).order_by(
            GPUPricePoint.price
        ).all()

        return jsonify([price_point.to_dict() for price_point in price_points])

    except Exception as e:
        print(f"Error fetching price points for GPU {gpu_id}: {str(e)}")
        return jsonify({"error": f"Failed to fetch price points for GPU {gpu_id}"}), 500

================
File: routes/project.py
================
from flask import Blueprint, request, jsonify, g
from models.project import Project
from models.gpu_listing import GPUListing
from utils.database import db
from middleware.auth import require_auth
from models.user import User

bp = Blueprint("project", __name__)


@bp.route("/", methods=["GET"])
@require_auth()
def get_user_projects():
    """Get all projects for the current user"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        projects = Project.query.filter_by(user_id=user.id).all()
        return jsonify([project.to_dict() for project in projects]), 200
    except Exception as e:
        print(f"Error in get_user_projects: {str(e)}")
        return jsonify({"error": str(e)}), 500


@bp.route("/", methods=["POST"])
@require_auth()
def create_project():
    """Create a new project"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        data = request.json
        if not data.get("name"):
            return jsonify({"error": "Project name is required"}), 400

        project = Project(
            name=data["name"],
            description=data.get("description", ""),
            user_id=user.id,
        )

        db.session.add(project)
        db.session.commit()

        return jsonify(project.to_dict()), 201
    except Exception as e:
        print(f"Error in create_project: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/<int:project_id>", methods=["PUT"])
@require_auth()
def update_project(project_id):
    """Update a project"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        project = Project.query.filter_by(id=project_id, user_id=user.id).first()
        if not project:
            return jsonify({"error": "Project not found"}), 404

        data = request.json
        if "name" in data:
            project.name = data["name"]
        if "description" in data:
            project.description = data["description"]

        db.session.commit()
        return jsonify(project.to_dict()), 200
    except Exception as e:
        print(f"Error in update_project: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/<int:project_id>", methods=["DELETE"])
@require_auth()
def delete_project(project_id):
    """Delete a project"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        project = Project.query.filter_by(id=project_id, user_id=user.id).first()
        if not project:
            return jsonify({"error": "Project not found"}), 404

        db.session.delete(project)
        db.session.commit()

        return jsonify({"message": "Project deleted successfully"}), 200
    except Exception as e:
        print(f"Error in delete_project: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/<int:project_id>/gpus", methods=["POST"])
@require_auth()
def add_gpu_to_project(project_id):
    """Add a GPU to a project"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        project = Project.query.filter_by(id=project_id, user_id=user.id).first()
        if not project:
            return jsonify({"error": "Project not found"}), 404

        data = request.json
        if not data or not data.get("gpu_id"):
            return jsonify({"error": "GPU ID is required"}), 400

        gpu = GPUListing.query.get(data["gpu_id"])
        if not gpu:
            return jsonify({"error": "GPU not found"}), 404

        if gpu in project.gpus:
            return jsonify({"error": "GPU already in project"}), 400

        project.gpus.append(gpu)
        db.session.commit()

        return jsonify(project.to_dict()), 200
    except Exception as e:
        print(f"Error in add_gpu_to_project: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/<int:project_id>/gpus/<int:gpu_id>", methods=["DELETE"])
@require_auth()
def remove_gpu_from_project(project_id, gpu_id):
    """Remove a GPU from a project"""
    try:
        user = User.query.filter_by(firebase_uid=g.user_id).first()
        if not user:
            return jsonify({"error": "User not found. Please sync your account."}), 404

        project = Project.query.filter_by(id=project_id, user_id=user.id).first()
        if not project:
            return jsonify({"error": "Project not found"}), 404

        gpu = GPUListing.query.get(gpu_id)
        if not gpu:
            return jsonify({"error": "GPU not found"}), 404

        if gpu not in project.gpus:
            return jsonify({"error": "GPU not in project"}), 400

        project.gpus.remove(gpu)
        db.session.commit()

        return jsonify(project.to_dict()), 200
    except Exception as e:
        print(f"Error in remove_gpu_from_project: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500

================
File: routes/user_preferences.py
================
from flask import Blueprint, jsonify, request
from models.user_preferences import RentedGPU, PriceAlert, FavoriteGPU, SelectedGPU
from models.gpu_listing import GPUListing
from utils.database import db
from datetime import datetime
from middleware.auth import require_auth

bp = Blueprint("preferences", __name__)


# Selected GPUs endpoints
@bp.route("/selected-gpus", methods=["GET"])
def get_selected_gpus():
    try:
        selected_gpus = SelectedGPU.query.all()
        return jsonify([gpu.to_dict() for gpu in selected_gpus])
    except Exception as e:
        print(f"Error fetching selected GPUs: {str(e)}")
        return jsonify({"error": "Failed to fetch selected GPUs"}), 500


@bp.route("/selected-gpus", methods=["POST"])
def add_selected_gpu():
    try:
        data = request.json
        gpu_id = data.get("gpuId")

        # Check if GPU exists
        gpu = GPUListing.query.get_or_404(gpu_id)

        # Check if already selected
        existing = SelectedGPU.query.filter_by(gpu_id=gpu_id).first()
        if existing:
            return jsonify({"message": "GPU is already selected"}), 400

        selected = SelectedGPU(gpu_id=gpu_id)
        db.session.add(selected)
        db.session.commit()

        return jsonify(selected.to_dict())
    except Exception as e:
        print(f"Error adding selected GPU: {str(e)}")
        return jsonify({"error": "Failed to add selected GPU"}), 500


@bp.route("/selected-gpus/<int:gpu_id>", methods=["DELETE"])
def remove_selected_gpu(gpu_id):
    try:
        selected = SelectedGPU.query.filter_by(gpu_id=gpu_id).first_or_404()
        db.session.delete(selected)
        db.session.commit()
        return jsonify({"message": "GPU removed from selection"})
    except Exception as e:
        print(f"Error removing selected GPU: {str(e)}")
        return jsonify({"error": "Failed to remove selected GPU"}), 500


# Rented GPUs endpoints
@bp.route("/rented-gpus", methods=["GET"])
def get_rented_gpus():
    try:
        rented_gpus = RentedGPU.query.filter_by(is_active=True).all()
        return jsonify([rental.to_dict() for rental in rented_gpus])
    except Exception as e:
        print(f"Error fetching rented GPUs: {str(e)}")
        return jsonify({"error": "Failed to fetch rented GPUs"}), 500


@bp.route("/rented-gpus", methods=["POST"])
def add_rented_gpu():
    try:
        data = request.json
        gpu_id = data.get("gpuId")

        # Check if GPU exists
        gpu = GPUListing.query.get_or_404(gpu_id)

        # Check if already rented and active
        existing = RentedGPU.query.filter_by(gpu_id=gpu_id, is_active=True).first()
        if existing:
            return jsonify({"message": "GPU is already rented"}), 400

        rental = RentedGPU(gpu_id=gpu_id)
        db.session.add(rental)
        db.session.commit()

        return jsonify(rental.to_dict())
    except Exception as e:
        print(f"Error adding rented GPU: {str(e)}")
        return jsonify({"error": "Failed to add rented GPU"}), 500


@bp.route("/rented-gpus/<int:gpu_id>", methods=["DELETE"])
def remove_rented_gpu(gpu_id):
    try:
        rental = RentedGPU.query.filter_by(gpu_id=gpu_id, is_active=True).first_or_404()
        rental.is_active = False
        rental.rental_end = datetime.utcnow()
        db.session.commit()
        return jsonify(rental.to_dict())
    except Exception as e:
        print(f"Error removing rented GPU: {str(e)}")
        return jsonify({"error": "Failed to remove rented GPU"}), 500


# Price Alerts endpoints
@bp.route("/price-alerts", methods=["GET"])
def get_price_alerts():
    try:
        alerts = PriceAlert.query.all()
        alerts_dict = {}
        for alert in alerts:
            alerts_dict.update(alert.to_dict())
        return jsonify(alerts_dict)
    except Exception as e:
        print(f"Error fetching price alerts: {str(e)}")
        return jsonify({"error": "Failed to fetch price alerts"}), 500


@bp.route("/price-alerts", methods=["POST"])
def add_price_alert():
    try:
        data = request.json
        gpu_id = data.get("gpuId")
        gpu_type = data.get("gpuType")
        target_price = data.get("targetPrice")
        is_type_alert = data.get("isTypeAlert", False)

        # Check if alert already exists
        if is_type_alert:
            existing = PriceAlert.query.filter_by(
                gpu_type=gpu_type, is_type_alert=True
            ).first()
        else:
            existing = PriceAlert.query.filter_by(
                gpu_id=gpu_id, is_type_alert=False
            ).first()

        if existing:
            return jsonify({"message": "Price alert already exists"}), 400

        alert = PriceAlert(
            gpu_id=None if is_type_alert else gpu_id,
            gpu_type=gpu_type if is_type_alert else None,
            target_price=target_price,
            is_type_alert=is_type_alert,
        )
        db.session.add(alert)
        db.session.commit()

        return jsonify(alert.to_dict())
    except Exception as e:
        print(f"Error adding price alert: {str(e)}")
        return jsonify({"error": "Failed to add price alert"}), 500


@bp.route("/price-alerts/<alert_id>", methods=["DELETE"])
def remove_price_alert(alert_id):
    try:
        if alert_id.startswith("type_"):
            gpu_type = alert_id[5:]  # Remove 'type_' prefix
            alert = PriceAlert.query.filter_by(
                gpu_type=gpu_type, is_type_alert=True
            ).first_or_404()
        else:
            alert = PriceAlert.query.filter_by(
                gpu_id=int(alert_id), is_type_alert=False
            ).first_or_404()

        db.session.delete(alert)
        db.session.commit()
        return jsonify({"message": "Price alert removed successfully"})
    except Exception as e:
        print(f"Error removing price alert: {str(e)}")
        return jsonify({"error": "Failed to remove price alert"}), 500


# Favorite GPUs endpoints
@bp.route("/favorite-gpus", methods=["GET"])
def get_favorite_gpus():
    try:
        favorites = FavoriteGPU.query.all()
        return jsonify([favorite.to_dict() for favorite in favorites])
    except Exception as e:
        print(f"Error fetching favorite GPUs: {str(e)}")
        return jsonify({"error": "Failed to fetch favorite GPUs"}), 500


@bp.route("/favorite-gpus", methods=["POST"])
def add_favorite_gpu():
    try:
        data = request.json
        gpu_id = data.get("gpuId")

        # Check if GPU exists
        gpu = GPUListing.query.get_or_404(gpu_id)

        # Check if already favorited
        existing = FavoriteGPU.query.filter_by(gpu_id=gpu_id).first()
        if existing:
            return jsonify({"message": "GPU is already favorited"}), 400

        favorite = FavoriteGPU(gpu_id=gpu_id)
        db.session.add(favorite)
        db.session.commit()

        return jsonify(favorite.to_dict())
    except Exception as e:
        print(f"Error adding favorite GPU: {str(e)}")
        return jsonify({"error": "Failed to add favorite GPU"}), 500


@bp.route("/favorite-gpus/<int:gpu_id>", methods=["DELETE"])
def remove_favorite_gpu(gpu_id):
    try:
        favorite = FavoriteGPU.query.filter_by(gpu_id=gpu_id).first_or_404()
        db.session.delete(favorite)
        db.session.commit()
        return jsonify({"message": "Favorite GPU removed successfully"})
    except Exception as e:
        print(f"Error removing favorite GPU: {str(e)}")
        return jsonify({"error": "Failed to remove favorite GPU"}), 500

================
File: routes/user.py
================
from flask import Blueprint, request, jsonify, g
from models.user import User
from utils.database import db
from middleware.auth import require_auth
from datetime import datetime
import firebase_admin
from firebase_admin import auth as firebase_auth

bp = Blueprint("user_bp", __name__)


@bp.route("/sync", methods=["POST"])
@require_auth()
def sync_user():
    """Sync Firebase user with backend database"""
    try:
        # Get user data from request

        # Check if user already exists
        user = User.query.filter_by(firebase_uid=g.user_id).first()

        # Get user data from Firebase
        firebase_user = firebase_auth.get_user(g.user_id)
        if user:
            # Update existing user
            user.last_login = datetime.utcnow()
            print("updated user", user)
        else:
            # Create new user
            user = User(
                firebase_uid=g.user_id,  # Use the verified UID from the token
                email=firebase_user.get("email"),
                display_name=firebase_user.get("name"),
                email_verified=firebase_user.get("email_verified", False),
                disabled=firebase_user.get("disabled", False),
                created_at=datetime.utcnow(),
                last_login=datetime.utcnow(),
            )
            print("created user", user)
            db.session.add(user)

        db.session.commit()
        return jsonify(user.to_dict()), 200
    except Exception as e:
        print(f"Error in sync_user: {str(e)}")
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/profile", methods=["GET"])
@require_auth()
def get_user_profile():
    """Get user profile including preferences"""
    try:
        user_id = g.user_id  # Get user ID from auth context
        user = User.query.filter_by(firebase_uid=user_id).first()
        print("user", user)
        if not user:
            return jsonify({"error": "User not found"}), 404

        profile = user.to_dict()
        # Add preference data
        print(profile)
        # profile.update(
        #     {
        #         "rented_gpus": [gpu.to_dict() for gpu in user.rented_gpus],
        #         "price_alerts": [alert.to_dict() for alert in user.price_alerts],
        #         "selected_gpus": [gpu.to_dict() for gpu in user.selected_gpus],
        #         "favorite_gpus": [gpu.to_dict() for gpu in user.favorite_gpus],
        #     }
        # )

        return jsonify(profile), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@bp.route("/profile", methods=["PUT"])
@require_auth()
def update_user_profile():
    """Update user profile information"""
    try:
        data = request.json
        user_id = g.user_id  # Get user ID from auth context
        user = User.query.filter_by(firebase_uid=user_id).first()

        if not user:
            return jsonify({"error": "User not found"}), 404

        # Update fields if provided
        if "first_name" in data:
            user.first_name = data["first_name"]
        if "last_name" in data:
            user.last_name = data["last_name"]
        if "organization" in data:
            user.organization = data["organization"]
        if "experience_level" in data:
            user.experience_level = data["experience_level"]

        db.session.commit()
        return jsonify(user.to_dict()), 200
    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/", methods=["DELETE"])
@require_auth()
def delete_user():
    """Delete user and all associated preferences"""
    try:
        firebase_user = request.user
        user = User.query.filter_by(firebase_uid=firebase_user["uid"]).first()

        if not user:
            return jsonify({"error": "User not found"}), 404

        db.session.delete(user)
        db.session.commit()
        return jsonify({"message": "User deleted successfully"}), 200
    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/register", methods=["POST"])
def register_user():
    """Register a new user and return a custom token"""
    try:
        data = request.get_json()
        email = data.get("email")
        password = data.get("password")
        first_name = data.get("first_name")
        last_name = data.get("last_name")
        organization = data.get("organization")
        experience_level = data.get("experience_level", "beginner")
        referral_source = data.get("referral_source")

        # Create the user in Firebase
        firebase_user = firebase_auth.create_user(
            email=email, password=password, display_name=f"{first_name} {last_name}"
        )

        # Create custom token
        custom_token = firebase_auth.create_custom_token(firebase_user.uid)

        # Create user in our database
        user = User(
            firebase_uid=firebase_user.uid,
            email=email,
            first_name=first_name,
            last_name=last_name,
            organization=organization,
            experience_level=experience_level,
            email_verified=False,
            disabled=False,
            created_at=datetime.utcnow(),
            last_login=datetime.utcnow(),
            referral_source=referral_source,
        )
        db.session.add(user)
        db.session.commit()

        return (
            jsonify({"token": custom_token.decode("utf-8"), "user": user.to_dict()}),
            201,
        )

    except Exception as e:
        db.session.rollback()
        return jsonify({"error": str(e)}), 500


@bp.route("/update", methods=["POST"])
@require_auth()
def update_user_data():
    """Update authenticated user's data"""
    try:
        data = request.get_json()
        user_id = g.user_id  # Get user ID from auth context

        print(f"Updating user data for user_id: {user_id}")  # Debug log
        print(f"Request data: {data}")  # Debug log

        # Get required fields
        first_name = data.get("first_name")
        last_name = data.get("last_name")
        organization = data.get("organization")
        experience_level = data.get("experience_level")
        referral_source = data.get("referral_source")

        # Update user data in database

        if not all([first_name, last_name, organization, experience_level]):
            missing = [
                f
                for f, v in [
                    ("first_name", first_name),
                    ("last_name", last_name),
                    ("organization", organization),
                    ("experience_level", experience_level),
                ]
                if not v
            ]
            return (
                jsonify({"error": f"Missing required fields: {', '.join(missing)}"}),
                400,
            )

        try:
            # Try to get Firebase user first to validate the ID
            firebase_user = firebase_auth.get_user(user_id)
            print(f"Firebase user found: {firebase_user.uid}")  # Debug log
        except Exception as e:
            print(f"Error getting Firebase user: {str(e)}")  # Debug log
            return jsonify({"error": "Invalid user ID"}), 400

        # Update user in database
        user = User.query.filter_by(firebase_uid=user_id).first()
        if not user:
            print(f"Creating new user for Firebase ID: {user_id}")  # Debug log
            # Create user if they don't exist (for social auth)
            user = User(
                firebase_uid=user_id,
                email=firebase_user.email,
                first_name=first_name,
                last_name=last_name,
                organization=organization,
                experience_level=experience_level,
                referral_source=referral_source,
                email_verified=firebase_user.email_verified,
                disabled=firebase_user.disabled,
                created_at=firebase_user.metadata.get("createdAt"),
                last_login=datetime.utcnow(),
            )
            db.session.add(user)
        else:
            print(f"Updating existing user: {user.id}")  # Debug log
            # Update existing user
            user.first_name = first_name
            user.last_name = last_name
            user.organization = organization
            user.experience_level = experience_level
            user.referral_source = referral_source

        # Update Firebase display name
        try:
            firebase_auth.update_user(user_id, display_name=f"{first_name} {last_name}")
            print(f"Updated Firebase display name for user: {user_id}")  # Debug log
        except Exception as e:
            # Log the error but don't fail the request
            print(f"Failed to update Firebase display name: {str(e)}")

        db.session.commit()
        print(f"Successfully updated user data in database")  # Debug log

        return jsonify({"message": "User data updated successfully"}), 200

    except Exception as e:
        db.session.rollback()
        print(f"Error updating user data: {str(e)}")
        return jsonify({"error": str(e)}), 500

================
File: scripts/web-scrapping/normalize_data.py
================
import json
import os
from datetime import datetime
from typing import Dict, Any
import re

def extract_vram_from_name(name: str) -> int:
    """Extract VRAM from GPU name if possible."""
    vram_pattern = r'(\d+)GB'
    match = re.search(vram_pattern, name, re.IGNORECASE)
    return int(match.group(1)) if match else None

def round_price(price: float) -> float:
    """Round price to 2 decimal places."""
    return round(price, 2) if price is not None else None

def round_flops(flops: float) -> float:
    """Round FLOPS to 2 decimal places."""
    return round(flops, 2) if flops is not None else None

def round_reliability(reliability: float) -> float:
    """Round reliability to 1 decimal place."""
    return round(reliability, 1) if reliability is not None else None

def normalize_latitude_data(data: Dict[str, Any]) -> list:
    normalized = []
    for plan_type in ['container_plans', 'regular_plans']:
        for plan in data.get(plan_type, []):
            specs = plan['specs']
            normalized.append({
                "id": f"latitude_{plan['slug']}",
                "name": plan['name'],
                "provider": "Latitude",
                "pricing": {
                    "amount": round_price(float(specs.get('price', 0))),
                    "currency": "USD",
                    "unit": "hour",
                    "price_change": None
                },
                "specifications": {
                    "vram": extract_vram_from_name(plan['name']),
                    "number_of_gpus": specs.get('gpu_count', 1),
                    "flops": None,
                    "reliability": None
                },
                "region": ", ".join(plan['regions']),
                "available": True,
                "timestamp": datetime.now().isoformat()
            })
    return normalized

def normalize_tensordock_data(data: Dict[str, Any]) -> list:
    normalized = []
    for gpu_type in ['rtx', 'non_rtx']:
        # Check if the item is a dictionary, if not, skip it
        gpu_list = data.get(gpu_type, [])
        if not isinstance(gpu_list, list):
            continue
            
        for item in gpu_list:
            if not isinstance(item, dict):
                continue
                
            normalized.append({
                "id": f"tensordock_{item.get('id', '')}",
                "name": item.get('gpu_name', ''),
                "provider": "TensorDock",
                "pricing": {
                    "amount": round_price(float(item.get('price', 0))),
                    "currency": "USD",
                    "unit": "hour",
                    "price_change": None
                },
                "specifications": {
                    "vram": extract_vram_from_name(item.get('gpu_name', '')),
                    "number_of_gpus": item.get('gpu_count', 1),
                    "flops": None,
                    "reliability": None
                },
                "region": item.get('region', 'Unknown'),
                "available": True,
                "timestamp": datetime.now().isoformat()
            })
    return normalized

def normalize_vastai_data(data: Dict[str, Any]) -> list:
    normalized = []
    
    # GPU name mapping for standardization
    gpu_name_mapping = {
        "RTX 6000Ada": "RTX 6000Ada",
        "RTX A6000": "RTX A6000",
        "A6000": "RTX A6000",
        "RTX 3090": "RTX 3090",
        "RTX 3080": "RTX 3080",
        "RTX 3070": "RTX 3070",
        "RTX 4090": "RTX 4090",
        "RTX 4080": "RTX 4080",
        "A100": "A100",
        "H100": "H100",
        "A40": "A40",
        "L40": "L40",
        "V100": "V100",
        "T4": "T4"
    }
    
    def standardize_gpu_name(name: str) -> str:
        if not name:
            return "Unknown GPU"
        
        # Remove extra spaces and standardize spacing
        name = name.strip()
        name = re.sub(r'\s+', ' ', name)
        
        # Remove manufacturer prefix if present
        for manufacturer in ["NVIDIA", "AMD", "Intel"]:
            name = name.replace(f"{manufacturer} ", "")
        
        # First try exact match
        standardized = gpu_name_mapping.get(name)
        if standardized:
            return standardized
        
        # Try without spaces
        no_spaces = name.replace(' ', '')
        for key, value in gpu_name_mapping.items():
            if no_spaces.lower() == key.replace(' ', '').lower():
                return value
        
        # Try partial matches
        for key, value in gpu_name_mapping.items():
            if key.lower() in name.lower() or name.lower() in key.lower():
                if len(key) > 3:  # Avoid matching very short strings
                    return value
        
        return name
    
    for _, gpu in data.items():
        # Convert VRAM from MB to GB and round to nearest integer
        vram_mb = gpu.get('gpu_ram', None)
        vram_gb = round(vram_mb / 1024) if vram_mb is not None else None
        
        # Standardize GPU name
        gpu_name = standardize_gpu_name(gpu.get('gpu_name', ''))
        
        normalized.append({
            "id": f"vastai_{gpu.get('id', '')}",
            "name": gpu_name,
            "provider": "Vast.ai",
            "pricing": {
                "amount": round(float(gpu.get('dph_total', 0)), 2),
                "currency": "USD",
                "unit": "hour",
                "price_change": None
            },
            "specifications": {
                "vram": vram_gb,
                "number_of_gpus": gpu.get('num_gpus', 1),
                "flops": gpu.get('total_flops', None),
                "reliability": gpu.get('reliability2', None) * 100 if gpu.get('reliability2') else None
            },
            "region": gpu.get('location', 'Unknown'),
            "available": gpu.get('rentable', False),
            "timestamp": datetime.now().isoformat()
        })
    return normalized

def normalize_scaleway_data(data, timestamp):
    normalized = []
    for item in data:
        gpu_name = item["name"].replace("NVIDIA ", "")
        # Remove any "Nx" prefix and "GPU" suffix
        gpu_name = re.sub(r'^\d+x\s*', '', gpu_name)
        gpu_name = re.sub(r'\s*GPU$', '', gpu_name)
        # Remove "Tensor Core" suffix
        gpu_name = re.sub(r'\s*Tensor Core$', '', gpu_name)
        
        # Extract VRAM size
        vram = int(item["gpu_memory"].replace("GB", ""))
        
        # Extract FLOPS
        flops = float(item["peak_fp16_perf"].replace(",", "").replace(" TFLOPS", ""))
        
        # Extract price
        price = float(item["hourly_price"].replace("€", "").replace("/HOUR", ""))
        
        # Try to extract number of GPUs from name, default to 1 if not found
        num_gpus_match = re.match(r'(\d+)x', item["name"])
        num_gpus = int(num_gpus_match.group(1)) if num_gpus_match else 1
        
        normalized.append({
            "id": f"scaleway_{gpu_name.lower().replace(' ', '_')}",
            "name": gpu_name,
            "provider": "Scaleway",
            "pricing": {
                "amount": price,
                "currency": "EUR",
                "unit": "hour",
                "price_change": None
            },
            "specifications": {
                "vram": vram,
                "number_of_gpus": num_gpus,
                "flops": flops,
                "reliability": None
            },
            "region": "Europe",
            "available": True,
            "timestamp": timestamp
        })
    return normalized

def normalize_leadergpu_data(data, timestamp):
    normalized = []
    
    # Enhanced GPU name mapping to standardize names
    gpu_name_mapping = {
        "H100": "H100",
        "3090": "RTX 3090",
        "3080": "RTX 3080",
        "3070": "RTX 3070",
        "A6000": "RTX A6000",
        "A6000 Ada": "RTX 6000Ada",
        "L40S": "L40S",
        "L40": "L40",
        "L20": "L20",
        "4090": "RTX 4090",
        "4080": "RTX 4080",
        "A100": "A100",
        "A10": "A10",
        "1080Ti": "GTX 1080 Ti",
        "1080": "GTX 1080",
        "RTX 6000 Ada": "RTX 6000 Ada",
        "RTX 6000": "RTX 6000",
        "V100": "V100",
        "T4": "T4"
    }
    
    # Memory type mapping
    memory_type_mapping = {
        "GDDR6X": "GDDR6X",
        "GDDR6": "GDDR6",
        "HBM2": "HBM2",
        "HBM2e": "HBM2e",
        "HBM3": "HBM3",
        "GDDR5x": "GDDR5x"
    }
    
    def extract_gpu_info(title):
        # Enhanced pattern matching for various formats
        # Matches: "8xA6000", "8 x A6000", "1 x RTX 6000 Ada", "4×A100"
        gpu_pattern = r'^(\d+)\s*[x×]\s*([^,]+)'
        match = re.match(gpu_pattern, title, re.IGNORECASE)
        
        if match:
            num_gpus = int(match.group(1))
            gpu_model = match.group(2).strip()
        else:
            # If no multiplier found, assume 1 GPU and try to extract model
            num_gpus = 1
            gpu_model = title.split(',')[0].strip()
        
        return num_gpus, gpu_model
    
    def calculate_hourly_rate(monthly_price):
        try:
            return round(float(monthly_price) / 730.484, 2)
        except (ValueError, TypeError):
            print(f"Error calculating hourly rate for price: {monthly_price}")
            return None
    
    def extract_vram_info(vram_info):
        if not vram_info:
            return None, None
            
        vram = None
        memory_type = None
        
        # Match total VRAM and memory type
        # Patterns: "160GB (2x80GB)", "48GB GDDR6X", "384GB (8x48GB) HBM2"
        vram_pattern = r'(\d+)\s*GB'
        mem_type_pattern = r'(GDDR6X|GDDR6|HBM2e|HBM2|HBM3)'
        
        vram_match = re.search(vram_pattern, vram_info)
        mem_type_match = re.search(mem_type_pattern, vram_info, re.IGNORECASE)
        
        if vram_match:
            vram = int(vram_match.group(1))
        
        if mem_type_match:
            memory_type = memory_type_mapping.get(mem_type_match.group(1).upper())
        
        return vram, memory_type
    
    def standardize_region(region_info):
        region_mapping = {
            "eu": "Europe",
            "europe": "Europe",
            "us": "United States",
            "usa": "United States",
            "asia": "Asia"
        }
        if not region_info:
            return "Europe"  # Default region for LeaderGPU
            
        region_key = region_info.lower().strip()
        return region_mapping.get(region_key, region_info)
    
    for item in data:
        try:
            num_gpus, gpu_model = extract_gpu_info(item["title"])
            
            # Get standardized GPU name
            standardized_name = None
            for key, value in gpu_name_mapping.items():
                if key.lower() in gpu_model.lower():
                    standardized_name = value
                    break
            
            if not standardized_name:
                standardized_name = gpu_model
            
            vram, memory_type = extract_vram_info(item["specifications"].get("gpu_ram"))
            region = standardize_region(item.get("region"))
            
            normalized.append({
                "id": f"leadergpu_{item['server_id']}",
                "name": standardized_name,
                "provider": "LeaderGPU",
                "pricing": {
                    "amount": calculate_hourly_rate(item["monthly_price_eur"]),
                    "currency": "EUR",
                    "unit": "hour",
                    "price_change": None
                },
                "specifications": {
                    "vram": vram,
                    "memory_type": memory_type,
                    "number_of_gpus": num_gpus,
                    "flops": None,
                    "reliability": None
                },
                "region": region,
                "available": True,
                "timestamp": timestamp
            })
            
        except Exception as e:
            print(f"Error processing server {item.get('server_id', 'unknown')}: {str(e)}")
            continue
    
    return normalized

def process_directory():
    script_dir = os.path.dirname(os.path.abspath(__file__))
    today = datetime.now().strftime('%Y%m%d')
    
    # Create normalized directory if it doesn't exist
    normalized_dir = os.path.join(script_dir, 'normalized')
    os.makedirs(normalized_dir, exist_ok=True)
    
    normalizers = {
        'latitude': normalize_latitude_data,
        'tensordock': normalize_tensordock_data,
        'vastai': normalize_vastai_data,
        'scaleway': lambda data: normalize_scaleway_data(data, datetime.now().isoformat()),
        'leadergpu': lambda data: normalize_leadergpu_data(data, datetime.now().isoformat()),
    }
    
    all_normalized_data = []
    
    # Process each JSON file
    for filename in os.listdir(script_dir):
        if filename.endswith('.json'):
            for provider in normalizers.keys():
                if provider in filename.lower():
                    with open(os.path.join(script_dir, filename), 'r') as f:
                        data = json.load(f)
                        normalized = normalizers[provider](data)
                        all_normalized_data.extend(normalized)
    
    # Save combined normalized data
    output_file = os.path.join(normalized_dir, f'normalized_gpu_data_{today}.json')
    with open(output_file, 'w') as f:
        json.dump(all_normalized_data, f, indent=2)
    
    print(f"Normalized data saved to: {output_file}")

if __name__ == "__main__":
    process_directory()

================
File: scripts/web-scrapping/scrape_latitude.py
================
import requests
import json
from datetime import datetime

def scrape_latitude_pricing():
    # Fetch JSON data from the API endpoint
    url = 'https://www.latitude.sh/_next/data/website-dcdab91bc4bee7f501bc6df274ac26addd7e0d02/en/network/pricing.json'
    response = requests.get(url)
    data = response.json()
    
    # Extract both container plans and regular plans data
    container_plans = data['pageProps']['containersPlansData']
    regular_plans = data['pageProps']['plansData']
    
    # Process and structure the data
    pricing_data = {
        'container_plans': [],
        'regular_plans': []
    }
    
    # Process container plans
    for plan in container_plans:
        plan_info = {
            'name': plan['attributes']['name'],
            'slug': plan['attributes']['slug'],
            'specs': plan['attributes']['specs'],
            'regions': plan['attributes']['regions']
        }
        pricing_data['container_plans'].append(plan_info)
    
    # Process regular plans
    for plan in regular_plans:
        plan_info = {
            'name': plan['attributes']['name'],
            'slug': plan['attributes']['slug'],
            'specs': plan['attributes']['specs'],
            'regions': plan['attributes']['regions']
        }
        pricing_data['regular_plans'].append(plan_info)
    
    return pricing_data

def save_to_json(pricing_data):
    # Format the date as YYYYMMDD
    today = datetime.now().strftime('%Y%m%d')
    
    # Save to JSON file
    with open(f'latitude{today}.json', 'w') as f:
        json.dump(pricing_data, f, indent=4)

if __name__ == "__main__":
    pricing_data = scrape_latitude_pricing()
    save_to_json(pricing_data)

================
File: scripts/web-scrapping/scrape_leadergpu.py
================
import requests
from bs4 import BeautifulSoup
import json
from datetime import datetime

def scrape_leadergpu():
    url = "https://www.leadergpu.com/filter_servers?filterExpression=os%3Awindows_server%3Bavailable_server%3Bavailable_server_next3d%3Bmonth%3A1"
    # Get JSON response and extract HTML from it
    response = requests.get(url).json()
    html_content = response['matchesHtml']
    soup = BeautifulSoup(html_content, 'html.parser')
    
    gpu_sections = soup.find_all('section', class_='b-product-gpu')
    servers = []
    
    for section in gpu_sections:
        # Basic info from title
        title_div = section.find('div', class_='b-product-gpu-title')
        if not title_div:
            continue
        print(title_div)
            
        # Extract server ID and title
        link = title_div.find('a')
        title = link.text.strip() if link else None
        server_id = link['href'].split('/')[-1] if link else None
        
        # Extract pricing from data-sort
        sort_data = title_div.get('data-sort', '').split(';')
        monthly_price = float(sort_data[1]) if len(sort_data) > 1 else None
        
        # Extract GPU configuration
        config_div = section.find('div', class_='config-list')
        gpu_info = config_div.find('div', string=lambda text: text and 'GPU:' in text) if config_div else None
        gpu_specs = gpu_info.find_next('p').text.strip() if gpu_info else None
        
        # Extract RAM, CPU, and GPU RAM
        gpu_ram = None
        cpu = None
        ram = None
        nvme = None
        network = None
        
        if config_div:
            for div in config_div.find_all('div', class_='mb-10'):
                text = div.text.strip()
                if 'GPU RAM:' in text:
                    gpu_ram = div.find('span', class_=None).text.strip()
                elif 'CPU:' in text:
                    cpu = div.find('span', class_=None).text.strip()
                elif 'RAM:' in text:
                    ram = div.find('span', class_=None).text.strip()
                elif 'NVME:' in text:
                    nvme = div.find('span', class_=None).text.strip()
                elif 'Internal network:' in text:
                    network = div.find('span', class_=None).text.strip()
        
        # Extract prices
        prices_div = section.find('div', class_='b-product-gpu-prices')
        price_items = {}
        if prices_div:
            for li in prices_div.find_all('li', class_='d-flex'):
                price_text = li.find('p').text.strip()
                if 'month' in price_text:
                    price_items['monthly'] = price_text
                elif 'week' in price_text:
                    price_items['weekly'] = price_text
                elif 'day' in price_text:
                    price_items['daily'] = price_text
                elif 'minute' in price_text:
                    price_items['per_minute'] = price_text
        
        server_info = {
            'server_id': server_id,
            'title': title,
            'monthly_price_eur': monthly_price,
            'detailed_prices': price_items,
            'specifications': {
                'gpu_info': gpu_specs,
                'gpu_ram': gpu_ram,
                'cpu': cpu,
                'ram': ram,
                'nvme': nvme,
                'network': network
            },
            'configuration_url': f"https://www.leadergpu.com/server_configurations/{server_id}"
        }
        
        servers.append(server_info)
    
    return servers

if __name__ == "__main__":
    try:
        servers = scrape_leadergpu()
        
        # Generate filename with today's date
        today = datetime.now().strftime('%Y%m%d')
        filename = f'leadergpu_{today}.json'
        
        # Save to JSON file
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(servers, f, indent=2, ensure_ascii=False)
            
        print(f"Data saved to {filename}")
        print(f"Found {len(servers)} server configurations")
    except Exception as e:
        print(f"Error occurred: {e}")

================
File: scripts/web-scrapping/scrape_scaleway.py
================
from playwright.sync_api import sync_playwright
import json
from datetime import datetime

def scrape_scaleway_gpus():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        
        # Go to Scaleway's GPU instances page
        page.goto('https://www.scaleway.com/en/gpu-instances/')
        
        # Wait for the pricing table to load
        page.wait_for_selector('.Table_table__6cXug')
        
        # Get the pricing table content
        pricing_table = page.query_selector('.Table_table__6cXug')
        
        # Get all rows from the table
        rows = pricing_table.query_selector_all('tr')
        
        gpus_data = []
        # Skip header row by starting from index 1
        for row in rows[1:]:
            columns = row.query_selector_all('td')
            if len(columns) >= 2:  # Ensure we have at least name and price columns
                name = columns[0].inner_text().strip()
                gpu_memory = columns[1].inner_text().strip()
                peak_fp16_perf = columns[2].inner_text().strip()
                price = columns[-1].inner_text().strip()  # Usually last column is price
                
                gpus_data.append({
                    "name": name,
                    "gpu_memory": gpu_memory,
                    "peak_fp16_perf": peak_fp16_perf,
                    "hourly_price": price
                })
        
        browser.close()
        return gpus_data

if __name__ == "__main__":
    try:
        gpu_data = scrape_scaleway_gpus()
        
        # Format today's date as YYYYMMDD
        today = datetime.now().strftime("%Y%m%d")
        
        # Save to file
        with open(f'scaleway{today}.json', 'w') as f:
            json.dump(gpu_data, indent=2, fp=f)
            
        print(f"Data saved to scaleway{today}.json")
    except Exception as e:
        print(f"Error occurred: {e}")

================
File: scripts/web-scrapping/scrape_vast.py
================
import requests
import json
from datetime import datetime

def scrape_vastai():
    # API URL
    url = "https://cloud.vast.ai/api/v0/bundles/"
    
    # Query parameters
    params = {
        "q": {
            "disk_space": {"gte": 13.454342644059432},
            "reliability2": {"gte": 0.9927008691532114},
            "duration": {"gte": 6294.080870000899},
            "verified": {"eq": True},
            "rentable": {"eq": True},
            "dph_total": {"lte": 128},
            "inet_up_cost": {"lte": 0.09753068502171296},
            "inet_down_cost": {"lte": 0.09753068502171296},
            "gpu_mem_bw": {"gte": 9.999999999999996, "lte": 8034.141162462954},
            "sort_option": {
                "0": ["dph_total", "asc"],
                "1": ["total_flops", "asc"]
            },
            "order": [["dph_total", "asc"], ["total_flops", "asc"]],
            "num_gpus": {"gte": 0, "lte": 18},
            "allocated_storage": 13.454342644059432,
            "cuda_max_good": {"gte": "12.1"},
            "compute_cap": {"gte": 500},
            "has_avx": {"eq": True},
            "limit": 1000,
            "extra_ids": [],
            "type": "ask",
            "direct_port_count": {"gte": 2}
        }
    }

    try:
        # Make the request
        response = requests.get(url, params={"q": json.dumps(params["q"])})
        response.raise_for_status()
        
        # Parse the response and extract just the offers
        data = response.json()
        gpu_data = {str(i): gpu for i, gpu in enumerate(data.get("offers", []))}
        
        # Generate filename with today's date
        today = datetime.now().strftime("%Y%m%d")
        filename = f"VastAI{today}.json"
        
        # Save to file
        with open(filename, 'w') as f:
            json.dump(gpu_data, f, indent=2)
            
        print(f"Data successfully saved to {filename}")
        
    except requests.exceptions.RequestException as e:
        print(f"Error making request: {e}")
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON response: {e}")
    except IOError as e:
        print(f"Error writing to file: {e}")

if __name__ == "__main__":
    scrape_vastai()

================
File: scripts/web-scrapping/scrape-tensordock.py
================
import requests
import json
from datetime import datetime

# Base API URL
base_url = "https://dashboard.tensordock.com/api/session/deploy/hostnodes"

# Common parameters with relaxed constraints
params = {
    "minGPUCount": 1,
    "minRAM": 4,
    "minvCPUs": 2,
    "minStorage": 20,
    "minVRAM": 10
}

# Fetch data for both RTX and non-RTX GPUs
all_data = {}

# Non-RTX GPUs
params["requiresRTX"] = False
non_rtx_response = requests.get(base_url, params=params)
if non_rtx_response.status_code == 200:
    all_data["non_rtx"] = non_rtx_response.json()

# RTX GPUs
params["requiresRTX"] = True
rtx_response = requests.get(base_url, params=params)
if rtx_response.status_code == 200:
    all_data["rtx"] = rtx_response.json()

# Generate filename with today's date
today = datetime.now().strftime("%Y-%m-%d")
filename = f"tensordock{today}.json"

# Save the combined data to a JSON file
with open(filename, "w") as f:
    json.dump(all_data, f, indent=2)

print(f"Data saved to {filename}")

================
File: scripts/check_db.py
================
import sys
import os

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from models.gpu_listing import Host, GPUListing
from utils.database import db

def check_db():
    app = create_app()
    with app.app_context():
        # Check hosts
        hosts = Host.query.all()
        print(f"\nFound {len(hosts)} hosts:")
        for host in hosts:
            print(f"- {host.name}")
            
        # Check GPU listings
        gpus = GPUListing.query.all()
        print(f"\nFound {len(gpus)} GPU listings:")
        for i, gpu in enumerate(gpus[:5], 1):
            print(f"\n{i}. GPU Details:")
            print(f"   - Name: {gpu.name}")
            print(f"   - Price: ${gpu.current_price}/{gpu.price_metric}")
            print(f"   - VRAM: {gpu.vram}GB")
            print(f"   - Provider: {gpu.host.name}")
            print(f"   - Reliability: {gpu.reliability}")
            print(f"   - FLOPS: {gpu.flops}")
            
        if len(gpus) > 5:
            print(f"\n... and {len(gpus) - 5} more GPUs")

if __name__ == "__main__":
    check_db()

================
File: scripts/populate_db.py
================
import sys
import os
import json

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app import create_app
from models.gpu_listing import Host, GPUListing
from utils.database import db
from datetime import datetime


def load_json_data(file_path):
    with open(file_path, "r") as f:
        return json.load(f)


def populate_db():
    app = create_app()
    
    # Override the database URI for local population
    app.config['SQLALCHEMY_DATABASE_URI'] = os.getenv('DATABASE_URI')
    
    with app.app_context():
        print("Starting database population...")

        # Clear existing data
        print("Clearing existing data...")
        db.session.query(GPUListing).delete()
        db.session.query(Host).delete()
        db.session.commit()
        print("Data cleared successfully")

        # Add hosts (unique providers from the JSON)
        print("Loading JSON data...")
        json_data = load_json_data(
            f"scripts/web-scrapping/normalized/normalized_gpu_data_20241120.json"
        )
        print(f"Loaded {len(json_data)} GPU entries from JSON")

        unique_providers = set(item["provider"] for item in json_data)
        print(f"Found {len(unique_providers)} unique providers")

        hosts = []
        for provider in unique_providers:
            host_data = {"name": provider, "description": f"{provider} GPU Provider"}
            host = Host(**host_data)
            db.session.add(host)
            hosts.append(host)
        db.session.commit()
        print(f"Added {len(hosts)} hosts to database")

        # Create a mapping of provider names to host IDs
        host_mapping = {host.name: host.id for host in hosts}
        print("Created host mapping")

        # Add GPU listings
        gpu_listings = []
        for item in json_data:
            try:
                gpu_data = {
                    "name": item["name"],
                    "current_price": round(float(item["pricing"]["amount"]), 2),
                    "price_metric": f"/{item['pricing']['unit']}",
                    "price_change": round(
                        float(item["pricing"]["price_change"] or 0.0), 2
                    ),
                    "reliability": round(
                        float(item["specifications"]["reliability"] or 0.0), 2
                    ),
                    "flops": round(float(item["specifications"]["flops"] or 0.0), 2),
                    "vram": round(float(item["specifications"]["vram"] or 0.0), 2),
                    "description": f"{item['name']} from {item['provider']}",
                    "image_url": "",
                    "host_id": host_mapping[item["provider"]],
                    "number_of_gpus": round(
                        float(item["specifications"]["number_of_gpus"] or 0.0), 2
                    ),
                }
                gpu = GPUListing(**gpu_data)
                db.session.add(gpu)
                gpu_listings.append(gpu)
            except Exception as e:
                print(f"Error adding GPU {item['name']}: {str(e)}")
                continue
        db.session.commit()
        print(f"Database populated successfully with {len(gpu_listings)} GPU listings!")


if __name__ == "__main__":
    populate_db()

================
File: scripts/reset_db.py
================
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from utils.database import db
from models.gpu_listing import GPUListing, Host
from flask import Flask

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///gpu_listings.db'
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False

db.init_app(app)

with app.app_context():
    # Drop all tables
    db.drop_all()
    # Create all tables with new schema
    db.create_all()
    print("Database schema has been reset successfully.")

================
File: scripts/setup_postgres.py
================
#!/usr/bin/env python3
import subprocess
import sys
import os
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_command(command, shell=False):
    """Run a command and return its output"""
    try:
        result = subprocess.run(
            command,
            shell=shell,
            check=True,
            capture_output=True,
            text=True
        )
        return result.stdout
    except subprocess.CalledProcessError as e:
        logger.error(f"Command failed: {e.cmd}")
        logger.error(f"Error output: {e.stderr}")
        return None

def setup_postgres():
    """Set up PostgreSQL for the Neotix project"""
    try:
        # Check if PostgreSQL is running
        logger.info("Checking PostgreSQL status...")
        status = run_command(["brew", "services", "list"])
        if "postgresql@15" not in status or "started" not in status:
            logger.info("Starting PostgreSQL...")
            run_command(["brew", "services", "start", "postgresql@15"])

        # Create postgres superuser if it doesn't exist
        logger.info("Creating postgres superuser...")
        run_command(["createuser", "-s", "postgres"])
        
        # Set password for postgres user
        logger.info("Setting password for postgres user...")
        run_command([
            "psql",
            "-d", "postgres",
            "-c", "ALTER USER postgres WITH PASSWORD 'postgres';"
        ])

        # Create neotix database if it doesn't exist
        logger.info("Creating neotix database...")
        run_command(["createdb", "neotix"])

        # Update local .env file
        env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), '.env')
        env_content = """DATABASE_URI=postgresql://postgres:postgres@localhost:5432/neotix
MILVUS_HOST=localhost
MILVUS_PORT=19530
EMBEDDING_MODEL_PATH=sentence-transformers/all-MiniLM-L6-v2
QDRANT_HOST=localhost
QDRANT_PORT=6333"""

        with open(env_path, 'w') as f:
            f.write(env_content)
        
        logger.info("Environment file updated successfully")
        
        logger.info("""
PostgreSQL setup completed successfully!
Your database is now configured with:
- Database name: neotix
- Username: postgres
- Password: postgres
- Port: 5432

To start using the database:
1. Make sure PostgreSQL is running: brew services start postgresql@15
2. Your .env file has been updated with the correct DATABASE_URI
3. Run your Flask application to create the tables
""")

    except Exception as e:
        logger.error(f"Error setting up PostgreSQL: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    setup_postgres()

================
File: utils/database.py
================
from flask_sqlalchemy import SQLAlchemy
import os
import logging
from sqlalchemy_utils import database_exists, create_database
from sqlalchemy import create_engine

db = SQLAlchemy()
logger = logging.getLogger(__name__)


def init_db(app):
    try:
        with app.app_context():
            database_uri = app.config["SQLALCHEMY_DATABASE_URI"]
            logger.info(f"Using database at: {database_uri}")

            # Create database if it doesn't exist
            engine = create_engine(database_uri)
            if not database_exists(engine.url):
                create_database(engine.url)
                logger.info(f"Created database at: {database_uri}")

            # Create all tables
            logger.info("Creating tables...")
            db.create_all()
            logger.info("Database initialization complete")
    except Exception as e:
        logger.error(f"Error initializing database: {str(e)}")
        raise

================
File: utils/gpu_data_fetcher.py
================
import sys
import os
from datetime import datetime
import hashlib

# Add gpuhunt submodule to Python path
gpuhunt_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'gpuhunt', 'src')
sys.path.insert(0, gpuhunt_path)

import gpuhunt
from models.gpu_listing import GPUListing, GPUPricePoint, GPUPriceHistory, Host
from utils.database import db

def hash_gpu_listing(offer):
    """
    Creates a unique hash of a GPU listing for comparison
    """
    # Create a deterministic string of all relevant fields
    listing_str = f"{offer.instance_name}:{offer.gpu_name}:{offer.gpu_count}:{offer.gpu_memory}:{offer.cpu}:{offer.memory}:{offer.disk_size}:{offer.provider}:{offer.location}:{offer.spot}"
    
    # Create SHA-256 hash
    return hashlib.sha256(listing_str.encode()).hexdigest()

def fetch_gpu_data():
    """
    Fetches GPU data from all providers using gpuhunt and updates the database
    """
    current_time = datetime.utcnow()
    
    # Get all offers from all providers
    offers = gpuhunt.query()
    
    # Get all existing listings for deduplication
    existing_listings = {}
    for listing in GPUListing.query.all():
        # Create a unique key for each listing
        key = f"{listing.instance_name}:{listing.gpu_name}:{listing.gpu_count}:{listing.gpu_memory}:{listing.cpu}:{listing.memory}:{listing.disk_size}:{listing.host.name}"
        existing_listings[key] = listing
    
    for offer in offers:
        # Skip GCP offers and those without GPUs
        if offer.provider == "gcp" or not offer.gpu_count or offer.gpu_count < 1:
            continue
            
        # Get or create host
        host = Host.query.filter_by(name=offer.provider).first()
        if not host:
            host = Host(
                name=offer.provider,
                description=f"GPU provider: {offer.provider}",
                url=""
            )
            db.session.add(host)
            db.session.flush()
            
        # Create key for deduplication
        listing_key = f"{offer.instance_name}:{offer.gpu_name}:{offer.gpu_count}:{offer.gpu_memory}:{offer.cpu}:{offer.memory}:{offer.disk_size}:{offer.provider}"
        
        if listing_key in existing_listings:
            # Update existing listing
            gpu_listing = existing_listings[listing_key]
            if gpu_listing.current_price != offer.price:
                # Calculate price change percentage
                price_change = ((offer.price - gpu_listing.current_price) / gpu_listing.current_price) * 100
                gpu_listing.price_change = f"{price_change:+.1f}%"
            gpu_listing.current_price = offer.price
            gpu_listing.last_updated = current_time
        else:
            # Create new listing
            gpu_listing = GPUListing(
                instance_name=offer.instance_name,
                gpu_name=offer.gpu_name,
                gpu_vendor=offer.gpu_vendor.value if offer.gpu_vendor else None,
                gpu_count=offer.gpu_count,
                gpu_memory=offer.gpu_memory,
                current_price=offer.price,
                cpu=offer.cpu,
                memory=offer.memory,
                disk_size=offer.disk_size,
                host_id=host.id
            )
            gpu_listing.price_change = "0%"
            db.session.add(gpu_listing)
            db.session.flush()
            existing_listings[listing_key] = gpu_listing
        
        # Update or create price point
        price_point = GPUPricePoint.query.filter_by(
            gpu_listing_id=gpu_listing.id,
            location=offer.location,
            spot=offer.spot
        ).first()
        
        if price_point:
            # Update existing price point
            price_point.price = offer.price
            price_point.last_updated = current_time
        else:
            # Create new price point
            price_point = GPUPricePoint(
                gpu_listing_id=gpu_listing.id,
                price=offer.price,
                location=offer.location,
                spot=offer.spot,
                last_updated=current_time
            )
            db.session.add(price_point)
        
        # Add historical price record
        history = GPUPriceHistory(
            gpu_listing_id=gpu_listing.id,
            price=offer.price,
            date=current_time,
            location=offer.location,
            spot=offer.spot
        )
        db.session.add(history)
    
    # Commit all changes
    try:
        db.session.commit()
    except Exception as e:
        db.session.rollback()
        raise e

================
File: app.py
================
from flask import Flask, jsonify
from flask_cors import CORS
from utils.database import db, init_db
from routes.user_preferences import bp as user_preferences_bp
from routes.gpu_listings import bp as gpu_bp
from routes.user import bp as user_bp
from routes.project import bp as project_bp
from models.user import User
from models.project import Project, ProjectGPU
from models.gpu_listing import GPUListing
from commands.fetch_gpu_data import fetch_gpu_data_command
import os
from firebase_admin import credentials
import firebase_admin
from config import Config
from dotenv import load_dotenv
from flask_migrate import Migrate

# Load environment variables from .env file
load_dotenv(os.path.join(os.path.dirname(__file__), ".env"))

# Debug: Print environment variables
print("Current working directory:", os.getcwd())
print("Environment file path:", os.path.join(os.path.dirname(__file__), ".env"))
print("DATABASE_URI:", os.getenv("DATABASE_URI"))


def create_app(environ=None, start_response=None):
    """Create and configure the Flask application"""
    app = Flask(__name__, instance_relative_config=True)

    try:
        # Initialize Firebase Admin with your service account
        cred = credentials.Certificate("firebaseKey.json")
        firebase_admin.initialize_app(cred)
    except ValueError:
        # Firebase already initialized, skip
        pass

    # Configure CORS - Allow specific origins
    app.config["CORS_HEADERS"] = "Content-Type"
    CORS(
        app,
        resources={
            r"/api/*": {
                "origins": "*",
                "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
                "allow_headers": [
                    "Content-Type",
                    "Authorization",
                    "X-Requested-With",
                    "Accept",
                    "Origin",
                ],
                "expose_headers": ["Content-Type", "Authorization"],
                "supports_credentials": True,
            }
        },
    )

    # Ensure the instance folder exists and is writable
    try:
        instance_path = app.instance_path
        os.makedirs(instance_path, exist_ok=True)
        # Test if directory is writable
        test_file = os.path.join(instance_path, "test.txt")
        with open(test_file, "w") as f:
            f.write("test")
        os.remove(test_file)
    except Exception as e:
        print(f"Warning: Could not verify instance path is writable: {e}")

    # Configure SQLite database with absolute path
    app.config.from_object(Config)

    # Debug: Print configuration
    print("Database URI:", app.config.get("SQLALCHEMY_DATABASE_URI"))
    print("Environment DATABASE_URI:", os.getenv("DATABASE_URI"))

    # Initialize database
    db.init_app(app)

    # Initialize database tables
    init_db(app)

    # Initialize flask_migrate
    migrate = Migrate(app, db)

    # Register blueprints
    app.register_blueprint(user_preferences_bp, url_prefix="/api/preferences")
    app.register_blueprint(gpu_bp, url_prefix="/api/gpu")
    app.register_blueprint(user_bp, url_prefix="/api/user")
    app.register_blueprint(project_bp, url_prefix="/api/projects")
    
    # Register CLI commands
    app.cli.add_command(fetch_gpu_data_command)

    # Add CORS headers to all responses
    @app.after_request
    def add_cors_headers(response):
        response.headers["Access-Control-Allow-Origin"] = "*"
        response.headers["Access-Control-Allow-Methods"] = (
            "GET, POST, PUT, DELETE, OPTIONS"
        )
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        return response

    # Error handlers
    @app.errorhandler(404)
    def not_found_error(error):
        return jsonify({"error": "Resource not found"}), 404

    @app.errorhandler(500)
    def internal_error(error):
        return jsonify({"error": "Internal server error"}), 500

    if environ is not None and start_response is not None:
        return app.wsgi_app(environ, start_response)

    return app


if __name__ == "__main__":
    app = create_app()
    app.run(debug=True, host="0.0.0.0")


#TODO: on 01/15: Add new routes for new UI 

#TODO: on 01/15: Improve speed of getting things inside the DB. + There are problems with some duplicates, like 10 of them in case we call the command twice 

#TODO: on 01/15: Improve DB schem for the User GPU selections. 

#TODO: Add more providers to gpulist

================
File: config.py
================
import os

class Config:
    SQLALCHEMY_DATABASE_URI = os.getenv(
        "DATABASE_URI",
        "postgresql://postgres:postgres@localhost:5432/neotix"  # Default for local development
    )
    SQLALCHEMY_TRACK_MODIFICATIONS = False

================
File: Ideas.md
================
I have have a revisions.md (rev#.md) file in my project and have Claud-Dev either create or modify the revisions.md file acordingly.. rev1.md, rev2.md. and maybe a design.md or process.md file with pertinent information. Then in my prompt I will do something like this.

Design.md contains The purpose of the project what needs to be acomplished, any design related information, psudo-code and other related project information.

Using the @design.md and @rev1.md I would like you to continue working on blah blah when your complete create a rev2.md file with updated status of the project and next steps. Then in the next prompt to continue I will do the same but then reference rev2.md instead of rev1.md.

At times I will do something like this. Using @design.md, @rev1.md @rev2.md @rev3.md ... make sure that we have implemented such and such. Provide a new design1.md document so that we can continue going forward.

I keep my revisions and then if I need to, or it gets lost I can always use the prompt to tell it to go though a certain revision if needed.
It seems to be working fairly well. Where Claud-Dev can create whatever file I tell it to it makes it nice to be able to handle revisions, document updates etc.

My actual last prompt I was using:
Using the existing solution code, @Design2.md, @Rev17.md as well as the code snippets.  evaluate the solution, the  iterations and existing code base and combine them for the ultimate solution.  When using the existing codebase make sure that the solution uses as much of the existing code as possible in implementing this "feature" implementation.  First act as a code reviewer and find any issues or items that have been missed. Provide a comprehensive list of items that still need to be implemented. Provide any pseudocode or examples that the coder could use. 

Then act as an expert thorough senior coder and use the suggestions from the reviewer to address each item given by the reviewer.  Make code changes and provide the new ultimate solution. For ANY pseudocode that is used within the examples implement the pseudocode.  Provide the complete code from the codebase with the added changes so that I can now add files and changes to the existing solution.  

Using the new code from the Coder and the suggestions from the Reviewer provide an Update that can be added to the design document.

Sometimes I will get 10-20 revisions deep before I will let Claud-Dev make any actual code changes. all of the code changes will be in the rev#.md file(s)
***If any of you have better suggestions or a better modified version of this please share....

================
File: README.md
================
# GPU Listings Backend

A simple Flask backend for fetching and managing GPU listings from various providers.

## Quick Setup

1. Create a virtual environment and activate it:
```bash
python -m venv .startup
source .startup/bin/activate
```

2. Install dependencies from requirements.txt:
```bash
pip install -r requirements.txt
```

3. Set up PostgreSQL database:
```bash
# Install PostgreSQL if not already installed
sudo pacman -S postgresql

# Create database
sudo -u postgres psql
postgres=# CREATE DATABASE neotix;
postgres=# \q
```

4. Create a `.env` file in the root directory:
```bash
DATABASE_URI=postgresql://postgres:postgres@localhost:5432/neotix
```

5. Initialize the database:
```bash
flask db upgrade
```

6. Run the application:
```bash
flask run
```

7. Fetch GPU data:
```bash
flask fetch-gpu-data
```
# Test change
